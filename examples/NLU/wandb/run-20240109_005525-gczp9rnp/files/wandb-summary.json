{"train/loss": 0.4858, "train/learning_rate": 1.2749003984063745e-05, "train/epoch": 1.0, "_timestamp": 1704733111.143098, "_runtime": 186.025386095047, "_step": 268, "gradients/classifier.out_proj.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07159308344125748, -0.0693558007478714, -0.06711851805448532, -0.06488123536109924, -0.06264394521713257, -0.06040666624903679, -0.05816937983036041, -0.055932097136974335, -0.05369481444358826, -0.05145753175020218, -0.0492202490568161, -0.046982962638139725, -0.04474567994475365, -0.04250839725136757, -0.04027111083269119, -0.038033828139305115, -0.03579654544591904, -0.03355926275253296, -0.03132198005914688, -0.029084693640470505, -0.026847410947084427, -0.02461012825369835, -0.022372843697667122, -0.020135559141635895, -0.017898276448249817, -0.01566099375486374, -0.013423709198832512, -0.01118642557412386, -0.008949141949415207, -0.006711858324706554, -0.004474574699997902, -0.002237290143966675, 0.0, 0.0022372836247086525, 0.004474567249417305, 0.0067118508741259575, 0.00894913449883461, 0.011186418123543262, 0.013423701748251915, 0.015660986304283142, 0.01789826899766922, 0.020135551691055298, 0.022372836247086525, 0.024610120803117752, 0.02684740349650383, 0.029084686189889908, 0.031321972608566284, 0.03355925530195236, 0.03579653799533844, 0.03803382068872452, 0.040271103382110596, 0.04250838980078697, 0.04474567249417305, 0.04698295518755913, 0.049220241606235504, 0.05145752429962158, 0.05369480699300766, 0.05593208968639374, 0.058169372379779816, 0.06040665879845619, 0.06264394521713257, 0.06488122791051865, 0.06711851060390472, 0.0693557932972908, 0.07159307599067688]}, "gradients/classifier.out_proj.weight": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 3.0, 6.0, 7.0, 10.0, 2.0, 10.0, 10.0, 17.0, 13.0, 23.0, 18.0, 27.0, 31.0, 42.0, 34.0, 57.0, 36.0, 62.0, 46.0, 78.0, 68.0, 72.0, 82.0, 82.0, 72.0, 68.0, 78.0, 46.0, 62.0, 36.0, 57.0, 34.0, 42.0, 31.0, 27.0, 18.0, 23.0, 13.0, 17.0, 10.0, 10.0, 2.0, 10.0, 7.0, 6.0, 3.0, 2.0, 4.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.05474424362182617, -0.053033486008644104, -0.051322728395462036, -0.04961197078227997, -0.0479012131690979, -0.04619045555591583, -0.044479697942733765, -0.0427689403295517, -0.04105818271636963, -0.03934742510318756, -0.03763666749000549, -0.035925909876823425, -0.03421515226364136, -0.03250439465045929, -0.03079363703727722, -0.029082879424095154, -0.027372121810913086, -0.025661364197731018, -0.02395060658454895, -0.022239848971366882, -0.020529091358184814, -0.018818333745002747, -0.01710757613182068, -0.01539681851863861, -0.013686060905456543, -0.011975303292274475, -0.010264545679092407, -0.00855378806591034, -0.0068430304527282715, -0.005132272839546204, -0.0034215152263641357, -0.0017107576131820679, 0.0, 0.0017107576131820679, 0.0034215152263641357, 0.005132272839546204, 0.0068430304527282715, 0.00855378806591034, 0.010264545679092407, 0.011975303292274475, 0.013686060905456543, 0.01539681851863861, 0.01710757613182068, 0.018818333745002747, 0.020529091358184814, 0.022239848971366882, 0.02395060658454895, 0.025661364197731018, 0.027372121810913086, 0.029082879424095154, 0.03079363703727722, 0.03250439465045929, 0.03421515226364136, 0.035925909876823425, 0.03763666749000549, 0.03934742510318756, 0.04105818271636963, 0.0427689403295517, 0.044479697942733765, 0.04619045555591583, 0.0479012131690979, 0.04961197078227997, 0.051322728395462036, 0.053033486008644104, 0.05474424362182617]}, "gradients/classifier.dense.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 4.0, 9.0, 7.0, 9.0, 7.0, 5.0, 22.0, 16.0, 25.0, 24.0, 37.0, 37.0, 32.0, 41.0, 54.0, 74.0, 49.0, 45.0, 45.0, 28.0, 29.0, 27.0, 27.0, 19.0, 21.0, 10.0, 10.0, 8.0, 9.0, 3.0, 8.0, 1.0, 4.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.007611290086060762, -0.007355234120041132, -0.007099178619682789, -0.006843122653663158, -0.006587067153304815, -0.006331011187285185, -0.006074955686926842, -0.005818899720907211, -0.005562843754887581, -0.0053067877888679504, -0.005050732288509607, -0.004794676322489977, -0.004538620822131634, -0.004282564856112003, -0.004026508890092373, -0.0037704533897340298, -0.0035143978893756866, -0.0032583421561867, -0.003002286422997713, -0.0027462304569780827, -0.0024901749566197395, -0.002234118990600109, -0.0019780632574111223, -0.0017220075242221355, -0.0014659517910331488, -0.001209896057844162, -0.0009538402664475143, -0.0006977844750508666, -0.0004417287418618798, -0.00018567300867289305, 7.038284093141556e-05, 0.00032643857412040234, 0.0005824947729706764, 0.0008385505061596632, 0.00109460623934865, 0.0013506620889529586, 0.0016067178221419454, 0.0018627735553309321, 0.0021188294049352407, 0.0023748851381242275, 0.0026309408713132143, 0.002886996604502201, 0.003143052337691188, 0.0033991080708801746, 0.003655164036899805, 0.003911219537258148, 0.004167275503277779, 0.004423331469297409, 0.004679386969655752, 0.004935442935675383, 0.005191498436033726, 0.005447554402053356, 0.005703609902411699, 0.00595966586843133, 0.006215721368789673, 0.006471777334809303, 0.006727833300828934, 0.006983889266848564, 0.007239944767206907, 0.007496000733226538, 0.007752056233584881, 0.008008112199604511, 0.008264168165624142, 0.008520223200321198, 0.008776279166340828]}, "gradients/classifier.dense.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 5.0, 1.0, 1.0, 3.0, 5.0, 3.0, 3.0, 5.0, 5.0, 8.0, 13.0, 7.0, 11.0, 18.0, 18.0, 21.0, 38.0, 62.0, 88.0, 154.0, 1433.0, 585694.0, 1767.0, 167.0, 73.0, 50.0, 31.0, 30.0, 12.0, 30.0, 15.0, 3.0, 10.0, 8.0, 4.0, 7.0, 5.0, 3.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.09878943860530853, -0.09615650027990341, -0.09352356195449829, -0.09089063107967377, -0.08825769275426865, -0.08562475442886353, -0.082991823554039, -0.08035888522863388, -0.07772594690322876, -0.07509300857782364, -0.07246007025241852, -0.069827139377594, -0.06719420105218887, -0.06456126272678375, -0.06192832812666893, -0.05929539352655411, -0.05666245520114899, -0.054029516875743866, -0.051396582275629044, -0.04876364767551422, -0.0461307093501091, -0.04349777102470398, -0.04086483642458916, -0.038231901824474335, -0.035598963499069214, -0.03296602517366409, -0.03033309057354927, -0.0277001541107893, -0.025067217648029327, -0.022434281185269356, -0.019801344722509384, -0.017168408259749413, -0.014535471796989441, -0.01190253533422947, -0.009269598871469498, -0.006636662408709526, -0.0040037259459495544, -0.0013707894831895828, 0.0012621469795703888, 0.0038950834423303604, 0.006528019905090332, 0.009160956367850304, 0.011793892830610275, 0.014426829293370247, 0.01705976575613022, 0.01969270221889019, 0.022325638681650162, 0.024958575144410133, 0.027591511607170105, 0.030224448069930077, 0.03285738453269005, 0.03549031913280487, 0.03812325745820999, 0.04075619578361511, 0.043389130383729935, 0.04602206498384476, 0.04865500330924988, 0.051287941634655, 0.05392087623476982, 0.056553810834884644, 0.059186749160289764, 0.061819687485694885, 0.06445261836051941, 0.06708555668592453, 0.06971849501132965]}, "gradients/roberta.encoder.layer.11.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 1.0, 3.0, 2.0, 4.0, 9.0, 18.0, 20.0, 24.0, 32.0, 51.0, 84.0, 139.0, 207.0, 308.0, 447.0, 609.0, 739.0, 794.0, 737.0, 595.0, 415.0, 303.0, 198.0, 128.0, 79.0, 56.0, 36.0, 30.0, 19.0, 7.0, 9.0, 9.0, 3.0, 4.0, 1.0, 1.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.010209803469479084, -0.009874645620584488, -0.009539487771689892, -0.009204329922795296, -0.008869171142578125, -0.008534013293683529, -0.008198855444788933, -0.007863697595894337, -0.007528539281338453, -0.007193381432443857, -0.006858223117887974, -0.006523065268993378, -0.006187907420098782, -0.005852749105542898, -0.005517591256648302, -0.005182432942092419, -0.004847275093197823, -0.0045121172443032265, -0.004176958929747343, -0.003841801080852747, -0.003506642999127507, -0.0031714849174022675, -0.0028363270685076714, -0.0025011689867824316, -0.002166010905057192, -0.001830852823331952, -0.0014956948580220342, -0.0011605368927121162, -0.0008253788109868765, -0.0004902207292616367, -0.00015506288036704063, 0.00018009520135819912, 0.0005152542144060135, 0.0008504122379235923, 0.0011855702614411712, 0.001520728226751089, 0.0018558863084763288, 0.0021910443902015686, 0.0025262022390961647, 0.0028613603208214045, 0.003196518402546644, 0.003531676484271884, 0.0038668345659971237, 0.00420199241489172, 0.004537150263786316, 0.004872308578342199, 0.005207466427236795, 0.005542624741792679, 0.005877782590687275, 0.006212940439581871, 0.0065480987541377544, 0.0068832566030323505, 0.007218414917588234, 0.00755357276648283, 0.007888730615377426, 0.008223888464272022, 0.008559046313166618, 0.008894204162061214, 0.00922936201095581, 0.009564520791172981, 0.009899678640067577, 0.010234836488962173, 0.01056999433785677, 0.010905152186751366, 0.011240310966968536]}, "gradients/roberta.encoder.layer.11.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 4.0, 20.0, 227.0, 3311.0, 2377.0, 162.0, 19.0, 3.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.18012350797653198, -0.17367364466190338, -0.16722378134727478, -0.16077393293380737, -0.15432406961917877, -0.14787420630455017, -0.14142434298992157, -0.13497447967529297, -0.12852463126182556, -0.12207476794719696, -0.11562491208314896, -0.10917504876852036, -0.10272519290447235, -0.09627532958984375, -0.08982546627521515, -0.08337560296058655, -0.07692573964595795, -0.07047587633132935, -0.06402602046728134, -0.05757615715265274, -0.05112629756331444, -0.044676437973976135, -0.038226574659347534, -0.03177671507000923, -0.02532685548067093, -0.018876995891332626, -0.012427134439349174, -0.005977272987365723, 0.00047258660197257996, 0.006922446191310883, 0.013372309505939484, 0.019822169095277786, 0.026272043585777283, 0.032721903175115585, 0.03917176276445389, 0.04562162607908249, 0.05207148566842079, 0.058521345257759094, 0.0649712085723877, 0.0714210718870163, 0.0778709277510643, 0.0843207910656929, 0.0907706469297409, 0.0972205102443695, 0.10367037355899811, 0.11012022942304611, 0.11657009273767471, 0.12301994860172272, 0.12946981191635132, 0.13591967523097992, 0.14236953854560852, 0.14881938695907593, 0.15526925027370453, 0.16171911358833313, 0.16816897690296173, 0.17461884021759033, 0.18106868863105774, 0.18751855194568634, 0.19396841526031494, 0.20041826367378235, 0.20686812698841095, 0.21331799030303955, 0.21976785361766815, 0.22621771693229675, 0.23266758024692535]}, "gradients/roberta.encoder.layer.11.attention.self.query.lora_B": {"_type": "histogram", "values": [2.0, 0.0, 3.0, 2.0, 0.0, 5.0, 1.0, 4.0, 3.0, 11.0, 7.0, 6.0, 11.0, 20.0, 12.0, 27.0, 21.0, 29.0, 41.0, 52.0, 46.0, 57.0, 77.0, 90.0, 142.0, 173.0, 143.0, 263.0, 340.0, 387.0, 511.0, 605.0, 585.0, 514.0, 383.0, 339.0, 256.0, 176.0, 144.0, 124.0, 114.0, 69.0, 63.0, 39.0, 38.0, 48.0, 28.0, 32.0, 16.0, 19.0, 8.0, 8.0, 16.0, 5.0, 6.0, 3.0, 8.0, 3.0, 3.0, 3.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.008143718354403973, -0.007889066822826862, -0.007634414825588465, -0.007379762828350067, -0.007125111296772957, -0.0068704597651958466, -0.006615807767957449, -0.006361155770719051, -0.006106504239141941, -0.005851852707564831, -0.005597200710326433, -0.005342548713088036, -0.005087897181510925, -0.004833245649933815, -0.004578593652695417, -0.00432394165545702, -0.0040692901238799095, -0.0038146383594721556, -0.0035599865950644016, -0.0033053348306566477, -0.0030506830662488937, -0.00279603130184114, -0.002541379537433386, -0.002286727773025632, -0.002032076008617878, -0.001777424244210124, -0.00152277247980237, -0.0012681207153946161, -0.0010134689509868622, -0.0007588171865791082, -0.0005041654221713543, -0.00024951365776360035, 5.138106644153595e-06, 0.00025978987105190754, 0.0005144416354596615, 0.0007690933998674154, 0.0010237451642751694, 0.0012783969286829233, 0.0015330486930906773, 0.0017877004574984312, 0.002042352221906185, 0.002297003986313939, 0.002551655750721693, 0.002806307515129447, 0.003060959279537201, 0.003315611043944955, 0.003570262808352709, 0.0038249145727604628, 0.004079566337168217, 0.004334217868745327, 0.004588869865983725, 0.004843521863222122, 0.0050981733947992325, 0.005352824926376343, 0.00560747692361474, 0.005862128920853138, 0.006116780452430248, 0.0063714319840073586, 0.006626083981245756, 0.006880735978484154, 0.007135387510061264, 0.007390039041638374, 0.007644691038876772, 0.00789934303611517, 0.00815399456769228]}, "gradients/roberta.encoder.layer.11.attention.self.query.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 745.0, 5356.0, 29.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0], "bins": [-0.012286152690649033, -0.011893337592482567, -0.011500522494316101, -0.011107707396149635, -0.01071489229798317, -0.010322077199816704, -0.009929262101650238, -0.009536447003483772, -0.009143631905317307, -0.00875081680715084, -0.008358001708984375, -0.00796518661081791, -0.0075723715126514435, -0.007179556414484978, -0.006786741781979799, -0.0063939266838133335, -0.006001112051308155, -0.005608296953141689, -0.0052154818549752235, -0.004822666756808758, -0.004429851658642292, -0.004037036560475826, -0.003644221927970648, -0.003251406829804182, -0.0028585917316377163, -0.0024657766334712505, -0.0020729615353047848, -0.0016801466699689627, -0.001287331571802497, -0.0008945164736360312, -0.000501701608300209, -0.00010888651013374329, 0.0002839295193552971, 0.0006767445593141019, 0.0010695595992729068, 0.0014623745810240507, 0.0018551896791905165, 0.0022480047773569822, 0.0026408196426928043, 0.00303363474085927, 0.003426449839025736, 0.0038192649371922016, 0.004212080035358667, 0.004604894667863846, 0.004997709766030312, 0.005390524864196777, 0.005783339962363243, 0.006176155060529709, 0.006568970158696175, 0.00696178525686264, 0.007354600355029106, 0.007747415453195572, 0.008140230551362038, 0.008533045649528503, 0.00892586074769497, 0.009318675845861435, 0.0097114909440279, 0.010104306042194366, 0.010497121140360832, 0.010889936238527298, 0.011282751336693764, 0.01167556643486023, 0.012068381533026695, 0.012461196631193161, 0.012854010798037052]}, "gradients/roberta.encoder.layer.10.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 5.0, 4.0, 5.0, 5.0, 14.0, 18.0, 21.0, 23.0, 40.0, 40.0, 69.0, 92.0, 137.0, 192.0, 307.0, 385.0, 576.0, 749.0, 938.0, 690.0, 509.0, 344.0, 267.0, 206.0, 139.0, 94.0, 78.0, 57.0, 36.0, 24.0, 22.0, 7.0, 5.0, 8.0, 10.0, 9.0, 5.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.020641827955842018, -0.020073559135198593, -0.019505292177200317, -0.01893702521920204, -0.018368756398558617, -0.01780048757791519, -0.017232220619916916, -0.01666395366191864, -0.016095684841275215, -0.015527416951954365, -0.014959149062633514, -0.014390881173312664, -0.013822613283991814, -0.013254345394670963, -0.012686077505350113, -0.012117809616029263, -0.011549541726708412, -0.010981273837387562, -0.010413005948066711, -0.009844738058745861, -0.00927647016942501, -0.00870820228010416, -0.00813993439078331, -0.0075716665014624596, -0.007003398612141609, -0.006435130722820759, -0.0058668628334999084, -0.005298594944179058, -0.004730327054858208, -0.004162059165537357, -0.003593791276216507, -0.0030255233868956566, -0.0024572573602199554, -0.001888989470899105, -0.0013207215815782547, -0.0007524536922574043, -0.00018418580293655396, 0.0003840820863842964, 0.0009523499757051468, 0.0015206178650259972, 0.0020888857543468475, 0.002657153643667698, 0.0032254215329885483, 0.0037936894223093987, 0.004361957311630249, 0.004930225200951099, 0.00549849309027195, 0.0060667609795928, 0.0066350288689136505, 0.007203296758234501, 0.007771564647555351, 0.008339832536876202, 0.008908100426197052, 0.009476368315517902, 0.010044636204838753, 0.010612904094159603, 0.011181171983480453, 0.011749439872801304, 0.012317707762122154, 0.012885975651443005, 0.013454243540763855, 0.014022511430084705, 0.014590779319405556, 0.015159047208726406, 0.015727315098047256]}, "gradients/roberta.encoder.layer.10.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 5.0, 45.0, 846.0, 5033.0, 183.0, 18.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.058037735521793365, -0.05564608424901962, -0.05325443297624588, -0.05086278170347214, -0.048471130430698395, -0.04607947915792465, -0.04368783161044121, -0.041296180337667465, -0.03890452906489372, -0.03651287779211998, -0.03412122651934624, -0.031729575246572495, -0.0293379258364439, -0.02694627456367016, -0.024554625153541565, -0.022162973880767822, -0.01977132260799408, -0.017379671335220337, -0.014988020993769169, -0.012596370652318, -0.010204719379544258, -0.007813068106770515, -0.005421417765319347, -0.0030297674238681793, -0.0006381161510944366, 0.0017535346560180187, 0.004145185463130474, 0.0065368362702429295, 0.008928487077355385, 0.011320138350129128, 0.013711788691580296, 0.016103439033031464, 0.018495090305805206, 0.02088674157857895, 0.02327839285135269, 0.025670042261481285, 0.028061693534255028, 0.03045334480702877, 0.032844994217157364, 0.03523664548993111, 0.03762829676270485, 0.04001994803547859, 0.042411599308252335, 0.04480325058102608, 0.04719489812850952, 0.049586549401283264, 0.05197820067405701, 0.05436985194683075, 0.05676150321960449, 0.059153154492378235, 0.06154480576515198, 0.06393645703792572, 0.06632810831069946, 0.0687197595834732, 0.07111141085624695, 0.07350306212902069, 0.07589471340179443, 0.07828636467456818, 0.08067801594734192, 0.08306966722011566, 0.0854613184928894, 0.08785296976566315, 0.09024462103843689, 0.09263627231121063, 0.09502791613340378]}, "gradients/roberta.encoder.layer.10.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 6.0, 9.0, 9.0, 12.0, 11.0, 26.0, 35.0, 39.0, 67.0, 85.0, 117.0, 161.0, 205.0, 345.0, 435.0, 548.0, 828.0, 900.0, 637.0, 437.0, 322.0, 247.0, 169.0, 105.0, 88.0, 69.0, 55.0, 26.0, 22.0, 24.0, 21.0, 12.0, 7.0, 3.0, 6.0, 8.0, 4.0, 3.0, 2.0, 3.0, 5.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.008189382962882519, -0.00793403573334217, -0.00767868896946311, -0.007423342205584049, -0.007167994976043701, -0.00691264821216464, -0.00665730144828558, -0.006401954218745232, -0.006146607454866171, -0.00589126069098711, -0.005635913461446762, -0.005380566697567701, -0.005125219933688641, -0.0048698727041482925, -0.004614525940269232, -0.004359179176390171, -0.004103831946849823, -0.0038484849501401186, -0.003593137953430414, -0.0033377911895513535, -0.003082444192841649, -0.0028270971961319447, -0.002571750432252884, -0.0023164034355431795, -0.002061056438833475, -0.0018057094421237707, -0.0015503625618293881, -0.0012950156815350056, -0.0010396686848253012, -0.0007843216881155968, -0.0005289748078212142, -0.0002736279275268316, -1.8281862139701843e-05, 0.00023706507636234164, 0.0004924120148643851, 0.0007477589533664286, 0.001003105891868472, 0.0012584528885781765, 0.001513799768872559, 0.0017691466491669416, 0.002024493645876646, 0.0022798406425863504, 0.002535187639296055, 0.0027905344031751156, 0.00304588139988482, 0.0033012283965945244, 0.003556575160473585, 0.0038119221571832895, 0.004067269153892994, 0.004322615917772055, 0.004577963147312403, 0.0048333099111914635, 0.0050886571407318115, 0.005344003904610872, 0.005599350668489933, 0.005854697898030281, 0.006110044661909342, 0.0063653914257884026, 0.006620738655328751, 0.006876085419207811, 0.007131432183086872, 0.00738677941262722, 0.007642126176506281, 0.007897472940385342, 0.00815282016992569]}, "gradients/roberta.encoder.layer.10.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 4.0, 26.0, 334.0, 2776.0, 2647.0, 306.0, 27.0, 1.0, 6.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.016475295647978783, -0.016029927879571915, -0.015584561042487621, -0.015139194205403328, -0.01469382643699646, -0.014248459599912167, -0.013803092762827873, -0.013357724994421005, -0.012912357226014137, -0.012466990388929844, -0.012021622620522976, -0.011576255783438683, -0.011130888015031815, -0.010685521177947521, -0.010240154340863228, -0.00979478657245636, -0.009349419735372066, -0.008904052898287773, -0.008458685129880905, -0.008013318292796612, -0.007567950524389744, -0.0071225836873054504, -0.00667721638455987, -0.006231849081814289, -0.005786481779068708, -0.005341114476323128, -0.004895747173577547, -0.004450379870831966, -0.004005013033747673, -0.0035596454981714487, -0.0031142784282565117, -0.002668911125510931, -0.0022235438227653503, -0.0017781765200197697, -0.0013328093336895108, -0.000887442147359252, -0.0004420748446136713, 3.2924581319093704e-06, 0.0004486595280468464, 0.0008940268307924271, 0.0013393941335380077, 0.0017847614362835884, 0.002230128739029169, 0.002675495808944106, 0.0031208631116896868, 0.0035662304144352674, 0.0040115974843502045, 0.004456964787095785, 0.004902332089841366, 0.0053476993925869465, 0.005793066695332527, 0.0062384335324168205, 0.0066838013008236885, 0.007129168137907982, 0.0075745354406535625, 0.008019902743399143, 0.008465269580483437, 0.00891063641756773, 0.009356004185974598, 0.009801371023058891, 0.01024673879146576, 0.010692105628550053, 0.011137472465634346, 0.011582840234041214, 0.012028208002448082]}, "gradients/roberta.encoder.layer.9.attention.self.value.lora_B": {"_type": "histogram", "values": [4.0, 2.0, 3.0, 2.0, 5.0, 5.0, 8.0, 7.0, 12.0, 22.0, 26.0, 27.0, 36.0, 41.0, 50.0, 85.0, 91.0, 110.0, 155.0, 148.0, 185.0, 272.0, 308.0, 397.0, 452.0, 562.0, 571.0, 486.0, 438.0, 324.0, 297.0, 213.0, 160.0, 133.0, 102.0, 93.0, 72.0, 52.0, 43.0, 27.0, 27.0, 21.0, 14.0, 7.0, 11.0, 6.0, 4.0, 5.0, 3.0, 2.0, 0.0, 6.0, 3.0, 0.0, 3.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.011667590588331223, -0.011218355037271976, -0.01076911948621273, -0.010319884866476059, -0.009870649315416813, -0.009421413764357567, -0.008972179144620895, -0.00852294359356165, -0.008073708042502403, -0.007624472491443157, -0.0071752374060451984, -0.00672600232064724, -0.006276766769587994, -0.0058275312185287476, -0.005378296133130789, -0.00492906104773283, -0.004479825496673584, -0.004030589945614338, -0.003581354860216379, -0.0031321195419877768, -0.0026828842237591743, -0.002233648905530572, -0.0017844135873019695, -0.0013351782690733671, -0.0008859429508447647, -0.0004367076326161623, 1.252768561244011e-05, 0.0004617630038410425, 0.0009109983220696449, 0.0013602336402982473, 0.0018094689585268497, 0.002258704276755452, 0.0027079395949840546, 0.003157174913212657, 0.0036064102314412594, 0.004055645316839218, 0.004504880867898464, 0.00495411641895771, 0.005403351504355669, 0.005852586589753628, 0.006301822140812874, 0.00675105769187212, 0.007200292777270079, 0.007649527862668037, 0.008098763413727283, 0.00854799896478653, 0.008997233584523201, 0.009446469135582447, 0.009895704686641693, 0.01034494023770094, 0.010794175788760185, 0.011243410408496857, 0.011692645959556103, 0.012141881510615349, 0.01259111613035202, 0.013040351681411266, 0.013489587232470512, 0.013938822783529758, 0.014388058334589005, 0.014837292954325676, 0.015286528505384922, 0.015735764056444168, 0.01618499867618084, 0.01663423515856266, 0.01708346977829933]}, "gradients/roberta.encoder.layer.9.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 29.0, 103.0, 997.0, 4642.0, 269.0, 52.0, 28.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.054839782416820526, -0.052580129355192184, -0.05032047629356384, -0.0480608195066452, -0.04580116644501686, -0.04354151338338852, -0.04128185659646988, -0.03902220353484154, -0.036762550473213196, -0.034502897411584854, -0.03224324434995651, -0.029983587563037872, -0.02772393450140953, -0.02546428143978119, -0.023204626515507698, -0.020944971591234207, -0.018685318529605865, -0.016425665467977524, -0.014166010543704033, -0.011906356550753117, -0.0096467025578022, -0.007387048564851284, -0.005127394571900368, -0.002867739647626877, -0.0006080865859985352, 0.0016515674069523811, 0.003911221399903297, 0.006170875392854214, 0.00843052938580513, 0.010690183378756046, 0.012949837371706963, 0.015209492295980453, 0.017469152808189392, 0.019728805869817734, 0.021988460794091225, 0.024248115718364716, 0.026507768779993057, 0.0287674218416214, 0.03102707676589489, 0.03328673169016838, 0.03554638475179672, 0.037806037813425064, 0.040065690875053406, 0.042325347661972046, 0.04458500072360039, 0.04684465378522873, 0.04910431057214737, 0.05136396363377571, 0.05362361669540405, 0.055883269757032394, 0.058142922818660736, 0.060402579605579376, 0.06266222894191742, 0.06492188572883606, 0.0671815425157547, 0.06944119930267334, 0.07170084863901138, 0.07396050542593002, 0.07622015476226807, 0.0784798115491867, 0.08073946833610535, 0.08299911767244339, 0.08525877445936203, 0.08751842379570007, 0.08977808058261871]}, "gradients/roberta.encoder.layer.9.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 3.0, 5.0, 10.0, 11.0, 12.0, 22.0, 22.0, 46.0, 55.0, 111.0, 204.0, 323.0, 800.0, 1673.0, 1467.0, 621.0, 292.0, 158.0, 92.0, 68.0, 40.0, 29.0, 14.0, 16.0, 4.0, 4.0, 6.0, 4.0, 2.0, 2.0, 4.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.021445835009217262, -0.020848412066698074, -0.020250990986824036, -0.019653568044304848, -0.01905614696443081, -0.01845872402191162, -0.017861302942037582, -0.017263879999518394, -0.016666457056999207, -0.01606903411448002, -0.01547161303460598, -0.014874190092086792, -0.014276768080890179, -0.013679346069693565, -0.013081924058496952, -0.012484502047300339, -0.011887080036103725, -0.011289658024907112, -0.010692236013710499, -0.010094814002513885, -0.009497391059994698, -0.008899969048798084, -0.008302547037601471, -0.00770512456074357, -0.007107702549546957, -0.006510280538350344, -0.005912858061492443, -0.00531543605029583, -0.0047180140390992165, -0.004120591562241316, -0.0035231695510447025, -0.002925747074186802, -0.0023283250629901886, -0.0017309028189629316, -0.0011334806913509965, -0.0005360585637390614, 6.136368028819561e-05, 0.0006587859243154526, 0.0012562079355120659, 0.0018536304123699665, 0.00245105242356658, 0.003048474667593837, 0.0036458969116210938, 0.004243318922817707, 0.00484074093401432, 0.005438163410872221, 0.006035585422068834, 0.006633007898926735, 0.007230429910123348, 0.007827851921319962, 0.008425273932516575, 0.009022695943713188, 0.009620118886232376, 0.01021754089742899, 0.010814962908625603, 0.01141238585114479, 0.01200980693101883, 0.012607228942215443, 0.013204650953412056, 0.013802073895931244, 0.014399495907127857, 0.01499691791832447, 0.015594339929521084, 0.016191761940717697, 0.016789184883236885]}, "gradients/roberta.encoder.layer.9.attention.self.query.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 3.0, 32.0, 331.0, 1987.0, 3011.0, 671.0, 80.0, 7.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.03006797656416893, -0.029133504256606102, -0.028199031949043274, -0.027264557778835297, -0.02633008547127247, -0.02539561316370964, -0.024461138993501663, -0.023526666685938835, -0.022592194378376007, -0.02165772207081318, -0.02072324976325035, -0.019788775593042374, -0.018854303285479546, -0.017919830977916718, -0.01698535680770874, -0.016050884500145912, -0.015116412192583084, -0.014181939885020256, -0.013247466646134853, -0.01231299340724945, -0.011378521099686623, -0.010444048792123795, -0.009509575553238392, -0.00857510231435299, -0.007640630006790161, -0.006706157233566046, -0.00577168446034193, -0.004837211687117815, -0.0039027389138936996, -0.0029682661406695843, -0.002033793367445469, -0.0010993205942213535, -0.0001648496836423874, 0.000769623089581728, 0.0017040958628058434, 0.0026385686360299587, 0.003573041409254074, 0.0045075141824781895, 0.005441986955702305, 0.00637645972892642, 0.007310932502150536, 0.008245404809713364, 0.009179878048598766, 0.010114351287484169, 0.011048823595046997, 0.011983295902609825, 0.012917769141495228, 0.01385224238038063, 0.014786714687943459, 0.015721186995506287, 0.016655661165714264, 0.017590133473277092, 0.01852460578083992, 0.019459078088402748, 0.020393550395965576, 0.021328024566173553, 0.02226249687373638, 0.02319696918129921, 0.024131443351507187, 0.025065915659070015, 0.026000387966632843, 0.02693486027419567, 0.0278693325817585, 0.028803806751966476, 0.029738279059529305]}, "gradients/roberta.encoder.layer.8.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 4.0, 12.0, 11.0, 22.0, 14.0, 28.0, 52.0, 65.0, 91.0, 115.0, 144.0, 188.0, 245.0, 284.0, 373.0, 470.0, 450.0, 455.0, 491.0, 487.0, 426.0, 392.0, 287.0, 251.0, 178.0, 144.0, 112.0, 93.0, 61.0, 50.0, 38.0, 21.0, 20.0, 12.0, 6.0, 6.0, 6.0, 7.0, 7.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03200533986091614, -0.03093569539487362, -0.0298660509288311, -0.028796406462788582, -0.027726761996746063, -0.026657117530703545, -0.025587473064661026, -0.024517830461263657, -0.02344818413257599, -0.02237853966653347, -0.02130889520049095, -0.020239250734448433, -0.019169606268405914, -0.018099961802363396, -0.017030317336320877, -0.015960674732923508, -0.014891030266880989, -0.01382138580083847, -0.012751741334795952, -0.011682096868753433, -0.010612452402710915, -0.009542807936668396, -0.008473164401948452, -0.007403519935905933, -0.006333875469863415, -0.005264231003820896, -0.0041945865377783775, -0.0031249425373971462, -0.0020552980713546276, -0.000985653605312109, 8.399039506912231e-05, 0.001153634861111641, 0.0022232793271541595, 0.003292923793196678, 0.004362568259239197, 0.005432212259620428, 0.006501856725662947, 0.007571501191705465, 0.008641145192086697, 0.009710789658129215, 0.010780434124171734, 0.011850078590214252, 0.012919723056256771, 0.013989366590976715, 0.015059011057019234, 0.016128655523061752, 0.01719829998910427, 0.01826794445514679, 0.019337588921189308, 0.020407233387231827, 0.021476877853274345, 0.022546522319316864, 0.023616166785359383, 0.0246858112514019, 0.02575545385479927, 0.02682510018348694, 0.027894742786884308, 0.028964387252926826, 0.030034031718969345, 0.031103676185011864, 0.03217332065105438, 0.03324296325445175, 0.03431260958313942, 0.03538225218653679, 0.03645189851522446]}, "gradients/roberta.encoder.layer.8.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 17.0, 542.0, 5493.0, 63.0, 8.0, 3.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.08895695209503174, -0.08703479170799255, -0.08511263132095337, -0.08319047838449478, -0.0812683179974556, -0.07934615761041641, -0.07742399722337723, -0.07550184428691864, -0.07357968389987946, -0.07165752351284027, -0.06973536312580109, -0.0678132101893425, -0.06589104980230331, -0.06396888941526413, -0.062046729028224945, -0.06012457236647606, -0.058202411979436874, -0.05628025159239769, -0.054358094930648804, -0.05243593454360962, -0.05051377788186073, -0.04859161749482155, -0.04666946083307266, -0.04474730044603348, -0.04282514005899429, -0.04090297967195511, -0.03898082301020622, -0.03705866262316704, -0.03513650596141815, -0.03321434557437897, -0.03129218518733978, -0.029370028525590897, -0.02744787558913231, -0.025525717064738274, -0.02360355854034424, -0.021681398153305054, -0.019759241491556168, -0.017837081104516983, -0.015914922580122948, -0.013992764055728912, -0.012070605531334877, -0.010148447006940842, -0.008226288482546806, -0.006304129026830196, -0.004381970502436161, -0.0024598119780421257, -0.0005376525223255157, 0.0013845060020685196, 0.003306664526462555, 0.00522882305085659, 0.007150982040911913, 0.009073141030967236, 0.010995299555361271, 0.012917458079755306, 0.014839617535471916, 0.01676177605986595, 0.018683934584259987, 0.020606093108654022, 0.022528251633048058, 0.024450410157442093, 0.026372570544481277, 0.028294727206230164, 0.030216887593269348, 0.03213904798030853, 0.03406120464205742]}, "gradients/roberta.encoder.layer.8.attention.self.query.lora_B": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 3.0, 5.0, 4.0, 7.0, 13.0, 11.0, 14.0, 16.0, 18.0, 30.0, 33.0, 57.0, 91.0, 150.0, 219.0, 323.0, 484.0, 810.0, 1272.0, 904.0, 523.0, 385.0, 234.0, 162.0, 99.0, 83.0, 45.0, 27.0, 31.0, 15.0, 13.0, 15.0, 11.0, 8.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.009306096471846104, -0.0089923907071352, -0.008678684942424297, -0.008364979177713394, -0.008051273413002491, -0.0077375671826303005, -0.007423861417919397, -0.007110155187547207, -0.006796449422836304, -0.0064827436581254005, -0.006169037893414497, -0.005855332128703594, -0.005541625898331404, -0.0052279201336205006, -0.004914214368909597, -0.004600508138537407, -0.004286802839487791, -0.003973097074776888, -0.003659391077235341, -0.003345685312524438, -0.003031979314982891, -0.002718273550271988, -0.0024045677855610847, -0.002090861788019538, -0.0017771560233086348, -0.0014634501421824098, -0.0011497442610561848, -0.0008360384963452816, -0.0005223326152190566, -0.0002086267340928316, 0.00010507903061807156, 0.0004187850281596184, 0.0007324907928705215, 0.0010461966739967465, 0.0013599025551229715, 0.0016736083198338747, 0.0019873143173754215, 0.0023010200820863247, 0.002614725846797228, 0.0029284318443387747, 0.003242137609049678, 0.003555843373760581, 0.003869549371302128, 0.004183255136013031, 0.004496960900723934, 0.004810666665434837, 0.0051243724301457405, 0.005438078660517931, 0.005751784425228834, 0.006065490189939737, 0.0063791959546506405, 0.006692902185022831, 0.007006607949733734, 0.007320313714444637, 0.0076340194791555405, 0.007947725243866444, 0.008261431008577347, 0.00857513677328825, 0.008888842537999153, 0.009202548302710056, 0.00951625406742096, 0.009829960763454437, 0.010143665596842766, 0.010457372292876244, 0.010771078057587147]}, "gradients/roberta.encoder.layer.8.attention.self.query.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 11.0, 93.0, 3426.0, 2536.0, 52.0, 10.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.03550000116229057, -0.03442216292023659, -0.0333443284034729, -0.032266490161418915, -0.03118865378201008, -0.030110817402601242, -0.029032979160547256, -0.02795514278113842, -0.026877306401729584, -0.025799470022320747, -0.02472163364291191, -0.023643795400857925, -0.02256595902144909, -0.021488122642040253, -0.020410284399986267, -0.01933244802057743, -0.018254611641168594, -0.017176775261759758, -0.01609893888235092, -0.015021100640296936, -0.0139432642608881, -0.012865427881479263, -0.011787590570747852, -0.010709753260016441, -0.009631916880607605, -0.008554080501198769, -0.007476243190467358, -0.006398406345397234, -0.00532056950032711, -0.004242732655256987, -0.003164895810186863, -0.0020870589651167393, -0.001009225845336914, 6.861099973320961e-05, 0.0011464478448033333, 0.002224284689873457, 0.0033021215349435806, 0.004379958380013704, 0.005457795225083828, 0.006535632070153952, 0.007613468915224075, 0.008691305294632912, 0.009769142605364323, 0.010846979916095734, 0.01192481629550457, 0.013002652674913406, 0.014080489985644817, 0.015158327296376228, 0.016236163675785065, 0.0173140000551939, 0.018391836434602737, 0.019469674676656723, 0.02054751105606556, 0.021625347435474396, 0.02270318567752838, 0.023781022056937218, 0.024858858436346054, 0.02593669481575489, 0.027014531195163727, 0.028092369437217712, 0.02917020581662655, 0.030248042196035385, 0.03132588043808937, 0.03240371495485306, 0.03348155319690704]}, "gradients/roberta.encoder.layer.7.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 4.0, 2.0, 5.0, 8.0, 6.0, 10.0, 21.0, 33.0, 33.0, 57.0, 76.0, 94.0, 145.0, 178.0, 243.0, 336.0, 494.0, 649.0, 826.0, 727.0, 621.0, 412.0, 311.0, 238.0, 157.0, 131.0, 86.0, 69.0, 59.0, 25.0, 25.0, 19.0, 11.0, 5.0, 6.0, 4.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05187644064426422, -0.050246939063072205, -0.048617441207170486, -0.04698793962597847, -0.04535843804478645, -0.043728940188884735, -0.04209943860769272, -0.0404699370265007, -0.038840435445308685, -0.03721093386411667, -0.03558143600821495, -0.033951934427022934, -0.03232243284583092, -0.03069293312728405, -0.029063433408737183, -0.027433931827545166, -0.025804433971643448, -0.02417493425309658, -0.022545432671904564, -0.020915932953357697, -0.01928643137216568, -0.017656931653618813, -0.016027431935071945, -0.014397931285202503, -0.012768430635333061, -0.01113892998546362, -0.009509429335594177, -0.00787992961704731, -0.006250428967177868, -0.004620928317308426, -0.0029914285987615585, -0.0013619279488921165, 0.00026757270097732544, 0.0018970731180161238, 0.003526573535054922, 0.005156073719263077, 0.006785574369132519, 0.00841507501900196, 0.010044574737548828, 0.01167407538741827, 0.013303576037287712, 0.014933076687157154, 0.016562577337026596, 0.018192077055573463, 0.01982157677412033, 0.021451078355312347, 0.023080578073859215, 0.024710077792406082, 0.0263395793735981, 0.027969079092144966, 0.029598580673336983, 0.03122808039188385, 0.03285758197307587, 0.03448708355426788, 0.0361165814101696, 0.03774608299136162, 0.039375580847263336, 0.04100508242845535, 0.04263458028435707, 0.04426408186554909, 0.045893583446741104, 0.04752308130264282, 0.04915258288383484, 0.050782084465026855, 0.05241158604621887]}, "gradients/roberta.encoder.layer.7.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 6.0, 19.0, 86.0, 2433.0, 3446.0, 105.0, 15.0, 9.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.05621667951345444, -0.05446391925215721, -0.05271115526556969, -0.05095839500427246, -0.049205631017684937, -0.04745287075638771, -0.045700106769800186, -0.04394734650850296, -0.042194582521915436, -0.04044182226061821, -0.038689058274030685, -0.03693629801273346, -0.035183534026145935, -0.03343077376484871, -0.031678009778261185, -0.02992524951696396, -0.028172487393021584, -0.02641972526907921, -0.024666963145136833, -0.022914201021194458, -0.021161438897252083, -0.019408676773309708, -0.01765591651201248, -0.015903152525424957, -0.014150391332805157, -0.012397629208862782, -0.010644867084920406, -0.008892105892300606, -0.007139343302696943, -0.005386581644415855, -0.0036338195204734802, -0.001881057396531105, -0.00012829527258872986, 0.0016244667349383235, 0.003377228742465377, 0.005129990633577108, 0.0068827527575194836, 0.008635514415800571, 0.010388276539742947, 0.012141038663685322, 0.013893800787627697, 0.015646561980247498, 0.017399324104189873, 0.019152086228132248, 0.020904848352074623, 0.022657610476017, 0.024410372599959373, 0.02616313472390175, 0.027915896847844124, 0.0296686589717865, 0.031421419233083725, 0.03317418321967125, 0.034926943480968475, 0.036679707467556, 0.038432467728853226, 0.04018523171544075, 0.041937991976737976, 0.0436907522380352, 0.045443516224622726, 0.04719627648591995, 0.04894904047250748, 0.0507018007338047, 0.05245456472039223, 0.05420732498168945, 0.05596008896827698]}, "gradients/roberta.encoder.layer.7.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 4.0, 7.0, 4.0, 8.0, 6.0, 17.0, 9.0, 14.0, 32.0, 56.0, 86.0, 153.0, 287.0, 839.0, 2308.0, 1393.0, 448.0, 203.0, 99.0, 47.0, 30.0, 15.0, 12.0, 12.0, 8.0, 6.0, 4.0, 4.0, 6.0, 2.0, 3.0, 2.0, 3.0, 2.0, 0.0, 4.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.025701317936182022, -0.024864928796887398, -0.024028539657592773, -0.0231921523809433, -0.022355763241648674, -0.02151937410235405, -0.020682986825704575, -0.01984659768640995, -0.019010208547115326, -0.0181738194078207, -0.017337430268526077, -0.016501042991876602, -0.015664653852581978, -0.014828264713287354, -0.013991876505315304, -0.013155488297343254, -0.01231909915804863, -0.011482710018754005, -0.010646321810781956, -0.009809933602809906, -0.008973544463515282, -0.008137155324220657, -0.007300767116248608, -0.006464378442615271, -0.005627989768981934, -0.004791601095348597, -0.0039552124217152596, -0.0031188237480819225, -0.0022824350744485855, -0.0014460464008152485, -0.0006096577271819115, 0.00022673094645142555, 0.0010631196200847626, 0.0018995082937180996, 0.0027358969673514366, 0.0035722856409847736, 0.004408674314618111, 0.005245062988251448, 0.006081451661884785, 0.006917840335518122, 0.007754229009151459, 0.008590618148446083, 0.009427006356418133, 0.010263394564390182, 0.011099783703684807, 0.011936172842979431, 0.01277256105095148, 0.01360894925892353, 0.014445338398218155, 0.01528172753751278, 0.016118116676807404, 0.01695450395345688, 0.017790893092751503, 0.018627282232046127, 0.019463669508695602, 0.020300058647990227, 0.02113644778728485, 0.021972836926579475, 0.0228092260658741, 0.023645613342523575, 0.0244820024818182, 0.025318391621112823, 0.0261547788977623, 0.026991168037056923, 0.027827557176351547]}, "gradients/roberta.encoder.layer.7.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 8.0, 10.0, 20.0, 724.0, 4955.0, 374.0, 27.0, 7.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06255625933408737, -0.060427770018577576, -0.05829928070306778, -0.05617079138755798, -0.05404230207204819, -0.05191381275653839, -0.04978532716631889, -0.0476568378508091, -0.0455283485352993, -0.043399859219789505, -0.04127136990427971, -0.03914288058876991, -0.037014394998550415, -0.03488590568304062, -0.03275741636753082, -0.030628927052021027, -0.02850043773651123, -0.026371948421001434, -0.024243459105491638, -0.02211497165262699, -0.019986482337117195, -0.0178579930216074, -0.015729505568742752, -0.013601016253232956, -0.01147252693772316, -0.009344037622213364, -0.007215549238026142, -0.005087060388177633, -0.0029585715383291245, -0.0008300822228193283, 0.0012984061613678932, 0.0034268945455551147, 0.005555391311645508, 0.007683880161494017, 0.009812369011342525, 0.011940857395529747, 0.014069346711039543, 0.01619783602654934, 0.018326323479413986, 0.020454812794923782, 0.02258330211043358, 0.024711791425943375, 0.02684028074145317, 0.028968768194317818, 0.031097257509827614, 0.03322574496269226, 0.03535423427820206, 0.03748272359371185, 0.03961121290922165, 0.041739702224731445, 0.04386819154024124, 0.04599668085575104, 0.048125170171260834, 0.05025365948677063, 0.05238214507699013, 0.054510634392499924, 0.05663912370800972, 0.058767613023519516, 0.06089610233902931, 0.06302458792924881, 0.0651530772447586, 0.0672815665602684, 0.0694100558757782, 0.071538545191288, 0.07366703450679779]}, "gradients/roberta.encoder.layer.6.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 6.0, 2.0, 7.0, 7.0, 14.0, 23.0, 25.0, 30.0, 52.0, 62.0, 63.0, 101.0, 103.0, 142.0, 188.0, 262.0, 311.0, 353.0, 499.0, 525.0, 533.0, 541.0, 464.0, 388.0, 277.0, 244.0, 188.0, 158.0, 119.0, 106.0, 75.0, 67.0, 50.0, 38.0, 28.0, 14.0, 22.0, 15.0, 7.0, 1.0, 5.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0], "bins": [-0.03225419670343399, -0.03129514306783676, -0.03033609315752983, -0.029377039521932602, -0.028417987748980522, -0.027458935976028442, -0.026499884203076363, -0.025540832430124283, -0.024581778794527054, -0.023622727021574974, -0.022663675248622894, -0.021704621613025665, -0.020745569840073586, -0.019786518067121506, -0.018827466294169426, -0.017868414521217346, -0.016909362748265266, -0.015950310975313187, -0.014991258271038532, -0.014032206498086452, -0.013073153793811798, -0.012114102020859718, -0.011155050247907639, -0.010195998474955559, -0.009236945770680904, -0.008277893997728825, -0.00731884129345417, -0.0063597895205020905, -0.005400737281888723, -0.004441685043275356, -0.0034826332703232765, -0.0025235810317099094, -0.0015645269304513931, -0.0006054748082533479, 0.0003535773139446974, 0.0013126293197274208, 0.002271681558340788, 0.003230733796954155, 0.004189785569906235, 0.005148837808519602, 0.006107890047132969, 0.007066942285746336, 0.008025994524359703, 0.008985046297311783, 0.009944098070263863, 0.010903150774538517, 0.011862202547490597, 0.012821255251765251, 0.013780307024717331, 0.01473935879766941, 0.01569841057062149, 0.01665746420621872, 0.0176165159791708, 0.01857556775212288, 0.01953461952507496, 0.02049367129802704, 0.021452724933624268, 0.022411776706576347, 0.023370828479528427, 0.024329882115125656, 0.025288933888077736, 0.026247985661029816, 0.027207037433981895, 0.028166089206933975, 0.029125140979886055]}, "gradients/roberta.encoder.layer.6.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 5.0, 4.0, 13.0, 5739.0, 359.0, 9.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0226149819791317, -0.01930517703294754, -0.015995372086763382, -0.012685568071901798, -0.00937576312571764, -0.006065959110856056, -0.002756154164671898, 0.0005536507815122604, 0.0038634557276964188, 0.007173260673880577, 0.010483065620064735, 0.013792869634926319, 0.017102673649787903, 0.02041247859597206, 0.02372228354215622, 0.027032088488340378, 0.030341893434524536, 0.033651698380708694, 0.03696150332689285, 0.04027130827307701, 0.04358111321926117, 0.04689091444015503, 0.050200723111629486, 0.053510524332523346, 0.0568203330039978, 0.06013013795018196, 0.06343994289636612, 0.06674974411725998, 0.07005955278873444, 0.0733693540096283, 0.07667916268110275, 0.07998896390199661, 0.08329876512289047, 0.08660856634378433, 0.08991837501525879, 0.09322817623615265, 0.0965379849076271, 0.09984778612852097, 0.10315759479999542, 0.10646739602088928, 0.10977720469236374, 0.1130870059132576, 0.11639681458473206, 0.11970661580562592, 0.12301642447710037, 0.12632623314857483, 0.1296360343694687, 0.13294583559036255, 0.1362556368112564, 0.13956543803215027, 0.14287523925304413, 0.14618505537509918, 0.14949485659599304, 0.1528046578168869, 0.15611445903778076, 0.15942427515983582, 0.16273407638072968, 0.16604387760162354, 0.1693536788225174, 0.17266349494457245, 0.1759732961654663, 0.17928309738636017, 0.18259289860725403, 0.18590271472930908, 0.18921251595020294]}, "gradients/roberta.encoder.layer.6.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 4.0, 4.0, 12.0, 14.0, 21.0, 26.0, 36.0, 75.0, 98.0, 223.0, 446.0, 823.0, 1339.0, 1291.0, 822.0, 391.0, 185.0, 112.0, 67.0, 40.0, 31.0, 21.0, 12.0, 6.0, 9.0, 5.0, 4.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.014312975108623505, -0.013850142247974873, -0.013387308456003666, -0.012924475595355034, -0.012461641803383827, -0.011998808942735195, -0.011535976082086563, -0.011073142290115356, -0.010610309429466724, -0.010147476568818092, -0.009684642776846886, -0.009221809916198254, -0.008758977055549622, -0.008296143263578415, -0.007833310402929783, -0.0073704770766198635, -0.006907643750309944, -0.006444810424000025, -0.0059819770976901054, -0.005519144237041473, -0.005056310910731554, -0.004593477584421635, -0.004130644723773003, -0.0036678113974630833, -0.003204978071153164, -0.0027421447448432446, -0.002279311651363969, -0.0018164784414693713, -0.0013536452315747738, -0.0008908119052648544, -0.00042797881178557873, 3.4854281693696976e-05, 0.000497688539326191, 0.0009605217492207885, 0.001423354959115386, 0.0018861881690099835, 0.002349021378904581, 0.0028118547052145004, 0.003274687798693776, 0.003737520892173052, 0.004200354218482971, 0.0046631875447928905, 0.00512602087110281, 0.005588853731751442, 0.006051687058061361, 0.006514520384371281, 0.006977353245019913, 0.007440186571329832, 0.007903019897639751, 0.008365852758288383, 0.00882868655025959, 0.009291519410908222, 0.009754352271556854, 0.010217186063528061, 0.010680018924176693, 0.011142851784825325, 0.011605685576796532, 0.012068518437445164, 0.01253135222941637, 0.012994185090065002, 0.013457018882036209, 0.013919851742684841, 0.014382684603333473, 0.01484551839530468, 0.015308351255953312]}, "gradients/roberta.encoder.layer.6.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 12.0, 21.0, 597.0, 4596.0, 846.0, 34.0, 19.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.032781582325696945, -0.03170863538980484, -0.030635686591267586, -0.02956273779273033, -0.028489790856838226, -0.027416842058300972, -0.026343893259763718, -0.025270946323871613, -0.024197997525334358, -0.023125048726797104, -0.022052101790905, -0.020979152992367744, -0.01990620419383049, -0.018833257257938385, -0.01776030845940113, -0.016687359660863876, -0.015614412724971771, -0.014541464857757092, -0.013468516990542412, -0.012395568192005157, -0.011322620324790478, -0.010249672457575798, -0.009176723659038544, -0.008103775791823864, -0.007030827924609184, -0.0059578800573945045, -0.0048849317245185375, -0.003811983624473214, -0.0027390355244278908, -0.001666087657213211, -0.000593139324337244, 0.000479809008538723, 0.0015527531504631042, 0.0026257012505084276, 0.003698649350553751, 0.004771597683429718, 0.005844545550644398, 0.0069174934178590775, 0.007990442216396332, 0.009063390083611012, 0.010136337950825691, 0.011209285818040371, 0.01228223368525505, 0.013355182483792305, 0.014428130351006985, 0.015501078218221664, 0.01657402701675892, 0.017646975815296173, 0.018719922751188278, 0.019792871549725533, 0.020865818485617638, 0.021938767284154892, 0.023011714220046997, 0.02408466301858425, 0.025157611817121506, 0.02623055875301361, 0.027303507551550865, 0.02837645635008812, 0.029449403285980225, 0.03052235208451748, 0.03159530088305473, 0.03266824781894684, 0.033741194754838943, 0.03481414541602135, 0.03588709235191345]}, "gradients/roberta.encoder.layer.5.attention.self.value.lora_B": {"_type": "histogram", "values": [2.0, 3.0, 1.0, 2.0, 1.0, 5.0, 5.0, 6.0, 7.0, 10.0, 15.0, 16.0, 20.0, 21.0, 23.0, 36.0, 51.0, 74.0, 71.0, 98.0, 118.0, 154.0, 182.0, 234.0, 271.0, 329.0, 413.0, 445.0, 453.0, 445.0, 440.0, 408.0, 348.0, 266.0, 241.0, 195.0, 146.0, 124.0, 100.0, 82.0, 61.0, 52.0, 35.0, 26.0, 24.0, 15.0, 17.0, 9.0, 8.0, 11.0, 5.0, 8.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.037631258368492126, -0.03633389249444008, -0.03503652289509773, -0.033739157021045685, -0.03244178742170334, -0.03114442154765129, -0.029847053810954094, -0.028549686074256897, -0.0272523183375597, -0.025954950600862503, -0.024657582864165306, -0.02336021512746811, -0.02206284925341606, -0.020765479654073715, -0.019468113780021667, -0.01817074604332447, -0.016873378306627274, -0.015576010569930077, -0.01427864283323288, -0.012981276027858257, -0.01168390829116106, -0.010386540554463863, -0.009089173749089241, -0.007791806012392044, -0.006494438275694847, -0.00519707053899765, -0.0038997032679617405, -0.002602335764095187, -0.0013049682602286339, -7.60052353143692e-06, 0.0012897667475044727, 0.0025871340185403824, 0.003884498029947281, 0.005181865766644478, 0.0064792330376803875, 0.007776600308716297, 0.009073968045413494, 0.010371335782110691, 0.011668702587485313, 0.01296607032418251, 0.014263438060879707, 0.015560805797576904, 0.0168581735342741, 0.018155541270971298, 0.019452907145023346, 0.020750276744365692, 0.02204764261841774, 0.023345010355114937, 0.024642378091812134, 0.02593974582850933, 0.027237113565206528, 0.028534481301903725, 0.02983184903860092, 0.03112921491265297, 0.032426584511995316, 0.03372395038604736, 0.03502131998538971, 0.03631868585944176, 0.0376160554587841, 0.03891342133283615, 0.0402107909321785, 0.041508156806230545, 0.04280552640557289, 0.04410289227962494, 0.04540025815367699]}, "gradients/roberta.encoder.layer.5.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 1.0, 15.0, 3155.0, 2941.0, 13.0, 2.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11368479579687119, -0.11061165481805801, -0.10753851383924484, -0.10446537286043167, -0.1013922318816185, -0.09831909090280533, -0.09524594992399216, -0.09217280894517899, -0.08909966796636581, -0.08602652698755264, -0.08295338600873947, -0.0798802450299263, -0.07680710405111313, -0.07373396307229996, -0.07066082209348679, -0.06758768111467361, -0.06451454013586044, -0.06144139915704727, -0.0583682581782341, -0.05529511719942093, -0.05222197622060776, -0.049148835241794586, -0.046075694262981415, -0.04300255328416824, -0.03992941230535507, -0.0368562713265419, -0.03378313034772873, -0.030709989368915558, -0.027636848390102386, -0.024563707411289215, -0.021490566432476044, -0.018417425453662872, -0.015344277024269104, -0.012271136045455933, -0.009197995066642761, -0.00612485408782959, -0.0030517131090164185, 2.142786979675293e-05, 0.0030945688486099243, 0.006167709827423096, 0.009240850806236267, 0.012313991785049438, 0.01538713276386261, 0.01846027374267578, 0.021533414721488953, 0.024606555700302124, 0.027679696679115295, 0.030752837657928467, 0.03382597863674164, 0.03689911961555481, 0.03997226059436798, 0.04304540157318115, 0.046118542551994324, 0.049191683530807495, 0.052264824509620667, 0.05533796548843384, 0.05841110646724701, 0.06148424744606018, 0.06455738842487335, 0.06763052940368652, 0.0707036703824997, 0.07377681136131287, 0.07684995234012604, 0.07992309331893921, 0.08299623429775238]}, "gradients/roberta.encoder.layer.5.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 7.0, 7.0, 16.0, 15.0, 43.0, 47.0, 118.0, 232.0, 511.0, 1417.0, 1909.0, 1006.0, 391.0, 175.0, 102.0, 43.0, 28.0, 14.0, 16.0, 6.0, 3.0, 5.0, 1.0, 2.0, 5.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.012942452915012836, -0.012409893795847893, -0.011877333745360374, -0.011344773694872856, -0.010812214575707912, -0.010279655456542969, -0.00974709540605545, -0.009214535355567932, -0.008681976236402988, -0.008149417117238045, -0.007616857066750526, -0.007084297481924295, -0.006551737897098064, -0.006019178312271833, -0.005486618727445602, -0.004954059142619371, -0.00442149955779314, -0.0038889399729669094, -0.0033563803881406784, -0.0028238208033144474, -0.0022912612184882164, -0.0017587016336619854, -0.0012261420488357544, -0.0006935824640095234, -0.0001610228791832924, 0.0003715367056429386, 0.0009040962904691696, 0.0014366558752954006, 0.0019692154601216316, 0.0025017750449478626, 0.0030343346297740936, 0.0035668942146003246, 0.004099452868103981, 0.004632012452930212, 0.005164572037756443, 0.005697131622582674, 0.006229691207408905, 0.006762250792235136, 0.007294810377061367, 0.00782736949622631, 0.008359929546713829, 0.008892489597201347, 0.009425048716366291, 0.009957607835531235, 0.010490167886018753, 0.011022727936506271, 0.011555287055671215, 0.012087846174836159, 0.012620406225323677, 0.013152966275811195, 0.013685525394976139, 0.014218084514141083, 0.014750644564628601, 0.01528320461511612, 0.015815764665603638, 0.016348322853446007, 0.016880882903933525, 0.017413442954421043, 0.017946001142263412, 0.01847856119275093, 0.01901112124323845, 0.019543681293725967, 0.020076241344213486, 0.020608799532055855, 0.021141359582543373]}, "gradients/roberta.encoder.layer.5.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 12.0, 33.0, 487.0, 4816.0, 724.0, 38.0, 11.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03894590586423874, -0.037748903036117554, -0.03655190393328667, -0.03535490110516548, -0.034157902002334595, -0.03296089917421341, -0.03176390007138252, -0.030566897243261337, -0.0293698962777853, -0.028172895312309265, -0.02697589434683323, -0.025778893381357193, -0.024581890553236008, -0.02338489145040512, -0.022187888622283936, -0.0209908876568079, -0.019793886691331863, -0.018596885725855827, -0.01739988476037979, -0.016202883794903755, -0.015005881898105145, -0.013808880932629108, -0.012611879035830498, -0.011414878070354462, -0.010217877104878426, -0.00902087613940239, -0.007823875173926353, -0.006626873277127743, -0.005429872311651707, -0.004232871346175671, -0.0030358699150383472, -0.0018388684839010239, -0.0006418675184249878, 0.0005551336798816919, 0.0017521348781883717, 0.0029491360764950514, 0.004146137274801731, 0.005343138240277767, 0.0065401396714150906, 0.007737141102552414, 0.00893414206802845, 0.010131143033504486, 0.011328143998980522, 0.012525145895779133, 0.013722146861255169, 0.014919147826731205, 0.016116149723529816, 0.017313150689005852, 0.018510151654481888, 0.019707152619957924, 0.02090415358543396, 0.022101154550909996, 0.023298155516386032, 0.024495158344507217, 0.025692159309983253, 0.02688916027545929, 0.028086161240935326, 0.02928316220641136, 0.030480163171887398, 0.031677164137363434, 0.03287416696548462, 0.034071166068315506, 0.03526816889643669, 0.03646516799926758, 0.03766217082738876]}, "gradients/roberta.encoder.layer.4.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 3.0, 6.0, 0.0, 5.0, 4.0, 6.0, 11.0, 7.0, 16.0, 20.0, 36.0, 36.0, 42.0, 78.0, 75.0, 107.0, 144.0, 145.0, 171.0, 251.0, 269.0, 340.0, 434.0, 533.0, 623.0, 555.0, 443.0, 333.0, 295.0, 229.0, 172.0, 150.0, 120.0, 114.0, 73.0, 58.0, 47.0, 43.0, 30.0, 26.0, 26.0, 17.0, 9.0, 1.0, 12.0, 2.0, 4.0, 5.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.027220413088798523, -0.026382025331258774, -0.025543635711073875, -0.024705247953534126, -0.023866858333349228, -0.02302847057580948, -0.02219008281826973, -0.02135169319808483, -0.020513303577899933, -0.019674915820360184, -0.018836526200175285, -0.017998138442635536, -0.017159748822450638, -0.01632136106491089, -0.015482972376048565, -0.014644583687186241, -0.013806195929646492, -0.012967807240784168, -0.012129418551921844, -0.011291030794382095, -0.010452641174197197, -0.009614253416657448, -0.008775864727795124, -0.0079374760389328, -0.0070990873500704765, -0.006260698661208153, -0.005422309972345829, -0.0045839217491447926, -0.003745533060282469, -0.002907144371420145, -0.0020687561482191086, -0.0012303674593567848, -0.00039197690784931183, 0.0004464116645976901, 0.001284800237044692, 0.002123188693076372, 0.002961577381938696, 0.0037999660708010197, 0.004638354294002056, 0.00547674298286438, 0.006315131671726704, 0.007153520360589027, 0.007991909049451351, 0.008830297738313675, 0.009668685495853424, 0.010507075116038322, 0.011345462873578072, 0.012183851562440395, 0.013022240251302719, 0.013860628940165043, 0.014699017629027367, 0.015537405386567116, 0.016375795006752014, 0.017214182764291763, 0.018052570521831512, 0.01889096014201641, 0.01972934976220131, 0.02056773751974106, 0.021406127139925957, 0.022244514897465706, 0.023082904517650604, 0.023921292275190353, 0.024759680032730103, 0.025598069652915, 0.02643645741045475]}, "gradients/roberta.encoder.layer.4.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 6.0, 2.0, 15.0, 134.0, 1659.0, 3762.0, 478.0, 51.0, 8.0, 7.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.015949362888932228, -0.014966852031648159, -0.01398434117436409, -0.013001830317080021, -0.012019319459795952, -0.011036808602511883, -0.010054297745227814, -0.009071786887943745, -0.008089276030659676, -0.0071067651733756065, -0.0061242543160915375, -0.005141743458807468, -0.004159232601523399, -0.0031767217442393303, -0.0021942108869552612, -0.0012117000296711922, -0.0002291891723871231, 0.000753321684896946, 0.001735832542181015, 0.002718343399465084, 0.003700854256749153, 0.004683365114033222, 0.005665875971317291, 0.00664838682860136, 0.007630897685885429, 0.008613408543169498, 0.009595919400453568, 0.010578430257737637, 0.011560941115021706, 0.012543451972305775, 0.013525962829589844, 0.014508473686873913, 0.015490982681512833, 0.016473494470119476, 0.01745600439608097, 0.018438514322042465, 0.01942102611064911, 0.020403537899255753, 0.021386047825217247, 0.02236855775117874, 0.023351069539785385, 0.02433358132839203, 0.025316091254353523, 0.026298601180315018, 0.02728111296892166, 0.028263624757528305, 0.0292461346834898, 0.030228644609451294, 0.031211156398057938, 0.03219366818666458, 0.033176176249980927, 0.03415868803858757, 0.035141199827194214, 0.03612371161580086, 0.0371062234044075, 0.038088731467723846, 0.03907124325633049, 0.040053755044937134, 0.04103626310825348, 0.04201877489686012, 0.043001286685466766, 0.04398379847407341, 0.044966310262680054, 0.0459488183259964, 0.04693133011460304]}, "gradients/roberta.encoder.layer.4.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 3.0, 2.0, 3.0, 4.0, 6.0, 6.0, 5.0, 14.0, 15.0, 22.0, 25.0, 57.0, 63.0, 106.0, 150.0, 287.0, 506.0, 884.0, 1212.0, 1057.0, 712.0, 388.0, 234.0, 105.0, 81.0, 50.0, 39.0, 22.0, 17.0, 12.0, 9.0, 5.0, 9.0, 4.0, 5.0, 7.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.008857479318976402, -0.008587165735661983, -0.008316852152347565, -0.008046537637710571, -0.0077762240543961525, -0.007505910471081734, -0.007235596887767315, -0.006965283304452896, -0.00669496925547719, -0.006424655672162771, -0.006154341623187065, -0.005884028039872646, -0.0056137144565582275, -0.0053434004075825214, -0.005073086824268103, -0.0048027727752923965, -0.004532459191977978, -0.004262145608663559, -0.003991831559687853, -0.003721517976373434, -0.0034512041602283716, -0.003180890344083309, -0.0029105767607688904, -0.002640262944623828, -0.0023699491284787655, -0.002099635312333703, -0.0018293216126039624, -0.0015590079128742218, -0.0012886940967291594, -0.001018380280584097, -0.0007480665808543563, -0.00047775288112461567, -0.0002074381336569786, 6.287562428042293e-05, 0.00033318938221782446, 0.000603503140155226, 0.0008738168980926275, 0.00114413071423769, 0.0014144444139674306, 0.0016847581136971712, 0.0019550719298422337, 0.002225385745987296, 0.0024956995621323586, 0.0027660131454467773, 0.00303632696159184, 0.0033066407777369022, 0.003576954361051321, 0.0038472681771963835, 0.004117581993341446, 0.004387895576655865, 0.004658209625631571, 0.00492852320894599, 0.005198837257921696, 0.0054691508412361145, 0.005739464424550533, 0.006009778007864952, 0.006280092056840658, 0.006550405640155077, 0.006820719689130783, 0.007091033272445202, 0.007361346855759621, 0.007631660904735327, 0.007901974953711033, 0.008172288537025452, 0.00844260212033987]}, "gradients/roberta.encoder.layer.4.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 5.0, 20.0, 108.0, 1163.0, 4068.0, 679.0, 64.0, 18.0, 6.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.014917709864675999, -0.01444235723465681, -0.013967005535960197, -0.01349165290594101, -0.013016300275921822, -0.012540947645902634, -0.01206559594720602, -0.011590243317186832, -0.011114891618490219, -0.010639538988471031, -0.010164187289774418, -0.00968883465975523, -0.009213482029736042, -0.008738130331039429, -0.00826277770102024, -0.007787425071001053, -0.007312072440981865, -0.006836720276623964, -0.006361367646604776, -0.005886015482246876, -0.005410662852227688, -0.004935310687869787, -0.004459958523511887, -0.003984605893492699, -0.003509253729134798, -0.0030339013319462538, -0.0025585489347577095, -0.002083196770399809, -0.0016078443732112646, -0.0011324919760227203, -0.0006571398116648197, -0.00018178741447627544, 0.00029356498271226883, 0.0007689173216931522, 0.0012442696606740355, 0.001719621941447258, 0.0021949743386358023, 0.0026703267358243465, 0.003145678900182247, 0.0036210312973707914, 0.004096383694559336, 0.004571735858917236, 0.005047088488936424, 0.005522440653294325, 0.0059977928176522255, 0.006473145447671413, 0.006948497612029314, 0.007423849776387215, 0.007899202406406403, 0.00837455503642559, 0.008849906735122204, 0.009325259365141392, 0.00980061199516058, 0.010275963693857193, 0.010751316323876381, 0.011226668953895569, 0.011702021583914757, 0.012177374213933945, 0.012652725912630558, 0.013128078542649746, 0.013603431172668934, 0.014078782871365547, 0.014554135501384735, 0.015029488131403923, 0.015504839830100536]}, "gradients/roberta.encoder.layer.3.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 4.0, 2.0, 5.0, 7.0, 8.0, 12.0, 10.0, 12.0, 14.0, 37.0, 42.0, 56.0, 39.0, 54.0, 89.0, 105.0, 104.0, 150.0, 207.0, 255.0, 340.0, 610.0, 921.0, 936.0, 540.0, 338.0, 243.0, 223.0, 160.0, 133.0, 103.0, 84.0, 72.0, 48.0, 37.0, 36.0, 20.0, 13.0, 15.0, 15.0, 8.0, 7.0, 1.0, 7.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.03572602942585945, -0.0345323383808136, -0.033338647335767746, -0.03214495629072189, -0.03095126710832119, -0.029757576063275337, -0.028563885018229485, -0.02737019583582878, -0.02617650479078293, -0.024982813745737076, -0.023789122700691223, -0.02259543165564537, -0.021401742473244667, -0.020208051428198814, -0.01901436038315296, -0.01782067120075226, -0.016626978293061256, -0.015433287248015404, -0.014239597134292126, -0.013045906089246273, -0.011852215975522995, -0.010658524930477142, -0.00946483388543129, -0.008271143771708012, -0.007077452726662159, -0.005883762147277594, -0.004690071567893028, -0.0034963805228471756, -0.0023026899434626102, -0.0011089993640780449, 8.469168096780777e-05, 0.0012783817946910858, 0.0024720728397369385, 0.003665763419121504, 0.004859453998506069, 0.006053145043551922, 0.007246835622936487, 0.008440526202321053, 0.009634217247366905, 0.010827907361090183, 0.012021598406136036, 0.013215289451181889, 0.014408979564905167, 0.01560267060995102, 0.016796361654996872, 0.017990052700042725, 0.019183743745088577, 0.02037743292748928, 0.021571123972535133, 0.022764815017580986, 0.02395850606262684, 0.025152195245027542, 0.026345886290073395, 0.027539577335119247, 0.0287332683801651, 0.029926959425210953, 0.031120650470256805, 0.03231434151530266, 0.03350803256034851, 0.03470172360539436, 0.035895414650440216, 0.03708910197019577, 0.03828279674053192, 0.039476484060287476, 0.04067017510533333]}, "gradients/roberta.encoder.layer.3.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 5.0, 5453.0, 664.0, 6.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.10818728059530258, -0.10444199293851852, -0.10069671273231506, -0.096951425075531, -0.09320614486932755, -0.08946085721254349, -0.08571557700634003, -0.08197028934955597, -0.07822500169277191, -0.07447971403598785, -0.0707344338297844, -0.06698914617300034, -0.06324386596679688, -0.05949857831001282, -0.05575329437851906, -0.0520080104470253, -0.04826273024082184, -0.04451744630932808, -0.04077216237783432, -0.03702687472105026, -0.0332815945148468, -0.029536308720707893, -0.025791022926568985, -0.022045738995075226, -0.018300455063581467, -0.014555171132087708, -0.010809886269271374, -0.00706460140645504, -0.003319317474961281, 0.00042596645653247833, 0.004171252250671387, 0.007916536182165146, 0.011661812663078308, 0.015407096594572067, 0.019152380526065826, 0.022897666320204735, 0.026642950251698494, 0.030388234183192253, 0.03413351997733116, 0.03787880390882492, 0.04162408784031868, 0.04536937177181244, 0.0491146557033062, 0.05285993963479996, 0.056605227291584015, 0.060350507497787476, 0.06409579515457153, 0.06784108281135559, 0.07158636301755905, 0.07533165067434311, 0.07907693088054657, 0.08282221853733063, 0.08656749874353409, 0.09031278640031815, 0.0940580666065216, 0.09780335426330566, 0.10154864192008972, 0.10529392957687378, 0.10903920978307724, 0.1127844974398613, 0.11652977764606476, 0.12027506530284882, 0.12402035295963287, 0.12776562571525574, 0.1315109133720398]}, "gradients/roberta.encoder.layer.3.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 6.0, 9.0, 11.0, 13.0, 27.0, 35.0, 57.0, 85.0, 157.0, 260.0, 472.0, 767.0, 1165.0, 1148.0, 767.0, 433.0, 273.0, 162.0, 97.0, 62.0, 42.0, 24.0, 15.0, 8.0, 9.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.010004415176808834, -0.009726504795253277, -0.00944859441369772, -0.009170684032142162, -0.008892773650586605, -0.008614863269031048, -0.00833695288747549, -0.008059042505919933, -0.007781132124364376, -0.007503221742808819, -0.0072253113612532616, -0.006947400979697704, -0.006669490598142147, -0.00639158021658659, -0.0061136698350310326, -0.005835759453475475, -0.005557849071919918, -0.005279938690364361, -0.0050020283088088036, -0.004724117927253246, -0.004446207545697689, -0.004168297164142132, -0.0038903867825865746, -0.0036124764010310173, -0.00333456601947546, -0.003056655637919903, -0.0027787452563643456, -0.0025008348748087883, -0.002222924493253231, -0.0019450141116976738, -0.0016671037301421165, -0.0013891933485865593, -0.0011112825013697147, -0.0008333721198141575, -0.0005554617382586002, -0.000277551356703043, 3.5902485251426697e-07, 0.0002782694064080715, 0.0005561797879636288, 0.000834090169519186, 0.0011120005510747433, 0.0013899109326303005, 0.0016678213141858578, 0.001945731695741415, 0.0022236420772969723, 0.0025015524588525295, 0.0027794628404080868, 0.003057373221963644, 0.0033352836035192013, 0.0036131939850747585, 0.0038911043666303158, 0.004169014748185873, 0.00444692512974143, 0.0047248355112969875, 0.005002745892852545, 0.005280656274408102, 0.005558566655963659, 0.0058364770375192165, 0.006114387419074774, 0.006392297800630331, 0.006670208182185888, 0.0069481185637414455, 0.007226028945297003, 0.00750393932685256, 0.007781849708408117]}, "gradients/roberta.encoder.layer.3.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 31.0, 996.0, 4884.0, 206.0, 11.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.022758159786462784, -0.022006867453455925, -0.021255575120449066, -0.020504284650087357, -0.019752992317080498, -0.01900169998407364, -0.01825040951371193, -0.01749911718070507, -0.01674782484769821, -0.015996532514691353, -0.015245241113007069, -0.014493949711322784, -0.013742657378315926, -0.012991365045309067, -0.012240073643624783, -0.011488782241940498, -0.01073748990893364, -0.00998619757592678, -0.009234906174242496, -0.008483614772558212, -0.0077323224395513535, -0.006981030572205782, -0.00622973870486021, -0.005478446837514639, -0.004727154970169067, -0.003975863102823496, -0.0032245712354779243, -0.002473279368132353, -0.0017219875007867813, -0.0009706956334412098, -0.00021940376609563828, 0.0005318881012499332, 0.0012831781059503555, 0.002034469973295927, 0.0027857618406414986, 0.00353705370798707, 0.004288345575332642, 0.005039637442678213, 0.005790929310023785, 0.006542221177369356, 0.007293513044714928, 0.008044805377721786, 0.00879609677940607, 0.009547388181090355, 0.010298680514097214, 0.011049972847104073, 0.011801264248788357, 0.012552555650472641, 0.0133038479834795, 0.014055140316486359, 0.014806431718170643, 0.015557723119854927, 0.016309015452861786, 0.017060307785868645, 0.017811600118875504, 0.018562890589237213, 0.019314182922244072, 0.02006547525525093, 0.02081676572561264, 0.0215680580586195, 0.022319350391626358, 0.023070642724633217, 0.023821935057640076, 0.024573225528001785, 0.025324517861008644]}, "gradients/roberta.encoder.layer.2.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 4.0, 1.0, 0.0, 1.0, 2.0, 2.0, 6.0, 3.0, 8.0, 6.0, 16.0, 9.0, 11.0, 16.0, 26.0, 28.0, 37.0, 39.0, 58.0, 82.0, 98.0, 115.0, 139.0, 174.0, 231.0, 285.0, 360.0, 402.0, 430.0, 473.0, 465.0, 408.0, 438.0, 334.0, 308.0, 267.0, 162.0, 159.0, 114.0, 81.0, 95.0, 58.0, 48.0, 28.0, 39.0, 20.0, 13.0, 13.0, 8.0, 8.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0], "bins": [-0.033770326524972916, -0.032834023237228394, -0.03189772367477417, -0.030961420387029648, -0.030025117099285126, -0.029088813811540604, -0.02815251238644123, -0.027216210961341858, -0.026279907673597336, -0.025343604385852814, -0.02440730296075344, -0.023471001535654068, -0.022534698247909546, -0.021598394960165024, -0.02066209353506565, -0.019725792109966278, -0.018789488822221756, -0.017853185534477234, -0.01691688410937786, -0.015980582684278488, -0.015044279396533966, -0.014107977040112019, -0.013171674683690071, -0.012235372327268124, -0.011299069970846176, -0.010362767614424229, -0.009426465258002281, -0.008490162901580334, -0.007553860545158386, -0.006617558188736439, -0.005681255832314491, -0.004744953475892544, -0.0038086529821157455, -0.002872350625693798, -0.0019360482692718506, -0.000999745912849903, -6.344355642795563e-05, 0.0008728587999939919, 0.0018091611564159393, 0.002745463512837887, 0.0036817658692598343, 0.004618068225681782, 0.005554370582103729, 0.006490672938525677, 0.007426975294947624, 0.008363277651369572, 0.00929958000779152, 0.010235882364213467, 0.011172184720635414, 0.012108487077057362, 0.013044789433479309, 0.013981091789901257, 0.014917394146323204, 0.015853695571422577, 0.0167899988591671, 0.01772630214691162, 0.018662603572010994, 0.019598904997110367, 0.02053520828485489, 0.02147151157259941, 0.022407812997698784, 0.023344114422798157, 0.02428041771054268, 0.0252167209982872, 0.026153022423386574]}, "gradients/roberta.encoder.layer.2.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 21.0, 6073.0, 33.0, 0.0, 1.0, 0.0, 0.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.09536660462617874, -0.09234477579593658, -0.08932294696569443, -0.08630111813545227, -0.08327929675579071, -0.08025746792554855, -0.0772356390953064, -0.07421381026506424, -0.07119198143482208, -0.06817015260457993, -0.06514832377433777, -0.06212649866938591, -0.05910466983914375, -0.056082841008901596, -0.05306101590394974, -0.05003918707370758, -0.047017358243465424, -0.04399552941322327, -0.04097370058298111, -0.03795187547802925, -0.034930046647787094, -0.03190821781754494, -0.02888639084994793, -0.02586456388235092, -0.022842735052108765, -0.019820906221866608, -0.0167990792542696, -0.013777251355350018, -0.010755423456430435, -0.007733595557510853, -0.0047117676585912704, -0.0016899406909942627, 0.0013318955898284912, 0.004353723488748074, 0.007375551387667656, 0.010397379286587238, 0.01341920718550682, 0.016441036015748978, 0.019462862983345985, 0.022484689950942993, 0.02550651878118515, 0.028528347611427307, 0.031550176441669464, 0.03457200154662132, 0.03759383037686348, 0.04061565920710564, 0.043637484312057495, 0.04665931314229965, 0.04968114197254181, 0.052702970802783966, 0.05572479963302612, 0.05874662473797798, 0.06176845356822014, 0.064790278673172, 0.06781210750341415, 0.07083393633365631, 0.07385576516389847, 0.07687759399414062, 0.07989942282438278, 0.08292125165462494, 0.0859430730342865, 0.08896490186452866, 0.09198673069477081, 0.09500855952501297, 0.09803038835525513]}, "gradients/roberta.encoder.layer.2.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 9.0, 4.0, 16.0, 22.0, 36.0, 70.0, 131.0, 491.0, 1565.0, 2488.0, 844.0, 260.0, 83.0, 42.0, 21.0, 10.0, 4.0, 6.0, 4.0, 3.0, 0.0, 3.0, 5.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.012815428897738457, -0.012345295399427414, -0.011875161901116371, -0.011405028402805328, -0.010934894904494286, -0.010464761406183243, -0.0099946279078722, -0.009524494409561157, -0.009054360911250114, -0.008584227412939072, -0.008114093914628029, -0.007643960416316986, -0.007173826918005943, -0.0067036934196949005, -0.006233560387045145, -0.005763426888734102, -0.005293293856084347, -0.004823160357773304, -0.004353026859462261, -0.003882893593981862, -0.0034127600956708193, -0.0029426265973597765, -0.0024724933318793774, -0.0020023598335683346, -0.0015322263352572918, -0.001062092836946249, -0.000591959455050528, -0.00012182607315480709, 0.0003483074251562357, 0.0008184409234672785, 0.0012885741889476776, 0.0017587076872587204, 0.002228841185569763, 0.002698974683880806, 0.0031691081821918488, 0.003639241447672248, 0.004109375178813934, 0.004579508677124977, 0.005049641709774733, 0.005519775208085775, 0.005989908706396818, 0.006460042204707861, 0.006930175703018904, 0.007400308735668659, 0.007870442233979702, 0.008340575732290745, 0.008810709230601788, 0.00928084272891283, 0.009750976227223873, 0.010221109725534916, 0.010691243223845959, 0.011161376722157001, 0.011631510220468044, 0.012101643718779087, 0.012571776285767555, 0.013041909784078598, 0.01351204328238964, 0.013982176780700684, 0.014452310279011726, 0.01492244377732277, 0.015392577275633812, 0.015862710773944855, 0.016332844272255898, 0.01680297777056694, 0.017273111268877983]}, "gradients/roberta.encoder.layer.2.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 5.0, 24.0, 115.0, 1137.0, 4367.0, 413.0, 55.0, 14.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05518719181418419, -0.053623899817466736, -0.05206060782074928, -0.05049731582403183, -0.04893402382731438, -0.047370731830596924, -0.04580744355916977, -0.04424414783716202, -0.04268085956573486, -0.04111756756901741, -0.03955427557229996, -0.037990983575582504, -0.03642769157886505, -0.0348643995821476, -0.033301107585430145, -0.03173781931400299, -0.03017452359199524, -0.028611231595277786, -0.027047939598560333, -0.02548464760184288, -0.023921355605125427, -0.022358063608407974, -0.02079477347433567, -0.019231481477618217, -0.017668189480900764, -0.01610489748418331, -0.014541605487465858, -0.01297831442207098, -0.011415022425353527, -0.009851730428636074, -0.008288439363241196, -0.006725147366523743, -0.005161859095096588, -0.003598567331209779, -0.0020352755673229694, -0.00047198403626680374, 0.0010913079604506493, 0.0026545999571681023, 0.004217891022562981, 0.005781183019280434, 0.007344475015997887, 0.00890776701271534, 0.010471059009432793, 0.012034350074827671, 0.013597642071545124, 0.015160934068262577, 0.016724225133657455, 0.01828751713037491, 0.01985080912709236, 0.021414101123809814, 0.022977393120527267, 0.02454068511724472, 0.026103977113962173, 0.027667269110679626, 0.02923055924475193, 0.030793851241469383, 0.03235714137554169, 0.03392043337225914, 0.03548372536897659, 0.037047017365694046, 0.0386103093624115, 0.04017360135912895, 0.041736893355846405, 0.04330018162727356, 0.04486347734928131]}, "gradients/roberta.encoder.layer.1.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 1.0, 1.0, 6.0, 5.0, 6.0, 5.0, 12.0, 12.0, 15.0, 20.0, 26.0, 36.0, 41.0, 72.0, 69.0, 113.0, 138.0, 187.0, 334.0, 393.0, 559.0, 743.0, 782.0, 683.0, 528.0, 342.0, 263.0, 211.0, 161.0, 108.0, 74.0, 40.0, 29.0, 23.0, 14.0, 13.0, 18.0, 6.0, 9.0, 9.0, 4.0, 4.0, 2.0, 4.0, 2.0, 5.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.025392651557922363, -0.024676209315657616, -0.023959767073392868, -0.02324332483112812, -0.022526882588863373, -0.021810442209243774, -0.021093998104333878, -0.02037755772471428, -0.01966111548244953, -0.018944673240184784, -0.018228230997920036, -0.01751178875565529, -0.01679534651339054, -0.016078904271125793, -0.01536246296018362, -0.014646021649241447, -0.013929578475654125, -0.013213136233389378, -0.01249669399112463, -0.011780252680182457, -0.01106381043791771, -0.010347368195652962, -0.009630925953388214, -0.008914483711123466, -0.008198041468858719, -0.007481599226593971, -0.006765157449990511, -0.006048715207725763, -0.005332273431122303, -0.004615831188857555, -0.0038993889465928078, -0.0031829471699893475, -0.002466505393385887, -0.0017500633839517832, -0.0010336212581023574, -0.0003171791322529316, 0.00039926287718117237, 0.0011157048866152763, 0.001832147128880024, 0.0025485889054834843, 0.003265031147748232, 0.0039814733900129795, 0.00469791516661644, 0.0054143574088811874, 0.006130799651145935, 0.006847241427749395, 0.007563683670014143, 0.008280125446617603, 0.008996567688882351, 0.009713009931147099, 0.010429452173411846, 0.01114589348435402, 0.011862335726618767, 0.012578777968883514, 0.013295220211148262, 0.01401166245341301, 0.014728104695677757, 0.015444546937942505, 0.016160989180207253, 0.016877431422472, 0.017593873664736748, 0.018310315907001495, 0.019026756286621094, 0.01974319852888584, 0.02045964077115059]}, "gradients/roberta.encoder.layer.1.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 5.0, 34.0, 6066.0, 23.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.10567837953567505, -0.10261434316635132, -0.09955031424760818, -0.09648627787828445, -0.09342224150896072, -0.09035821259021759, -0.08729417622089386, -0.08423013985157013, -0.0811661034822464, -0.07810206711292267, -0.07503803819417953, -0.0719740018248558, -0.06890996545553207, -0.06584593653678894, -0.06278190016746521, -0.05971786379814148, -0.056653834879398346, -0.053589802235364914, -0.050525765866041183, -0.04746173322200775, -0.04439769685268402, -0.04133366420865059, -0.03826963156461716, -0.035205595195293427, -0.032141562551259995, -0.029077528044581413, -0.026013493537902832, -0.0229494608938694, -0.01988542638719082, -0.016821391880512238, -0.013757359236478806, -0.010693324729800224, -0.007629290223121643, -0.004565256182104349, -0.0015012221410870552, 0.0015628114342689514, 0.004626845940947533, 0.007690880447626114, 0.010754913091659546, 0.013818947598338127, 0.01688298210501671, 0.01994701661169529, 0.02301105111837387, 0.026075083762407303, 0.029139118269085884, 0.032203152775764465, 0.0352671854197979, 0.03833121806383133, 0.04139525443315506, 0.04445928707718849, 0.04752332344651222, 0.050587356090545654, 0.053651392459869385, 0.05671542510390282, 0.05977945774793625, 0.06284349411725998, 0.06590752303600311, 0.06897155940532684, 0.07203558832406998, 0.07509962469339371, 0.07816366106271744, 0.08122768998146057, 0.0842917263507843, 0.08735576272010803, 0.09041979908943176]}, "gradients/roberta.encoder.layer.1.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 6.0, 2.0, 10.0, 17.0, 28.0, 42.0, 80.0, 241.0, 473.0, 1023.0, 1886.0, 1251.0, 554.0, 266.0, 106.0, 54.0, 29.0, 25.0, 6.0, 5.0, 6.0, 6.0, 3.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.009608532302081585, -0.009272625669836998, -0.008936719968914986, -0.008600813336670399, -0.008264906704425812, -0.007929000072181225, -0.007593093905597925, -0.0072571877390146255, -0.006921281106770039, -0.006585374474525452, -0.006249468307942152, -0.005913562141358852, -0.0055776555091142654, -0.0052417488768696785, -0.004905842710286379, -0.004569936543703079, -0.004234029911458492, -0.003898123512044549, -0.0035622171126306057, -0.0032263107132166624, -0.002890404313802719, -0.002554497914388776, -0.0022185915149748325, -0.0018826851155608892, -0.001546778716146946, -0.0012108723167330027, -0.0008749659173190594, -0.0005390595179051161, -0.0002031531184911728, 0.0001327532809227705, 0.0004686596803367138, 0.0008045660797506571, 0.001140473410487175, 0.0014763798099011183, 0.0018122862093150616, 0.002148192608729005, 0.002484099008142948, 0.0028200054075568914, 0.0031559118069708347, 0.003491818206384778, 0.0038277246057987213, 0.004163631238043308, 0.004499537404626608, 0.0048354435712099075, 0.0051713502034544945, 0.005507256835699081, 0.005843163002282381, 0.006179069168865681, 0.006514975801110268, 0.006850882433354855, 0.007186788599938154, 0.007522694766521454, 0.00785860139876604, 0.008194508031010628, 0.00853041373193264, 0.008866320364177227, 0.009202226996421814, 0.009538133628666401, 0.009874040260910988, 0.010209945961833, 0.010545852594077587, 0.010881759226322174, 0.011217664927244186, 0.011553571559488773, 0.01188947819173336]}, "gradients/roberta.encoder.layer.1.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 6.0, 9.0, 51.0, 179.0, 579.0, 1561.0, 2046.0, 1158.0, 354.0, 126.0, 43.0, 15.0, 1.0, 4.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.009913640096783638, -0.00967369507998228, -0.009433749131858349, -0.009193804115056992, -0.008953859098255634, -0.008713914081454277, -0.008473968133330345, -0.008234023116528988, -0.00799407809972763, -0.007754132617264986, -0.007514187600463629, -0.007274242118000984, -0.007034297101199627, -0.006794351618736982, -0.006554406136274338, -0.0063144611194729805, -0.006074515637010336, -0.005834570154547691, -0.005594625137746334, -0.0053546796552836895, -0.005114734638482332, -0.004874789156019688, -0.00463484413921833, -0.004394898656755686, -0.004154953174293041, -0.003915007691830397, -0.0036750626750290394, -0.003435117192566395, -0.0031951721757650375, -0.002955226693302393, -0.002715281443670392, -0.002475336194038391, -0.002235391642898321, -0.0019954463932663202, -0.0017555011436343193, -0.0015155557775869966, -0.0012756105279549956, -0.0010356652783229947, -0.000795719912275672, -0.000555774662643671, -0.0003158294130116701, -7.588413427583873e-05, 0.00016406114445999265, 0.0004040064522996545, 0.0006439517019316554, 0.0008838969515636563, 0.001123842317610979, 0.00136378756724298, 0.001603732816874981, 0.0018436780665069818, 0.0020836233161389828, 0.0023235687986016273, 0.0025635138154029846, 0.002803459297865629, 0.00304340454749763, 0.003283349797129631, 0.003523295046761632, 0.003763240296393633, 0.0040031857788562775, 0.004243130795657635, 0.004483076278120279, 0.004723021294921637, 0.004962966777384281, 0.005202911794185638, 0.005442857276648283]}, "gradients/roberta.encoder.layer.0.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 9.0, 5.0, 8.0, 8.0, 13.0, 17.0, 22.0, 30.0, 23.0, 41.0, 44.0, 68.0, 72.0, 104.0, 164.0, 194.0, 274.0, 367.0, 501.0, 620.0, 712.0, 698.0, 534.0, 379.0, 311.0, 200.0, 197.0, 125.0, 86.0, 84.0, 55.0, 41.0, 29.0, 20.0, 15.0, 11.0, 11.0, 5.0, 9.0, 5.0, 7.0, 2.0, 4.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0], "bins": [-0.02348659746348858, -0.02274542674422264, -0.022004257887601852, -0.021263087168335915, -0.020521916449069977, -0.01978074572980404, -0.0190395750105381, -0.018298406153917313, -0.017557235434651375, -0.016816064715385437, -0.01607489585876465, -0.01533372513949871, -0.014592554420232773, -0.013851383700966835, -0.013110213913023472, -0.012369044125080109, -0.01162787340581417, -0.010886702686548233, -0.01014553289860487, -0.009404363110661507, -0.008663192391395569, -0.007922021672129631, -0.007180851884186268, -0.006439681630581617, -0.005698511376976967, -0.004957341123372316, -0.004216170869767666, -0.0034750006161630154, -0.002733830362558365, -0.0019926601089537144, -0.0012514898553490639, -0.0005103196017444134, 0.0002308487892150879, 0.0009720190428197384, 0.0017131892964243889, 0.0024543595500290394, 0.00319552980363369, 0.00393670005723834, 0.004677870310842991, 0.005419040564447641, 0.006160210818052292, 0.006901381071656942, 0.007642551325261593, 0.008383721113204956, 0.009124891832470894, 0.009866062551736832, 0.010607232339680195, 0.011348402127623558, 0.012089572846889496, 0.012830743566155434, 0.013571913354098797, 0.01431308314204216, 0.015054253861308098, 0.015795424580574036, 0.016536593437194824, 0.017277764156460762, 0.0180189348757267, 0.018760105594992638, 0.019501276314258575, 0.020242445170879364, 0.020983615890145302, 0.02172478660941124, 0.022465955466032028, 0.023207126185297966, 0.023948296904563904]}, "gradients/roberta.encoder.layer.0.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 1.0, 7.0, 15.0, 43.0, 126.0, 468.0, 1306.0, 2055.0, 1402.0, 504.0, 144.0, 35.0, 17.0, 5.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.02190123312175274, -0.021373676136136055, -0.02084612101316452, -0.020318564027547836, -0.019791007041931152, -0.01926345005631447, -0.018735893070697784, -0.01820833794772625, -0.017680780962109566, -0.017153223976492882, -0.016625668853521347, -0.016098111867904663, -0.015570554882287979, -0.015042997896671295, -0.014515441842377186, -0.013987885788083076, -0.013460328802466393, -0.012932771816849709, -0.0124052157625556, -0.01187765970826149, -0.011350102722644806, -0.010822545737028122, -0.010294989682734013, -0.009767433628439903, -0.00923987664282322, -0.008712319657206535, -0.008184763602912426, -0.007657207082957029, -0.007129650563001633, -0.006602094043046236, -0.006074537523090839, -0.005546981003135443, -0.005019426345825195, -0.004491869825869799, -0.003964313305914402, -0.0034367567859590054, -0.0029092002660036087, -0.002381643746048212, -0.0018540872260928154, -0.0013265307061374187, -0.0007989741861820221, -0.00027141766622662544, 0.0002561388537287712, 0.0007836953736841679, 0.0013112518936395645, 0.0018388084135949612, 0.002366364933550358, 0.0028939214535057545, 0.003421477973461151, 0.003949034493416548, 0.004476591013371944, 0.005004147533327341, 0.005531704053282738, 0.006059260573238134, 0.006586817093193531, 0.007114373613148928, 0.007641930133104324, 0.008169487118721008, 0.008697043173015118, 0.009224599227309227, 0.009752156212925911, 0.010279713198542595, 0.010807269252836704, 0.011334825307130814, 0.011862382292747498]}, "gradients/roberta.encoder.layer.0.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 3.0, 4.0, 4.0, 7.0, 9.0, 5.0, 10.0, 15.0, 21.0, 24.0, 25.0, 29.0, 60.0, 63.0, 80.0, 103.0, 154.0, 214.0, 324.0, 437.0, 720.0, 1123.0, 871.0, 512.0, 371.0, 226.0, 177.0, 120.0, 110.0, 77.0, 51.0, 35.0, 30.0, 32.0, 22.0, 10.0, 11.0, 11.0, 9.0, 4.0, 1.0, 4.0, 4.0, 1.0, 4.0, 0.0, 5.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.003479850711300969, -0.003366573713719845, -0.0032532967161387205, -0.003140019718557596, -0.0030267424881458282, -0.0029134657233953476, -0.0028001884929835796, -0.0026869114954024553, -0.002573634497821331, -0.0024603575002402067, -0.0023470805026590824, -0.002233803505077958, -0.002120526507496834, -0.002007249277085066, -0.0018939722795039415, -0.0017806952819228172, -0.001667418284341693, -0.0015541412867605686, -0.0014408642891794443, -0.0013275871751829982, -0.0012143101776018739, -0.0011010331800207496, -0.0009877560660243034, -0.0008744790684431791, -0.0007612020708620548, -0.0006479250732809305, -0.0005346480174921453, -0.00042137099080719054, -0.0003080939641222358, -0.00019481696654111147, -8.153991075232625e-05, 3.173714503645897e-05, 0.00014501414261758327, 0.00025829116930253804, 0.0003715681959874928, 0.00048484522267244756, 0.0005981222493574023, 0.0007113992469385266, 0.0008246763027273118, 0.0009379533585160971, 0.0010512303560972214, 0.0011645073536783457, 0.00127778435125947, 0.0013910614652559161, 0.0015043384628370404, 0.0016176154604181647, 0.0017308925744146109, 0.0018441695719957352, 0.0019574465695768595, 0.0020707235671579838, 0.002184000564739108, 0.0022972775623202324, 0.0024105547927320004, 0.002523831557482481, 0.002637108787894249, 0.0027503857854753733, 0.0028636627830564976, 0.002976939780637622, 0.003090216778218746, 0.0032034937757998705, 0.003316770773380995, 0.0034300480037927628, 0.003543325001373887, 0.0036566019989550114, 0.0037698789965361357]}, "gradients/roberta.encoder.layer.0.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 5.0, 8.0, 15.0, 20.0, 47.0, 91.0, 155.0, 242.0, 455.0, 658.0, 844.0, 970.0, 863.0, 671.0, 447.0, 298.0, 166.0, 90.0, 45.0, 25.0, 7.0, 6.0, 6.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0018825000151991844, -0.001826364197768271, -0.0017702283803373575, -0.001714092562906444, -0.0016579567454755306, -0.0016018209280446172, -0.0015456851106137037, -0.0014895492931827903, -0.0014334134757518768, -0.0013772776583209634, -0.00132114184089005, -0.0012650060234591365, -0.001208870206028223, -0.0011527343885973096, -0.0010965985711663961, -0.0010404627537354827, -0.0009843269363045692, -0.0009281911188736558, -0.0008720553014427423, -0.0008159194840118289, -0.0007597836665809155, -0.000703647849150002, -0.0006475120317190886, -0.0005913762142881751, -0.0005352402804419398, -0.0004791044630110264, -0.00042296864558011293, -0.0003668328281491995, -0.00031069701071828604, -0.00025456116418354213, -0.00019842534675262868, -0.00014228952932171524, -8.615374099463224e-05, -3.001791992573999e-05, 2.6117901143152267e-05, 8.225372585002333e-05, 0.00013838954328093678, 0.00019452537526376545, 0.0002506611926946789, 0.00030679701012559235, 0.0003629328275565058, 0.00041906864498741925, 0.0004752044624183327, 0.0005313403089530766, 0.00058747612638399, 0.0006436119438149035, 0.000699747761245817, 0.0007558835786767304, 0.0008120193961076438, 0.0008681552135385573, 0.0009242910309694707, 0.000980426906608045, 0.0010365627240389585, 0.001092698541469872, 0.0011488343589007854, 0.001204970176331699, 0.0012611059937626123, 0.0013172418111935258, 0.0013733776286244392, 0.0014295134460553527, 0.0014856492634862661, 0.0015417850809171796, 0.001597920898348093, 0.0016540567157790065, 0.00171019253320992]}, "eval/loss": 0.4653194546699524, "eval/matthews_correlation": 0.4860627149832655, "eval/runtime": 6.713, "eval/samples_per_second": 155.369, "train/train_runtime": 189.5731, "train/train_samples_per_second": 1.414, "train/total_flos": 3289809517651968.0, "_wandb": {"runtime": 191}}