{"train/loss": 0.5028, "train/learning_rate": 1.2749003984063745e-05, "train/epoch": 1.0, "_timestamp": 1704732761.0676515, "_runtime": 147.98333048820496, "_step": 268, "gradients/classifier.out_proj.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.051927778869867325, -0.05030503496527672, -0.04868229106068611, -0.0470595508813858, -0.0454368069767952, -0.04381406307220459, -0.04219131916761398, -0.040568575263023376, -0.03894583135843277, -0.03732308745384216, -0.035700343549251556, -0.03407759964466095, -0.03245485946536064, -0.030832115560770035, -0.029209371656179428, -0.02758662775158882, -0.025963885709643364, -0.024341141805052757, -0.0227183997631073, -0.021095655858516693, -0.019472911953926086, -0.01785016804933548, -0.016227426007390022, -0.014604682102799416, -0.012981939129531384, -0.011359196156263351, -0.009736452251672745, -0.008113709278404713, -0.006490965839475393, -0.004868222400546074, -0.003245479427278042, -0.0016227355226874352, 7.450580596923828e-09, 0.0016227507730945945, 0.003245494095608592, 0.004868237301707268, 0.006490980740636587, 0.008113724179565907, 0.009736467152833939, 0.011359211057424545, 0.012981954030692577, 0.01460469700396061, 0.016227440908551216, 0.017850182950496674, 0.01947292685508728, 0.021095670759677887, 0.022718414664268494, 0.0243411585688591, 0.025963900610804558, 0.027586644515395164, 0.029209386557340622, 0.03083213046193123, 0.032454874366521835, 0.03407761827111244, 0.03570035845041275, 0.03732310235500336, 0.038945846259593964, 0.04056859016418457, 0.04219133406877518, 0.043814077973365784, 0.04543681815266609, 0.0470595620572567, 0.048682305961847305, 0.05030504986643791, 0.05192779377102852]}, "gradients/classifier.out_proj.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 2.0, 4.0, 4.0, 6.0, 4.0, 8.0, 7.0, 10.0, 16.0, 24.0, 24.0, 34.0, 49.0, 63.0, 82.0, 56.0, 78.0, 92.0, 99.0, 98.0, 98.0, 99.0, 92.0, 78.0, 56.0, 82.0, 63.0, 49.0, 34.0, 24.0, 24.0, 16.0, 10.0, 7.0, 8.0, 4.0, 6.0, 4.0, 4.0, 2.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05498703196644783, -0.053268685936927795, -0.05155034363269806, -0.049831997603178024, -0.04811365157365799, -0.04639530926942825, -0.04467696323990822, -0.042958617210388184, -0.04124027490615845, -0.03952192887663841, -0.037803586572408676, -0.03608524054288864, -0.03436689451336861, -0.03264855220913887, -0.030930206179618835, -0.02921186201274395, -0.027493515983223915, -0.02577517181634903, -0.024056825786828995, -0.02233848161995411, -0.020620137453079224, -0.01890179142355919, -0.017183447256684303, -0.015465103089809418, -0.013746757991611958, -0.012028412893414497, -0.010310068726539612, -0.008591723628342152, -0.006873378995805979, -0.005155034363269806, -0.0034366892650723457, -0.0017183450981974602, 0.0, 0.0017183447489514947, 0.0034366894979029894, 0.005155034363269806, 0.006873378995805979, 0.008591723628342152, 0.010310068726539612, 0.012028412893414497, 0.013746757991611958, 0.015465103089809418, 0.017183447256684303, 0.01890179142355919, 0.020620137453079224, 0.02233848161995411, 0.024056825786828995, 0.02577517181634903, 0.027493515983223915, 0.0292118601500988, 0.030930206179618835, 0.03264854848384857, 0.03436689451336861, 0.03608524054288864, 0.03780358284711838, 0.03952192887663841, 0.04124027490615845, 0.04295862093567848, 0.04467696323990822, 0.04639530926942825, 0.04811365529894829, 0.049831997603178024, 0.05155034363269806, 0.053268685936927795, 0.05498703196644783]}, "gradients/classifier.dense.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 5.0, 7.0, 5.0, 9.0, 3.0, 16.0, 8.0, 17.0, 21.0, 22.0, 39.0, 38.0, 36.0, 41.0, 57.0, 92.0, 49.0, 51.0, 40.0, 31.0, 31.0, 24.0, 26.0, 17.0, 13.0, 12.0, 7.0, 4.0, 5.0, 9.0, 3.0, 5.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.006825122982263565, -0.006615710444748402, -0.0064062983728945255, -0.006196885835379362, -0.005987473297864199, -0.005778061226010323, -0.005568648688495159, -0.005359236150979996, -0.00514982407912612, -0.004940411541610956, -0.00473099946975708, -0.004521586932241917, -0.004312174394726753, -0.004102762322872877, -0.0038933497853577137, -0.003683937480673194, -0.0034745249431580305, -0.0032651126384735107, -0.0030557001009583473, -0.0028462877962738276, -0.002636875491589308, -0.0024274629540741444, -0.0022180506493896246, -0.002008638344705105, -0.0017992259236052632, -0.0015898135025054216, -0.0013804011978209019, -0.0011709887767210603, -0.0009615764138288796, -0.0007521640509366989, -0.0005427516298368573, -0.00033333932515233755, -0.00012392690405249596, 8.548547339159995e-05, 0.00029489785083569586, 0.000504310242831707, 0.0007137226057238877, 0.0009231349686160684, 0.00113254738971591, 0.0013419596944004297, 0.0015513721155002713, 0.001760784536600113, 0.0019701968412846327, 0.0021796091459691525, 0.002389021683484316, 0.0025984339881688356, 0.0028078462928533554, 0.003017258830368519, 0.0032266711350530386, 0.0034360834397375584, 0.003645495977252722, 0.0038549082819372416, 0.004064320586621761, 0.004273733124136925, 0.004483145661652088, 0.004692557733505964, 0.004901970271021128, 0.005111382808536291, 0.005320794880390167, 0.005530207417905331, 0.005739619955420494, 0.00594903202727437, 0.006158444564789534, 0.00636785663664341, 0.006577269174158573]}, "gradients/classifier.dense.weight": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 4.0, 4.0, 8.0, 2.0, 13.0, 9.0, 9.0, 16.0, 17.0, 34.0, 43.0, 75.0, 246.0, 27621.0, 560943.0, 480.0, 109.0, 54.0, 23.0, 23.0, 11.0, 15.0, 11.0, 12.0, 6.0, 8.0, 0.0, 2.0, 4.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.08539211750030518, -0.08303047716617584, -0.0806688442826271, -0.07830720394849777, -0.07594557106494904, -0.0735839307308197, -0.07122229039669037, -0.06886065006256104, -0.0664990171790123, -0.06413737684488297, -0.06177574396133423, -0.059414103627204895, -0.05705246701836586, -0.054690830409526825, -0.05232919007539749, -0.049967553466558456, -0.04760591685771942, -0.045244280248880386, -0.04288264364004135, -0.04052100330591202, -0.03815936669707298, -0.03579773008823395, -0.033436089754104614, -0.03107445314526558, -0.028712816536426544, -0.02635117992758751, -0.023989541456103325, -0.02162790298461914, -0.019266266375780106, -0.01690462976694107, -0.014542991295456886, -0.012181352823972702, -0.009819716215133667, -0.007458078674972057, -0.005096441134810448, -0.002734803594648838, -0.0003731660544872284, 0.0019884714856743813, 0.004350109025835991, 0.006711747497320175, 0.00907338410615921, 0.01143502164632082, 0.01379665918648243, 0.016158297657966614, 0.01851993426680565, 0.020881570875644684, 0.023243209347128868, 0.025604847818613052, 0.027966484427452087, 0.030328121036291122, 0.03268975764513016, 0.03505139797925949, 0.037413034588098526, 0.03977467119693756, 0.042136311531066895, 0.04449794813990593, 0.046859584748744965, 0.049221221357584, 0.051582857966423035, 0.05394449830055237, 0.0563061349093914, 0.05866777151823044, 0.06102941185235977, 0.06339104473590851, 0.06575268507003784]}, "gradients/roberta.encoder.layer.11.attention.self.value.lora_B": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 3.0, 6.0, 4.0, 6.0, 7.0, 8.0, 11.0, 17.0, 24.0, 27.0, 20.0, 72.0, 82.0, 129.0, 129.0, 178.0, 270.0, 332.0, 384.0, 492.0, 528.0, 573.0, 512.0, 495.0, 433.0, 364.0, 249.0, 183.0, 150.0, 105.0, 85.0, 72.0, 46.0, 25.0, 32.0, 27.0, 14.0, 10.0, 7.0, 7.0, 6.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.008647331967949867, -0.008381699211895466, -0.008116067387163639, -0.007850434631109238, -0.007584801875054836, -0.007319169584661722, -0.007053537294268608, -0.006787904538214207, -0.006522272247821093, -0.0062566399574279785, -0.005991007201373577, -0.005725374910980463, -0.005459742620587349, -0.0051941098645329475, -0.0049284775741398335, -0.004662845283746719, -0.004397212527692318, -0.004131580237299204, -0.0038659474812448025, -0.0036003151908516884, -0.0033346826676279306, -0.003069050144404173, -0.002803417854011059, -0.002537785330787301, -0.0022721528075635433, -0.0020065202843397856, -0.0017408878775313497, -0.0014752554707229137, -0.001209622947499156, -0.0009439904242753983, -0.0006783580174669623, -0.0004127256106585264, -0.0001470940187573433, 0.00011853844625875354, 0.00038417091127485037, 0.0006498033762909472, 0.000915435841307044, 0.0011810683645308018, 0.0014467007713392377, 0.0017123331781476736, 0.0019779657013714314, 0.002243598224595189, 0.002509230747818947, 0.002774863038212061, 0.0030404955614358187, 0.0033061280846595764, 0.0035717603750526905, 0.0038373928982764482, 0.004103025421500206, 0.00436865771189332, 0.0046342904679477215, 0.004899922758340836, 0.005165555514395237, 0.005431187804788351, 0.005696820095181465, 0.0059624528512358665, 0.006228085141628981, 0.006493717432022095, 0.006759350188076496, 0.00702498247846961, 0.007290614768862724, 0.007556247524917126, 0.007821880280971527, 0.008087512105703354, 0.008353144861757755]}, "gradients/roberta.encoder.layer.11.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 4.0, 5.0, 22.0, 45.0, 182.0, 644.0, 2778.0, 1861.0, 411.0, 120.0, 40.0, 10.0, 5.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.097190722823143, -0.09381985664367676, -0.09044899046421051, -0.08707812428474426, -0.08370725810527802, -0.08033639192581177, -0.07696552574634552, -0.07359465956687927, -0.07022379338741302, -0.06685292720794678, -0.06348206102848053, -0.06011119484901428, -0.056740328669548035, -0.05336946249008179, -0.04999859631061554, -0.04662773013114929, -0.043256860226392746, -0.0398859940469265, -0.03651512786746025, -0.033144261687994, -0.029773395508527756, -0.02640252746641636, -0.02303166128695011, -0.019660795107483864, -0.016289928928017616, -0.012919062748551369, -0.009548196569085121, -0.006177329458296299, -0.0028064632788300514, 0.0005644038319587708, 0.003935270011425018, 0.007306136190891266, 0.010677002370357513, 0.014047868549823761, 0.01741873472929001, 0.020789600908756256, 0.024160467088222504, 0.0275313351303339, 0.030902201309800148, 0.034273065626621246, 0.037643931806087494, 0.04101479798555374, 0.04438566416501999, 0.04775653034448624, 0.051127396523952484, 0.05449826270341873, 0.05786912888288498, 0.06123999506235123, 0.06461086869239807, 0.06798173487186432, 0.07135260105133057, 0.07472346723079681, 0.07809433341026306, 0.08146519958972931, 0.08483606576919556, 0.0882069319486618, 0.09157779812812805, 0.0949486643075943, 0.09831953048706055, 0.1016903966665268, 0.10506126284599304, 0.10843212902545929, 0.11180299520492554, 0.11517386138439178, 0.11854472756385803]}, "gradients/roberta.encoder.layer.11.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 4.0, 3.0, 7.0, 12.0, 5.0, 20.0, 18.0, 15.0, 24.0, 24.0, 31.0, 62.0, 86.0, 95.0, 135.0, 154.0, 271.0, 313.0, 448.0, 577.0, 757.0, 742.0, 594.0, 461.0, 333.0, 225.0, 181.0, 132.0, 110.0, 71.0, 51.0, 31.0, 27.0, 28.0, 14.0, 23.0, 14.0, 10.0, 8.0, 7.0, 7.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.008568108081817627, -0.008282649330794811, -0.007997190579771996, -0.0077117327600717545, -0.007426274009048939, -0.007140815258026123, -0.006855356972664595, -0.006569898687303066, -0.0062844399362802505, -0.005998981185257435, -0.0057135228998959064, -0.005428064614534378, -0.005142605863511562, -0.004857147112488747, -0.004571688827127218, -0.00428623054176569, -0.004000771790742874, -0.003715313272550702, -0.00342985475435853, -0.003144396236166358, -0.002858937717974186, -0.002573479199782014, -0.002288020681589842, -0.00200256216339767, -0.0017171036452054977, -0.0014316451270133257, -0.0011461866088211536, -0.0008607280906289816, -0.0005752695724368095, -0.0002898110542446375, -4.352536052465439e-06, 0.0002811059821397066, 0.0005665654316544533, 0.0008520239498466253, 0.0011374824680387974, 0.0014229409862309694, 0.0017083995044231415, 0.0019938580226153135, 0.0022793165408074856, 0.0025647750589996576, 0.0028502335771918297, 0.0031356920953840017, 0.0034211506135761738, 0.003706609131768346, 0.003992067649960518, 0.004277526400983334, 0.004562984686344862, 0.00484844297170639, 0.005133901722729206, 0.005419360473752022, 0.00570481875911355, 0.005990277044475079, 0.006275735795497894, 0.00656119454652071, 0.006846652831882238, 0.007132111117243767, 0.0074175698682665825, 0.007703028619289398, 0.00798848643898964, 0.008273945190012455, 0.00855940394103527, 0.008844862692058086, 0.009130321443080902, 0.009415779262781143, 0.009701238013803959]}, "gradients/roberta.encoder.layer.11.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 1.0, 2.0, 1.0, 17.0, 187.0, 1599.0, 3044.0, 1124.0, 127.0, 6.0, 2.0, 0.0, 4.0, 3.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0030361358076334, -0.002900550840422511, -0.0027649658732116222, -0.0026293806731700897, -0.002493795705959201, -0.002358210738748312, -0.002222625771537423, -0.0020870408043265343, -0.0019514557207003236, -0.0018158707534894347, -0.001680285669863224, -0.0015447007026523352, -0.0014091157354414463, -0.0012735306518152356, -0.0011379456846043468, -0.001002360600978136, -0.0008667756337672472, -0.0007311906083486974, -0.0005956055829301476, -0.0004600206157192588, -0.000324435590300709, -0.00018885056488215923, -5.326559767127037e-05, 8.23194277472794e-05, 0.00021790445316582918, 0.00035348947858437896, 0.0004890745040029287, 0.0006246594712138176, 0.0007602444966323674, 0.0008958295220509171, 0.001031414489261806, 0.0011669995728880167, 0.0013025845400989056, 0.0014381695073097944, 0.0015737545909360051, 0.001709339558146894, 0.0018449246417731047, 0.0019805096089839935, 0.0021160945761948824, 0.0022516795434057713, 0.0023872647434473038, 0.0025228497106581926, 0.0026584346778690815, 0.002794019877910614, 0.002929604845121503, 0.0030651898123323917, 0.0032007747795432806, 0.0033363597467541695, 0.0034719447139650583, 0.003607529681175947, 0.003743114648386836, 0.003878699615597725, 0.004014284815639257, 0.00414987001568079, 0.004285454750061035, 0.004421039950102568, 0.004556624684482813, 0.004692209884524345, 0.004827794618904591, 0.004963379818946123, 0.005098964553326368, 0.005234549753367901, 0.005370134487748146, 0.005505719687789679, 0.005641304887831211]}, "gradients/roberta.encoder.layer.10.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 4.0, 3.0, 5.0, 8.0, 10.0, 17.0, 16.0, 20.0, 28.0, 26.0, 62.0, 71.0, 109.0, 143.0, 230.0, 290.0, 392.0, 535.0, 738.0, 872.0, 673.0, 488.0, 339.0, 263.0, 216.0, 144.0, 112.0, 74.0, 68.0, 42.0, 37.0, 18.0, 18.0, 16.0, 9.0, 9.0, 11.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0], "bins": [-0.019019562751054764, -0.018510781228542328, -0.018001999706029892, -0.017493218183517456, -0.01698443666100502, -0.016475655138492584, -0.01596687361598015, -0.015458093024790287, -0.014949311502277851, -0.014440529979765415, -0.01393174845725298, -0.013422966934740543, -0.012914186343550682, -0.012405404821038246, -0.01189662329852581, -0.011387841776013374, -0.010879060253500938, -0.010370278730988503, -0.009861497208476067, -0.00935271568596363, -0.008843934163451195, -0.008335152640938759, -0.007826372049748898, -0.007317590527236462, -0.006808809004724026, -0.00630002748221159, -0.005791245959699154, -0.005282464902848005, -0.004773683380335569, -0.0042649018578231335, -0.003756120568141341, -0.003247339278459549, -0.0027385596185922623, -0.0022297780960798264, -0.001720996806398034, -0.00121221540030092, -0.0007034339942038059, -0.00019465247169137, 0.00031412881799042225, 0.0008229101076722145, 0.0013316916301846504, 0.0018404730362817645, 0.0023492544423788786, 0.002858035732060671, 0.0033668172545731068, 0.0038755987770855427, 0.004384379833936691, 0.004893161356449127, 0.005401942878961563, 0.005910724401473999, 0.006419505923986435, 0.0069282869808375835, 0.0074370685033500195, 0.007945850491523743, 0.008454631082713604, 0.00896341260522604, 0.009472194127738476, 0.009980975650250912, 0.010489757172763348, 0.010998538695275784, 0.011507319286465645, 0.01201610080897808, 0.012524882331490517, 0.013033663854002953, 0.013542445376515388]}, "gradients/roberta.encoder.layer.10.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 7.0, 84.0, 1017.0, 4756.0, 229.0, 30.0, 3.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05648712441325188, -0.054249487817287445, -0.05201185122132301, -0.04977421462535858, -0.04753658175468445, -0.04529894143342972, -0.043061308562755585, -0.04082367196679115, -0.03858603537082672, -0.03634839877486229, -0.03411076217889786, -0.031873125582933426, -0.029635490849614143, -0.02739785425364971, -0.02516021952033043, -0.022922582924365997, -0.020684946328401566, -0.018447309732437134, -0.016209673136472702, -0.01397203840315342, -0.011734401807188988, -0.009496765211224556, -0.007259129546582699, -0.005021493881940842, -0.00278385728597641, -0.0005462211556732655, 0.001691414974629879, 0.0039290511049330235, 0.006166687235236168, 0.0084043238312006, 0.010641959495842457, 0.012879595160484314, 0.015117228031158447, 0.01735486462712288, 0.01959250122308731, 0.021830135956406593, 0.024067772552371025, 0.026305409148335457, 0.02854304388165474, 0.03078068047761917, 0.0330183170735836, 0.035255953669548035, 0.037493590265512466, 0.0397312268614769, 0.04196885973215103, 0.04420650005340576, 0.046444132924079895, 0.04868176952004433, 0.05091940611600876, 0.05315704271197319, 0.05539467930793762, 0.057632315903902054, 0.059869952499866486, 0.06210758537054062, 0.06434522569179535, 0.06658285856246948, 0.06882049143314362, 0.07105812430381775, 0.07329576462507248, 0.07553339749574661, 0.07777103781700134, 0.08000867068767548, 0.0822463110089302, 0.08448394387960434, 0.08672158420085907]}, "gradients/roberta.encoder.layer.10.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 1.0, 5.0, 5.0, 13.0, 6.0, 17.0, 20.0, 15.0, 41.0, 33.0, 51.0, 77.0, 116.0, 157.0, 217.0, 292.0, 443.0, 564.0, 731.0, 807.0, 655.0, 515.0, 367.0, 229.0, 195.0, 159.0, 101.0, 69.0, 46.0, 36.0, 31.0, 24.0, 26.0, 11.0, 13.0, 8.0, 6.0, 6.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.0064546349458396435, -0.0062483446672558784, -0.006042054388672113, -0.005835764110088348, -0.005629473831504583, -0.005423183552920818, -0.005216893274337053, -0.005010602995753288, -0.004804312717169523, -0.004598022438585758, -0.004391732160001993, -0.004185441881418228, -0.003979151602834463, -0.003772861324250698, -0.003566571045666933, -0.003360280767083168, -0.003153990488499403, -0.002947700209915638, -0.002741409931331873, -0.002535119652748108, -0.002328829374164343, -0.002122539095580578, -0.0019162488169968128, -0.0017099585384130478, -0.0015036682598292828, -0.0012973779812455177, -0.0010910877026617527, -0.0008847974240779877, -0.0006785071454942226, -0.0004722168669104576, -0.0002659265883266926, -5.963630974292755e-05, 0.00014665443450212479, 0.0003529447130858898, 0.0005592349916696548, 0.0007655252702534199, 0.0009718155488371849, 0.00117810582742095, 0.001384396106004715, 0.00159068638458848, 0.001796976663172245, 0.00200326694175601, 0.002209557220339775, 0.00241584749892354, 0.002622137777507305, 0.00282842805609107, 0.003034718334674835, 0.0032410086132586002, 0.0034472988918423653, 0.0036535891704261303, 0.0038598794490098953, 0.00406616972759366, 0.004272460006177425, 0.00447875028476119, 0.0046850405633449554, 0.0048913308419287205, 0.0050976211205124855, 0.0053039113990962505, 0.0055102016776800156, 0.005716491956263781, 0.005922782234847546, 0.006129072513431311, 0.006335362792015076, 0.006541653070598841, 0.006747943349182606]}, "gradients/roberta.encoder.layer.10.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 12.0, 11.0, 174.0, 1931.0, 3412.0, 541.0, 34.0, 13.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.015187401324510574, -0.014730180613696575, -0.014272959902882576, -0.013815740123391151, -0.013358519412577152, -0.012901298701763153, -0.012444077990949154, -0.011986857280135155, -0.01152963750064373, -0.011072416789829731, -0.010615196079015732, -0.010157976299524307, -0.009700755588710308, -0.009243534877896309, -0.00878631416708231, -0.00832909345626831, -0.007871873676776886, -0.007414652965962887, -0.006957432720810175, -0.006500212009996176, -0.006042991764843464, -0.005585771054029465, -0.0051285503432154655, -0.004671330098062754, -0.004214108921587467, -0.0037568884436041117, -0.003299667965620756, -0.002842447254806757, -0.002385227009654045, -0.001928006298840046, -0.0014707858208566904, -0.0010135653428733349, -0.000556345097720623, -9.912459063343704e-05, 0.00035809591645374894, 0.0008153164526447654, 0.001272536930628121, 0.0017297575250267982, 0.0021869780030101538, 0.0026441984809935093, 0.003101418958976865, 0.0035586394369602203, 0.0040158601477742195, 0.004473080392926931, 0.0049303011037409306, 0.005387521348893642, 0.005844742059707642, 0.006301962770521641, 0.006759183015674353, 0.007216403726488352, 0.007673623971641064, 0.008130844682455063, 0.008588065393269062, 0.009045286104083061, 0.009502505883574486, 0.009959726594388485, 0.010416947305202484, 0.010874168016016483, 0.011331388726830482, 0.011788608506321907, 0.012245829217135906, 0.012703049927949905, 0.013160270638763905, 0.013617491349577904, 0.014074711129069328]}, "gradients/roberta.encoder.layer.9.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 4.0, 5.0, 12.0, 10.0, 19.0, 23.0, 29.0, 25.0, 39.0, 48.0, 86.0, 87.0, 127.0, 121.0, 185.0, 202.0, 277.0, 349.0, 351.0, 479.0, 585.0, 579.0, 552.0, 378.0, 300.0, 274.0, 195.0, 172.0, 137.0, 108.0, 94.0, 48.0, 45.0, 40.0, 30.0, 24.0, 19.0, 13.0, 11.0, 14.0, 5.0, 6.0, 6.0, 3.0, 4.0, 4.0, 0.0, 1.0, 3.0, 2.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0], "bins": [-0.01076942216604948, -0.010396900586783886, -0.010024378076195717, -0.009651856496930122, -0.009279333986341953, -0.008906812407076359, -0.00853428989648819, -0.008161768317222595, -0.007789246272295713, -0.007416724227368832, -0.00704420218244195, -0.006671680137515068, -0.006299158558249474, -0.0059266360476613045, -0.00555411446839571, -0.005181592423468828, -0.004809070378541946, -0.004436548333615065, -0.004064026288688183, -0.0036915044765919447, -0.003318982431665063, -0.002946460386738181, -0.002573938574641943, -0.002201416529715061, -0.0018288944847881794, -0.0014563724398612976, -0.0010838505113497376, -0.0007113285828381777, -0.0003388065379112959, 3.37155070155859e-05, 0.00040623731911182404, 0.0007787593640387058, 0.001151280477643013, 0.0015238025225698948, 0.0018963244510814548, 0.0022688463795930147, 0.0026413684245198965, 0.0030138904694467783, 0.0033864122815430164, 0.0037589343264698982, 0.00413145637139678, 0.004503978416323662, 0.004876500461250544, 0.005249022506177425, 0.00562154408544302, 0.005994066596031189, 0.0063665881752967834, 0.006739110220223665, 0.007111632265150547, 0.007484154310077429, 0.00785667635500431, 0.008229197934269905, 0.008601720444858074, 0.008974242024123669, 0.009346764534711838, 0.009719286113977432, 0.010091807693243027, 0.010464329272508621, 0.01083685178309679, 0.011209373362362385, 0.011581895872950554, 0.011954417452216148, 0.012326939031481743, 0.012699461542069912, 0.013071984052658081]}, "gradients/roberta.encoder.layer.9.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 6.0, 15.0, 50.0, 122.0, 759.0, 4481.0, 497.0, 118.0, 50.0, 16.0, 12.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04767470434308052, -0.0461578406393528, -0.044640976935625076, -0.043124113231897354, -0.04160724952816963, -0.04009038582444191, -0.03857352212071419, -0.037056658416986465, -0.03553979471325874, -0.03402293100953102, -0.0325060673058033, -0.030989203602075577, -0.029472339898347855, -0.027955476194620132, -0.02643861249089241, -0.024921748787164688, -0.023404885083436966, -0.021888021379709244, -0.02037115767598152, -0.0188542939722538, -0.017337430268526077, -0.015820566564798355, -0.014303702861070633, -0.01278683915734291, -0.011269975453615189, -0.009753111749887466, -0.008236248046159744, -0.006719384342432022, -0.0052025206387043, -0.0036856569349765778, -0.0021687932312488556, -0.0006519295275211334, 0.0008649379014968872, 0.0023818016052246094, 0.0038986653089523315, 0.005415529012680054, 0.006932392716407776, 0.008449256420135498, 0.00996612012386322, 0.011482983827590942, 0.012999847531318665, 0.014516711235046387, 0.01603357493877411, 0.01755043864250183, 0.019067302346229553, 0.020584166049957275, 0.022101029753684998, 0.02361789345741272, 0.025134757161140442, 0.026651620864868164, 0.028168484568595886, 0.02968534827232361, 0.03120221197605133, 0.03271907567977905, 0.034235939383506775, 0.0357528030872345, 0.03726966679096222, 0.03878653049468994, 0.040303394198417664, 0.041820257902145386, 0.04333712160587311, 0.04485398530960083, 0.04637084901332855, 0.047887712717056274, 0.049404576420784]}, "gradients/roberta.encoder.layer.9.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 4.0, 2.0, 4.0, 2.0, 5.0, 5.0, 11.0, 12.0, 23.0, 38.0, 63.0, 84.0, 132.0, 214.0, 442.0, 914.0, 1514.0, 1256.0, 627.0, 307.0, 142.0, 117.0, 78.0, 44.0, 30.0, 19.0, 9.0, 9.0, 6.0, 1.0, 5.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.014739167876541615, -0.014289290644228458, -0.013839414343237877, -0.01338953711092472, -0.012939659878611565, -0.012489782646298409, -0.012039906345307827, -0.011590029112994671, -0.011140151880681515, -0.010690274648368359, -0.010240398347377777, -0.009790521115064621, -0.009340643882751465, -0.008890766650438309, -0.008440890349447727, -0.007991013117134571, -0.007541136350482702, -0.0070912595838308334, -0.006641382351517677, -0.0061915055848658085, -0.005741628352552652, -0.0052917515859007835, -0.004841874353587627, -0.004391997586935759, -0.00394212082028389, -0.0034922438208013773, -0.003042366821318865, -0.002592490054666996, -0.00214261282235384, -0.001692736055701971, -0.0012428590562194586, -0.0007929820567369461, -0.00034310482442379, 0.00010677214595489204, 0.0005566491163335741, 0.0010065260576084256, 0.001456403057090938, 0.0019062799401581287, 0.002356156939640641, 0.0028060339391231537, 0.003255910938605666, 0.0037057879380881786, 0.0041556647047400475, 0.004605541937053204, 0.005055418703705072, 0.005505295470356941, 0.005955172702670097, 0.0064050499349832535, 0.006854926701635122, 0.007304803468286991, 0.007754680700600147, 0.008204557932913303, 0.008654434233903885, 0.009104311466217041, 0.009554188698530197, 0.010004065930843353, 0.010453942231833935, 0.010903819464147091, 0.011353695765137672, 0.011803572997450829, 0.012253450229763985, 0.01270332746207714, 0.013153203763067722, 0.013603080995380878, 0.014052958227694035]}, "gradients/roberta.encoder.layer.9.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 6.0, 16.0, 201.0, 2638.0, 2978.0, 256.0, 22.0, 7.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.0308978408575058, -0.02979566901922226, -0.02869349718093872, -0.027591325342655182, -0.026489153504371643, -0.025386981666088104, -0.024284807965159416, -0.023182636126875877, -0.02208046428859234, -0.0209782924503088, -0.01987612061202526, -0.018773948773741722, -0.017671775072813034, -0.016569603234529495, -0.015467431396245956, -0.014365259557962418, -0.013263087719678879, -0.01216091588139534, -0.011058744043111801, -0.009956571273505688, -0.008854399435222149, -0.00775222759693861, -0.006650055292993784, -0.005547882989048958, -0.004445711150765419, -0.0033435390796512365, -0.002241367008537054, -0.0011391949374228716, -3.702286630868912e-05, 0.0010651489719748497, 0.002167321275919676, 0.003269493579864502, 0.004371665418148041, 0.00547383725643158, 0.006576009560376406, 0.007678181864321232, 0.00878035370260477, 0.00988252554088831, 0.010984698310494423, 0.012086870148777962, 0.0131890419870615, 0.01429121382534504, 0.015393385663628578, 0.016495557501912117, 0.017597731202840805, 0.018699903041124344, 0.019802074879407883, 0.02090424671769142, 0.02200641855597496, 0.0231085903942585, 0.024210762232542038, 0.025312934070825577, 0.026415105909109116, 0.027517277747392654, 0.028619451448321342, 0.02972162328660488, 0.03082379512488842, 0.03192596882581711, 0.03302814066410065, 0.034130312502384186, 0.035232484340667725, 0.03633465617895126, 0.0374368280172348, 0.03853899985551834, 0.03964117169380188]}, "gradients/roberta.encoder.layer.8.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 3.0, 1.0, 6.0, 3.0, 9.0, 18.0, 22.0, 32.0, 49.0, 61.0, 91.0, 125.0, 202.0, 235.0, 263.0, 322.0, 410.0, 501.0, 574.0, 655.0, 553.0, 467.0, 364.0, 287.0, 244.0, 191.0, 124.0, 94.0, 71.0, 52.0, 27.0, 22.0, 13.0, 10.0, 5.0, 6.0, 5.0, 4.0, 4.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03698289766907692, -0.035896364599466324, -0.03480983152985573, -0.03372329846024513, -0.03263676166534424, -0.03155022859573364, -0.030463695526123047, -0.02937716245651245, -0.028290629386901855, -0.02720409631729126, -0.026117563247680664, -0.02503102831542492, -0.023944495245814323, -0.022857962176203728, -0.021771427243947983, -0.020684894174337387, -0.01959836110472679, -0.018511828035116196, -0.0174252949655056, -0.016338760033249855, -0.01525222696363926, -0.014165693894028664, -0.013079159893095493, -0.011992625892162323, -0.010906092822551727, -0.009819559752941132, -0.008733025752007961, -0.007646492216736078, -0.006559958681464195, -0.005473425146192312, -0.004386891610920429, -0.0033003580756485462, -0.0022138208150863647, -0.0011272872798144817, -4.0753744542598724e-05, 0.0010457797907292843, 0.0021323133260011673, 0.0032188468612730503, 0.004305380396544933, 0.005391913931816816, 0.006478447467088699, 0.007564981002360582, 0.008651514537632465, 0.009738048538565636, 0.010824581608176231, 0.011911114677786827, 0.012997648678719997, 0.014084182679653168, 0.015170715749263763, 0.01625724881887436, 0.017343781888484955, 0.0184303168207407, 0.019516849890351295, 0.02060338295996189, 0.021689917892217636, 0.022776450961828232, 0.023862984031438828, 0.024949517101049423, 0.02603605017066002, 0.027122585102915764, 0.02820911817252636, 0.029295651242136955, 0.0303821861743927, 0.031468719244003296, 0.03255525231361389]}, "gradients/roberta.encoder.layer.8.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 8.0, 157.0, 5718.0, 221.0, 16.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.10819859802722931, -0.10592462122440338, -0.10365064442157745, -0.10137666761875153, -0.0991026908159256, -0.09682871401309967, -0.09455473721027374, -0.09228076040744781, -0.09000678360462189, -0.08773280680179596, -0.08545882999897003, -0.0831848531961441, -0.08091087639331818, -0.07863689959049225, -0.07636292278766632, -0.0740889459848404, -0.07181496173143387, -0.06954098492860794, -0.06726700812578201, -0.06499303132295609, -0.06271905452013016, -0.06044507771730423, -0.058171097189188004, -0.055897120386362076, -0.05362314358353615, -0.05134916678071022, -0.04907518997788429, -0.046801213175058365, -0.04452723264694214, -0.04225325584411621, -0.03997927904129028, -0.037705302238464355, -0.035431332886219025, -0.0331573560833931, -0.03088337928056717, -0.028609400615096092, -0.026335423812270164, -0.024061447009444237, -0.02178746834397316, -0.019513491541147232, -0.017239514738321304, -0.014965537935495377, -0.012691560201346874, -0.010417582467198372, -0.008143605664372444, -0.005869628861546516, -0.003595651127398014, -0.0013216733932495117, 0.000952303409576416, 0.003226280678063631, 0.005500257946550846, 0.007774235215038061, 0.010048212483525276, 0.012322189286351204, 0.014596167020499706, 0.01687014475464821, 0.019144121557474136, 0.021418098360300064, 0.023692075163125992, 0.02596605382859707, 0.028240030631422997, 0.030514007434248924, 0.03278798609972, 0.03506196290254593, 0.03733593970537186]}, "gradients/roberta.encoder.layer.8.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 4.0, 8.0, 11.0, 13.0, 18.0, 32.0, 53.0, 84.0, 192.0, 382.0, 887.0, 2136.0, 1235.0, 520.0, 260.0, 125.0, 62.0, 38.0, 27.0, 17.0, 8.0, 6.0, 3.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.02483217418193817, -0.02404867112636566, -0.023265168070793152, -0.022481665015220642, -0.021698161959648132, -0.020914658904075623, -0.020131155848503113, -0.019347650930285454, -0.018564147874712944, -0.017780644819140434, -0.016997141763567924, -0.016213638707995415, -0.01543013472110033, -0.01464663166552782, -0.01386312860995531, -0.013079624623060226, -0.012296122498810291, -0.011512619443237782, -0.010729116387665272, -0.009945612400770187, -0.009162109345197678, -0.008378606289625168, -0.007595103234052658, -0.006811599712818861, -0.006028096657246351, -0.0052445936016738415, -0.004461090080440044, -0.0036775870248675346, -0.0028940837364643812, -0.002110580448061228, -0.001327077392488718, -0.000543573871254921, 0.0002399291843175888, 0.0010234324727207422, 0.0018069356447085738, 0.0025904388166964054, 0.003373942105099559, 0.004157445393502712, 0.004940948449075222, 0.005724451970309019, 0.006507955025881529, 0.007291458081454039, 0.008074961602687836, 0.008858464658260345, 0.009641967713832855, 0.010425470769405365, 0.011208973824977875, 0.01199247781187296, 0.012775980867445469, 0.013559483923017979, 0.014342986978590488, 0.015126490965485573, 0.015909994021058083, 0.016693497076630592, 0.017477000132203102, 0.018260503187775612, 0.01904400624334812, 0.01982750929892063, 0.02061101235449314, 0.02139451541006565, 0.02217801846563816, 0.02296152338385582, 0.02374502643942833, 0.02452852949500084, 0.02531203255057335]}, "gradients/roberta.encoder.layer.8.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 10.0, 125.0, 2582.0, 3216.0, 182.0, 7.0, 6.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0], "bins": [-0.029650382697582245, -0.028753584250807762, -0.02785678580403328, -0.026959985494613647, -0.026063187047839165, -0.025166388601064682, -0.02426958829164505, -0.023372789844870567, -0.022475991398096085, -0.021579192951321602, -0.02068239450454712, -0.019785594195127487, -0.018888795748353004, -0.01799199730157852, -0.01709519699215889, -0.016198398545384407, -0.015301600098609924, -0.014404801651835442, -0.013508002273738384, -0.012611202895641327, -0.011714404448866844, -0.010817606002092361, -0.009920806623995304, -0.009024007245898247, -0.008127208799123764, -0.007230409886687994, -0.006333610974252224, -0.005436812061816454, -0.004540013149380684, -0.003643214236944914, -0.002746415324509144, -0.0018496164120733738, -0.0009528174996376038, -5.6018587201833725e-05, 0.0008407803252339363, 0.0017375792376697063, 0.0026343781501054764, 0.0035311770625412464, 0.0044279759749770164, 0.0053247748874127865, 0.0062215737998485565, 0.0071183727122843266, 0.008015171624720097, 0.008911971002817154, 0.009808769449591637, 0.01070556789636612, 0.011602367274463177, 0.012499166652560234, 0.013395965099334717, 0.0142927635461092, 0.015189562924206257, 0.016086362302303314, 0.016983160749077797, 0.01787995919585228, 0.01877675950527191, 0.019673557952046394, 0.020570356398820877, 0.02146715484559536, 0.022363953292369843, 0.023260753601789474, 0.024157552048563957, 0.02505435049533844, 0.025951150804758072, 0.026847949251532555, 0.027744747698307037]}, "gradients/roberta.encoder.layer.7.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 3.0, 1.0, 4.0, 2.0, 3.0, 6.0, 10.0, 14.0, 5.0, 12.0, 17.0, 19.0, 20.0, 36.0, 34.0, 40.0, 65.0, 54.0, 79.0, 112.0, 121.0, 156.0, 190.0, 245.0, 286.0, 320.0, 419.0, 473.0, 505.0, 487.0, 429.0, 313.0, 315.0, 265.0, 214.0, 173.0, 131.0, 100.0, 83.0, 72.0, 60.0, 49.0, 40.0, 34.0, 26.0, 18.0, 14.0, 15.0, 16.0, 7.0, 7.0, 5.0, 4.0, 4.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0], "bins": [-0.028984226286411285, -0.028068741783499718, -0.02715325728058815, -0.02623777464032173, -0.025322290137410164, -0.024406805634498596, -0.02349132113158703, -0.02257583662867546, -0.021660353988409042, -0.020744869485497475, -0.019829384982585907, -0.01891390234231949, -0.01799841783940792, -0.017082933336496353, -0.016167448833584785, -0.015251965261995792, -0.014336480759084225, -0.013420996256172657, -0.012505512684583664, -0.011590028181672096, -0.010674544610083103, -0.009759060107171535, -0.008843576535582542, -0.007928092032670975, -0.007012607995420694, -0.006097123958170414, -0.005181639920920134, -0.004266155883669853, -0.003350671613588929, -0.002435187343508005, -0.0015197033062577248, -0.0006042192690074444, 0.000311264768242836, 0.0012267488054931164, 0.0021422328427433968, 0.003057717112824321, 0.0039732009172439575, 0.004888685420155525, 0.005804169457405806, 0.006719653494656086, 0.007635137531906366, 0.008550621569156647, 0.009466106072068214, 0.010381589643657207, 0.011297074146568775, 0.012212557718157768, 0.013128042221069336, 0.014043526723980904, 0.014959010295569897, 0.01587449386715889, 0.016789978370070457, 0.017705462872982025, 0.018620947375893593, 0.01953643187880516, 0.02045191451907158, 0.021367399021983147, 0.022282883524894714, 0.023198368027806282, 0.02411385253071785, 0.025029335170984268, 0.025944819673895836, 0.026860304176807404, 0.02777578867971897, 0.02869127318263054, 0.029606755822896957]}, "gradients/roberta.encoder.layer.7.attention.self.value.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 8.0, 18.0, 1637.0, 4426.0, 27.0, 10.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0], "bins": [-0.130290225148201, -0.12623338401317596, -0.12217655777931213, -0.1181197240948677, -0.11406289041042328, -0.11000605672597885, -0.10594922304153442, -0.1018923819065094, -0.09783555567264557, -0.09377872198820114, -0.08972188830375671, -0.08566505461931229, -0.08160822093486786, -0.07755138725042343, -0.073494553565979, -0.06943771243095398, -0.06538087874650955, -0.061324045062065125, -0.0572672113776207, -0.05321037769317627, -0.04915354400873184, -0.045096710324287415, -0.04103987291455269, -0.03698303923010826, -0.032926205545663834, -0.028869371861219406, -0.02481253817677498, -0.020755702629685402, -0.016698868945240974, -0.012642035260796547, -0.00858519971370697, -0.004528366029262543, -0.00047153234481811523, 0.0035853018052875996, 0.007642135955393314, 0.011698970571160316, 0.015755804255604744, 0.01981263794004917, 0.023869473487138748, 0.027926307171583176, 0.0319831408560276, 0.03603997454047203, 0.04009680822491646, 0.044153645634651184, 0.04821047931909561, 0.05226731300354004, 0.05632414668798447, 0.060380980372428894, 0.06443781405687332, 0.06849464774131775, 0.07255148142576218, 0.0766083151102066, 0.08066514879465103, 0.08472198247909546, 0.08877882361412048, 0.09283564984798431, 0.09689249098300934, 0.10094932466745377, 0.1050061583518982, 0.10906299203634262, 0.11311982572078705, 0.11717665940523148, 0.1212334930896759, 0.12529033422470093, 0.12934716045856476]}, "gradients/roberta.encoder.layer.7.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0, 3.0, 5.0, 15.0, 13.0, 18.0, 23.0, 23.0, 52.0, 96.0, 134.0, 258.0, 517.0, 1052.0, 1905.0, 961.0, 448.0, 224.0, 119.0, 67.0, 50.0, 36.0, 17.0, 19.0, 12.0, 10.0, 4.0, 4.0, 5.0, 6.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.015614436939358711, -0.015133286826312542, -0.014652136713266373, -0.014170986600220203, -0.013689836487174034, -0.01320868730545044, -0.01272753719240427, -0.012246387079358101, -0.011765236966311932, -0.011284086853265762, -0.010802936740219593, -0.010321786627173424, -0.009840637445449829, -0.009359486401081085, -0.00887833721935749, -0.008397187106311321, -0.007916036993265152, -0.007434886880218983, -0.006953736767172813, -0.0064725871197879314, -0.005991437006741762, -0.005510286893695593, -0.005029137246310711, -0.004547987133264542, -0.004066837020218372, -0.003585686907172203, -0.0031045370269566774, -0.002623387146741152, -0.0021422370336949825, -0.0016610869206488132, -0.0011799370404332876, -0.000698787160217762, -0.0002176370471715927, 0.00026351294945925474, 0.0007446629460901022, 0.0012258129427209496, 0.001706962939351797, 0.0021881130523979664, 0.002669262932613492, 0.0031504128128290176, 0.003631562925875187, 0.004112713038921356, 0.0045938631519675255, 0.0050750127993524075, 0.005556162912398577, 0.006037313025444746, 0.006518462672829628, 0.006999612785875797, 0.0074807628989219666, 0.007961913011968136, 0.008443063125014305, 0.008924213238060474, 0.009405363351106644, 0.009886512532830238, 0.010367662645876408, 0.010848812758922577, 0.011329962871968746, 0.011811112985014915, 0.012292263098061085, 0.012773413211107254, 0.013254562392830849, 0.013735713437199593, 0.014216862618923187, 0.014698012731969357, 0.015179162845015526]}, "gradients/roberta.encoder.layer.7.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 4.0, 7.0, 12.0, 131.0, 4360.0, 1535.0, 62.0, 14.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.0504465252161026, -0.048564013093709946, -0.04668150097131729, -0.04479898884892464, -0.04291647672653198, -0.04103396460413933, -0.039151452481746674, -0.03726894035935402, -0.035386428236961365, -0.03350391611456871, -0.031621403992176056, -0.0297388918697834, -0.027856379747390747, -0.025973867624998093, -0.024091355502605438, -0.022208843380212784, -0.02032633125782013, -0.018443819135427475, -0.01656130701303482, -0.014678794890642166, -0.012796282768249512, -0.010913770645856857, -0.009031258523464203, -0.0071487464010715485, -0.005266234278678894, -0.0033837221562862396, -0.0015012100338935852, 0.0003813020884990692, 0.0022638142108917236, 0.004146326333284378, 0.0060288384556770325, 0.007911350578069687, 0.009793862700462341, 0.011676374822854996, 0.01355888694524765, 0.015441399067640305, 0.01732391119003296, 0.019206423312425613, 0.021088935434818268, 0.022971447557210922, 0.024853959679603577, 0.02673647180199623, 0.028618983924388885, 0.03050149604678154, 0.032384008169174194, 0.03426652029156685, 0.0361490324139595, 0.03803154453635216, 0.03991405665874481, 0.041796568781137466, 0.04367908090353012, 0.045561593025922775, 0.04744410514831543, 0.049326617270708084, 0.05120912939310074, 0.05309164151549339, 0.05497415363788605, 0.0568566657602787, 0.058739177882671356, 0.06062169000506401, 0.06250420212745667, 0.06438671052455902, 0.06626922637224197, 0.06815174221992493, 0.07003425061702728]}, "gradients/roberta.encoder.layer.6.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 7.0, 1.0, 5.0, 6.0, 4.0, 7.0, 12.0, 21.0, 34.0, 42.0, 51.0, 70.0, 99.0, 117.0, 170.0, 231.0, 310.0, 413.0, 838.0, 1228.0, 797.0, 431.0, 313.0, 224.0, 179.0, 118.0, 98.0, 80.0, 65.0, 40.0, 41.0, 18.0, 15.0, 14.0, 10.0, 2.0, 5.0, 5.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.04093031957745552, -0.03970955312252045, -0.03848879039287567, -0.0372680239379406, -0.036047257483005524, -0.03482649102807045, -0.033605724573135376, -0.0323849618434906, -0.031164195388555527, -0.029943428933620453, -0.028722664341330528, -0.027501899749040604, -0.02628113329410553, -0.025060366839170456, -0.02383960224688053, -0.022618837654590607, -0.021398071199655533, -0.02017730474472046, -0.018956540152430534, -0.01773577556014061, -0.016515009105205536, -0.015294243581593037, -0.014073478057980537, -0.012852712534368038, -0.011631947010755539, -0.01041118148714304, -0.00919041596353054, -0.007969650439918041, -0.006748884916305542, -0.005528119392693043, -0.0043073538690805435, -0.0030865883454680443, -0.0018658265471458435, -0.0006450610235333443, 0.000575704500079155, 0.0017964700236916542, 0.0030172355473041534, 0.004238001070916653, 0.005458766594529152, 0.006679532118141651, 0.00790029764175415, 0.00912106316536665, 0.010341828688979149, 0.011562594212591648, 0.012783359736204147, 0.014004125259816647, 0.015224890783429146, 0.01644565537571907, 0.017666421830654144, 0.018887188285589218, 0.020107952877879143, 0.021328717470169067, 0.02254948392510414, 0.023770250380039215, 0.02499101497232914, 0.026211779564619064, 0.027432546019554138, 0.028653312474489212, 0.029874077066779137, 0.03109484165906906, 0.032315608114004135, 0.03353637456893921, 0.034757137298583984, 0.03597790375351906, 0.03719867020845413]}, "gradients/roberta.encoder.layer.6.attention.self.value.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 7.0, 6.0, 14.0, 26.0, 1220.0, 4548.0, 269.0, 10.0, 7.0, 6.0, 4.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.013973202556371689, -0.01331784576177597, -0.012662488967180252, -0.012007132172584534, -0.01135177444666624, -0.010696417652070522, -0.010041060857474804, -0.009385703131556511, -0.008730346336960793, -0.008074989542365074, -0.0074196322821080685, -0.00676427548751235, -0.006108918227255344, -0.005453561432659626, -0.004798204638063908, -0.004142847377806902, -0.003487491048872471, -0.002832134021446109, -0.0021767769940197468, -0.0015214201994240284, -0.0008660631719976664, -0.00021070614457130432, 0.00044465065002441406, 0.0011000079102814198, 0.0017553647048771381, 0.0024107217323035, 0.003066078759729862, 0.0037214355543255806, 0.004376792348921299, 0.005032149609178305, 0.005687506403774023, 0.006342863664031029, 0.006998220458626747, 0.0076535772532224655, 0.008308934047818184, 0.008964290842413902, 0.009619648568332195, 0.010275005362927914, 0.010930362157523632, 0.011585719883441925, 0.012241076678037643, 0.012896433472633362, 0.01355179026722908, 0.014207147061824799, 0.014862504787743092, 0.01551786158233881, 0.016173217445611954, 0.01682857610285282, 0.01748393103480339, 0.01813928782939911, 0.018794644623994827, 0.019450001418590546, 0.020105358213186264, 0.020760715007781982, 0.0214160718023777, 0.02207143045961857, 0.022726787254214287, 0.023382144048810005, 0.024037500843405724, 0.024692857638001442, 0.02534821443259716, 0.026003573089838028, 0.026658929884433746, 0.027314286679029465, 0.027969643473625183]}, "gradients/roberta.encoder.layer.6.attention.self.query.lora_B": {"_type": "histogram", "values": [2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 4.0, 6.0, 7.0, 12.0, 30.0, 20.0, 38.0, 77.0, 132.0, 266.0, 500.0, 1143.0, 1430.0, 1182.0, 623.0, 295.0, 135.0, 63.0, 51.0, 31.0, 20.0, 22.0, 5.0, 5.0, 8.0, 9.0, 4.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.010761408135294914, -0.010304505005478859, -0.009847602806985378, -0.009390699677169323, -0.008933797478675842, -0.008476894348859787, -0.008019992150366306, -0.007563089020550251, -0.00710618682205677, -0.006649284157902002, -0.006192381493747234, -0.005735478829592466, -0.005278576165437698, -0.004821673035621643, -0.004364770837128162, -0.003907867707312107, -0.003450965043157339, -0.002994062379002571, -0.002537159714847803, -0.002080257050693035, -0.0016233542701229453, -0.0011664514895528555, -0.0007095488253980875, -0.0002526461612433195, 0.00020425650291144848, 0.0006611591670662165, 0.0011180618312209845, 0.0015749646117910743, 0.002031867392361164, 0.002488770056515932, 0.0029456727206707, 0.003402575384825468, 0.003859478048980236, 0.004316380713135004, 0.004773283377289772, 0.00523018604144454, 0.005687088705599308, 0.006143991835415363, 0.006600894033908844, 0.007057797163724899, 0.00751469936221838, 0.007971602492034435, 0.008428504690527916, 0.008885407820343971, 0.009342310018837452, 0.009799213148653507, 0.010256115347146988, 0.010713018476963043, 0.011169921606779099, 0.011626824736595154, 0.012083726935088634, 0.01254063006490469, 0.01299753226339817, 0.013454435393214226, 0.013911337591707706, 0.014368240721523762, 0.014825142920017242, 0.015282046049833298, 0.015738949179649353, 0.01619585044682026, 0.016652753576636314, 0.01710965670645237, 0.017566559836268425, 0.01802346110343933, 0.018480364233255386]}, "gradients/roberta.encoder.layer.6.attention.self.query.lora_A": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 7.0, 9.0, 277.0, 4170.0, 1588.0, 59.0, 11.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.023135198280215263, -0.022236905992031097, -0.02133861556649208, -0.020440323278307915, -0.01954203099012375, -0.018643740564584732, -0.017745448276400566, -0.0168471559882164, -0.015948865562677383, -0.015050574205815792, -0.014152281917631626, -0.013253990560770035, -0.012355698272585869, -0.011457406915724277, -0.010559115558862686, -0.00966082327067852, -0.008762530982494354, -0.007864239625632763, -0.006965947337448597, -0.006067655980587006, -0.005169364158064127, -0.004271072335541248, -0.003372780978679657, -0.0024744891561567783, -0.0015761973336338997, -0.0006779056275263429, 0.00022038607858121395, 0.001118677668273449, 0.0020169694907963276, 0.0029152613133192062, 0.0038135526701807976, 0.004711844492703676, 0.005610138177871704, 0.006508430000394583, 0.007406721822917461, 0.008305013179779053, 0.009203305467963219, 0.01010159682482481, 0.010999888181686401, 0.011898180469870567, 0.012796471826732159, 0.01369476318359375, 0.014593055471777916, 0.015491346828639507, 0.0163896381855011, 0.017287930473685265, 0.01818622276186943, 0.019084513187408447, 0.019982805475592613, 0.02088109776377678, 0.021779388189315796, 0.022677680477499962, 0.023575972765684128, 0.024474263191223145, 0.02537255547940731, 0.026270847767591476, 0.027169138193130493, 0.02806743048131466, 0.028965720906853676, 0.029864013195037842, 0.030762305483222008, 0.031660597771406174, 0.03255888819694519, 0.03345717862248421, 0.03435547277331352]}, "gradients/roberta.encoder.layer.5.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 5.0, 1.0, 3.0, 5.0, 9.0, 11.0, 9.0, 19.0, 21.0, 20.0, 25.0, 41.0, 49.0, 57.0, 71.0, 121.0, 111.0, 187.0, 198.0, 282.0, 336.0, 387.0, 441.0, 501.0, 565.0, 504.0, 426.0, 354.0, 275.0, 240.0, 174.0, 156.0, 109.0, 83.0, 84.0, 58.0, 47.0, 33.0, 22.0, 20.0, 12.0, 13.0, 11.0, 9.0, 12.0, 4.0, 1.0, 5.0, 2.0, 1.0, 1.0, 4.0, 2.0], "bins": [-0.03856125846505165, -0.03746802732348442, -0.03637479990720749, -0.03528156876564026, -0.03418834134936333, -0.0330951102077961, -0.032001882791519165, -0.030908651649951935, -0.029815422371029854, -0.028722193092107773, -0.027628963813185692, -0.02653573453426361, -0.02544250339269638, -0.02434927597641945, -0.02325604483485222, -0.022162815555930138, -0.021069586277008057, -0.019976356998085976, -0.018883127719163895, -0.017789898440241814, -0.016696669161319733, -0.015603438951075077, -0.014510208740830421, -0.01341697946190834, -0.01232375018298626, -0.011230520904064178, -0.010137291625142097, -0.009044061414897442, -0.007950832135975361, -0.00685760285705328, -0.005764373112469912, -0.004671143367886543, -0.0035779178142547607, -0.002484688302502036, -0.0013914587907493114, -0.0002982292789965868, 0.0007950002327561378, 0.0018882295116782188, 0.002981459256261587, 0.0040746890008449554, 0.0051679182797670364, 0.006261147558689117, 0.007354377303272486, 0.008447607047855854, 0.009540836326777935, 0.010634065605700016, 0.011727295815944672, 0.012820525094866753, 0.013913754373788834, 0.015006983652710915, 0.016100212931632996, 0.017193442210555077, 0.018286671489477158, 0.019379902631044388, 0.02047313190996647, 0.02156636118888855, 0.02265959046781063, 0.023752819746732712, 0.024846049025654793, 0.025939278304576874, 0.027032509446144104, 0.028125736862421036, 0.029218968003988266, 0.030312197282910347, 0.03140542656183243]}, "gradients/roberta.encoder.layer.5.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 7.0, 12.0, 141.0, 4809.0, 1119.0, 21.0, 6.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04080292955040932, -0.03927532583475113, -0.03774772211909294, -0.03622011840343475, -0.034692518413066864, -0.033164914697408676, -0.03163731098175049, -0.0301097072660923, -0.028582105413079262, -0.027054501697421074, -0.025526899844408035, -0.023999296128749847, -0.02247169241309166, -0.02094409056007862, -0.019416486844420433, -0.017888884991407394, -0.016361281275749207, -0.014833678491413593, -0.01330607570707798, -0.011778471991419792, -0.010250869207084179, -0.008723266422748566, -0.007195662707090378, -0.0056680599227547646, -0.004140457138419151, -0.0026128541212528944, -0.0010852511040866375, 0.00044235214591026306, 0.0019699549302458763, 0.0034975577145814896, 0.005025161430239677, 0.006552764214575291, 0.008080363273620605, 0.009607966057956219, 0.011135568842291832, 0.01266317255795002, 0.014190775342285633, 0.015718378126621246, 0.017245981842279434, 0.018773585557937622, 0.02030118741095066, 0.02182879112660885, 0.023356392979621887, 0.024883996695280075, 0.026411600410938263, 0.0279392022639513, 0.02946680597960949, 0.030994407832622528, 0.032522011548280716, 0.034049615263938904, 0.03557721897959709, 0.03710482269525528, 0.03863242268562317, 0.04016002640128136, 0.041687630116939545, 0.04321523383259773, 0.04474283754825592, 0.04627044126391411, 0.047798044979572296, 0.049325644969940186, 0.05085324868559837, 0.05238085240125656, 0.05390845611691475, 0.05543605983257294, 0.056963659822940826]}, "gradients/roberta.encoder.layer.5.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 3.0, 6.0, 10.0, 33.0, 47.0, 107.0, 350.0, 1147.0, 2182.0, 1464.0, 471.0, 142.0, 64.0, 41.0, 21.0, 12.0, 5.0, 5.0, 6.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.011596344411373138, -0.010973984375596046, -0.010351624339818954, -0.009729264304041862, -0.00910690426826477, -0.008484544232487679, -0.007862184196710587, -0.007239824160933495, -0.006617464125156403, -0.005995104089379311, -0.005372744053602219, -0.004750384017825127, -0.004128023982048035, -0.0035056639462709427, -0.0028833039104938507, -0.0022609438747167587, -0.0016385838389396667, -0.0010162238031625748, -0.0003938637673854828, 0.0002284962683916092, 0.0008508563041687012, 0.0014732163399457932, 0.002095576375722885, 0.002717936411499977, 0.003340296447277069, 0.003962656483054161, 0.004585016518831253, 0.005207376554608345, 0.005829736590385437, 0.006452096626162529, 0.007074456661939621, 0.007696816697716713, 0.008319176733493805, 0.008941536769270897, 0.009563896805047989, 0.010186256840825081, 0.010808616876602173, 0.011430976912379265, 0.012053336948156357, 0.012675696983933449, 0.01329805701971054, 0.013920417055487633, 0.014542777091264725, 0.015165137127041817, 0.01578749716281891, 0.016409857198596, 0.017032217234373093, 0.017654577270150185, 0.018276937305927277, 0.01889929734170437, 0.01952165737748146, 0.020144017413258553, 0.020766377449035645, 0.021388737484812737, 0.02201109752058983, 0.02263345755636692, 0.023255817592144012, 0.023878177627921104, 0.024500537663698196, 0.02512289769947529, 0.02574525773525238, 0.026367617771029472, 0.026989977806806564, 0.027612337842583656, 0.02823469787836075]}, "gradients/roberta.encoder.layer.5.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 5.0, 7.0, 18.0, 18.0, 42.0, 169.0, 437.0, 1006.0, 1569.0, 1567.0, 809.0, 278.0, 118.0, 51.0, 23.0, 9.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.008030225522816181, -0.007792964577674866, -0.007555704098194838, -0.007318443153053522, -0.007081182673573494, -0.0068439217284321785, -0.006606660783290863, -0.006369400303810835, -0.006132139358669519, -0.005894878413528204, -0.005657617934048176, -0.00542035698890686, -0.005183096509426832, -0.004945835564285517, -0.004708575084805489, -0.004471314139664173, -0.004234053194522858, -0.003996792249381542, -0.003759531769901514, -0.0035222708247601986, -0.003285010112449527, -0.003047749400138855, -0.002810488687828183, -0.0025732279755175114, -0.002335967496037483, -0.0020987067837268114, -0.0018614459550008178, -0.001624185242690146, -0.0013869244139641523, -0.0011496637016534805, -0.0009124029893428087, -0.0006751421606168151, -0.00043788133189082146, -0.00020062057592440397, 3.6640180042013526e-05, 0.0002739009214565158, 0.0005111616919748485, 0.0007484224624931812, 0.000985683174803853, 0.0012229440035298467, 0.0014602047158405185, 0.0016974654281511903, 0.001934726256877184, 0.0021719869691878557, 0.0024092476814985275, 0.002646508626639843, 0.002883769106119871, 0.0031210300512611866, 0.0033582907635718584, 0.00359555147588253, 0.003832812188193202, 0.004070072900503874, 0.004307333845645189, 0.0045445943251252174, 0.004781855270266533, 0.005019116215407848, 0.0052563766948878765, 0.005493637640029192, 0.00573089811950922, 0.005968159064650536, 0.006205419544130564, 0.006442680489271879, 0.006679940968751907, 0.006917201913893223, 0.007154462859034538]}, "gradients/roberta.encoder.layer.4.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 5.0, 5.0, 5.0, 5.0, 5.0, 11.0, 8.0, 29.0, 27.0, 36.0, 42.0, 59.0, 83.0, 88.0, 125.0, 166.0, 202.0, 299.0, 392.0, 552.0, 718.0, 753.0, 650.0, 472.0, 357.0, 229.0, 183.0, 143.0, 119.0, 93.0, 55.0, 52.0, 39.0, 35.0, 24.0, 22.0, 10.0, 11.0, 3.0, 8.0, 2.0, 8.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.026537569239735603, -0.02571471966803074, -0.024891870096325874, -0.02406901866197586, -0.023246169090270996, -0.02242331951856613, -0.021600469946861267, -0.020777620375156403, -0.019954770803451538, -0.019131921231746674, -0.01830907166004181, -0.017486222088336945, -0.01666337065398693, -0.015840521082282066, -0.015017671510577202, -0.014194821938872337, -0.013371971435844898, -0.012549121864140034, -0.011726271361112595, -0.01090342178940773, -0.010080572217702866, -0.009257722645998001, -0.008434872142970562, -0.0076120225712656975, -0.006789172533899546, -0.005966322496533394, -0.005143472924828529, -0.0043206228874623775, -0.0034977730829268694, -0.0026749232783913612, -0.0018520732410252094, -0.001029223669320345, -0.00020637363195419312, 0.000616476230788976, 0.001439326093532145, 0.002262176014482975, 0.003085025819018483, 0.003907875623553991, 0.004730725660920143, 0.005553575232625008, 0.0063764252699911594, 0.007199275307357311, 0.008022124879062176, 0.008844975382089615, 0.00966782495379448, 0.010490674525499344, 0.011313524097204208, 0.012136373668909073, 0.012959224171936512, 0.013782073743641376, 0.014604924246668816, 0.01542777381837368, 0.016250623390078545, 0.01707347296178341, 0.017896324396133423, 0.018719173967838287, 0.019542023539543152, 0.020364873111248016, 0.02118772268295288, 0.022010572254657745, 0.02283342368900776, 0.023656273260712624, 0.024479122832417488, 0.025301972404122353, 0.026124821975827217]}, "gradients/roberta.encoder.layer.4.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 8.0, 430.0, 5655.0, 35.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.08189472556114197, -0.0797559916973114, -0.07761725038290024, -0.07547851651906967, -0.07333977520465851, -0.07120104134082794, -0.06906230747699738, -0.06692356616258621, -0.06478483229875565, -0.06264609843492508, -0.060507357120513916, -0.05836862325668335, -0.056229885667562485, -0.05409114807844162, -0.051952410489320755, -0.04981367290019989, -0.047674935311079025, -0.04553619772195816, -0.043397460132837296, -0.04125872254371643, -0.039119988679885864, -0.036981251090765, -0.034842513501644135, -0.03270377591252327, -0.030565040186047554, -0.02842630259692669, -0.026287566870450974, -0.02414882928133011, -0.022010091692209244, -0.019871355965733528, -0.017732618376612663, -0.015593881718814373, -0.013455145061016083, -0.011316408403217793, -0.009177671745419502, -0.007038934156298637, -0.004900197498500347, -0.002761460840702057, -0.000622723251581192, 0.0015160134062170982, 0.0036547500640153885, 0.005793486721813679, 0.007932223379611969, 0.010070960968732834, 0.012209697626531124, 0.014348434284329414, 0.01648717187345028, 0.018625907599925995, 0.02076464518904686, 0.022903382778167725, 0.02504211850464344, 0.027180856093764305, 0.02931959182024002, 0.031458329409360886, 0.03359706699848175, 0.035735804587602615, 0.03787454217672348, 0.040013279765844345, 0.04215201735496521, 0.044290751218795776, 0.04642948880791664, 0.048568226397037506, 0.05070696398615837, 0.052845701575279236, 0.0549844354391098]}, "gradients/roberta.encoder.layer.4.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 8.0, 3.0, 23.0, 24.0, 21.0, 48.0, 63.0, 106.0, 156.0, 259.0, 444.0, 848.0, 1147.0, 1106.0, 707.0, 471.0, 258.0, 146.0, 81.0, 57.0, 39.0, 28.0, 22.0, 14.0, 8.0, 10.0, 5.0, 6.0, 3.0, 2.0, 3.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.0044349669478833675, -0.004281654953956604, -0.0041283429600298405, -0.003975030966103077, -0.0038217189721763134, -0.00366840697824955, -0.0035150947514921427, -0.003361782757565379, -0.0032084707636386156, -0.003055158769711852, -0.0029018467757850885, -0.002748534781858325, -0.002595222555100918, -0.0024419105611741543, -0.0022885985672473907, -0.002135286573320627, -0.0019819745793938637, -0.0018286625854671001, -0.0016753505915403366, -0.0015220384811982512, -0.0013687264872714877, -0.0012154144933447242, -0.0010621023830026388, -0.0009087903890758753, -0.0007554783951491117, -0.0006021664012223482, -0.00044885434908792377, -0.0002955423260573298, -0.00014223030302673578, 1.1081690900027752e-05, 0.0001643937430344522, 0.00031770579516887665, 0.0004710173234343529, 0.0006243293173611164, 0.0007776413694955409, 0.0009309534216299653, 0.0010842654155567288, 0.0012375774094834924, 0.0013908895198255777, 0.0015442015137523413, 0.0016975135076791048, 0.0018508255016058683, 0.002004137495532632, 0.0021574494894593954, 0.0023107617162168026, 0.002464073710143566, 0.0026173857040703297, 0.002770697697997093, 0.0029240096919238567, 0.0030773216858506203, 0.003230633679777384, 0.0033839456737041473, 0.003537257667630911, 0.0036905696615576744, 0.0038438818883150816, 0.0039971936494112015, 0.004150506108999252, 0.004303818102926016, 0.004457130096852779, 0.004610442090779543, 0.0047637540847063065, 0.00491706607863307, 0.0050703780725598335, 0.005223690532147884, 0.005377002060413361]}, "gradients/roberta.encoder.layer.4.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 15.0, 39.0, 150.0, 823.0, 3177.0, 1549.0, 284.0, 63.0, 12.0, 8.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.013975018635392189, -0.013662433251738548, -0.013349846936762333, -0.013037261553108692, -0.012724675238132477, -0.012412089854478836, -0.012099504470825195, -0.01178691815584898, -0.01147433277219534, -0.011161747388541698, -0.010849161073565483, -0.010536575689911842, -0.010223989374935627, -0.009911403991281986, -0.009598817676305771, -0.00928623229265213, -0.00897364690899849, -0.008661061525344849, -0.008348475210368633, -0.008035889826714993, -0.0077233039774000645, -0.007410718128085136, -0.007098132278770208, -0.00678554642945528, -0.006472960114479065, -0.006160374265164137, -0.005847788415849209, -0.005535203032195568, -0.00522261718288064, -0.004910031333565712, -0.004597445484250784, -0.004284859634935856, -0.003972274251282215, -0.003659688401967287, -0.0033471027854830027, -0.0030345169361680746, -0.00272193131968379, -0.002409345470368862, -0.002096759621053934, -0.0017841740045696497, -0.0014715881552547216, -0.0011590024223551154, -0.0008464166312478483, -0.0005338308401405811, -0.0002212451072409749, 9.134062565863132e-05, 0.0004039264749735594, 0.0007165120914578438, 0.0010290979407727718, 0.001341683673672378, 0.0016542694065719843, 0.0019668552558869123, 0.0022794408723711967, 0.002592026721686125, 0.002904612571001053, 0.0032171981874853373, 0.0035297840368002653, 0.0038423698861151934, 0.004154955502599478, 0.004467541351914406, 0.004780127201229334, 0.005092713050544262, 0.005405298434197903, 0.005717884283512831, 0.006030470132827759]}, "gradients/roberta.encoder.layer.3.attention.self.value.lora_B": {"_type": "histogram", "values": [2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 5.0, 2.0, 7.0, 5.0, 13.0, 11.0, 13.0, 29.0, 21.0, 31.0, 45.0, 52.0, 64.0, 69.0, 77.0, 113.0, 115.0, 149.0, 160.0, 217.0, 285.0, 328.0, 680.0, 1182.0, 600.0, 347.0, 258.0, 243.0, 193.0, 173.0, 116.0, 85.0, 86.0, 70.0, 50.0, 51.0, 38.0, 29.0, 21.0, 17.0, 22.0, 9.0, 11.0, 10.0, 5.0, 4.0, 5.0, 1.0, 1.0, 2.0, 3.0, 1.0, 4.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.031391844153404236, -0.03035939484834671, -0.029326947405934334, -0.028294499963521957, -0.027262050658464432, -0.026229601353406906, -0.02519715391099453, -0.024164706468582153, -0.023132257163524628, -0.022099807858467102, -0.021067360416054726, -0.02003491297364235, -0.019002463668584824, -0.017970014363527298, -0.01693756692111492, -0.015905119478702545, -0.01487267017364502, -0.013840221799910069, -0.012807773426175117, -0.011775325052440166, -0.010742876678705215, -0.009710428304970264, -0.008677979931235313, -0.007645531557500362, -0.006613083183765411, -0.00558063481003046, -0.004548186436295509, -0.0035157380625605583, -0.0024832896888256073, -0.0014508413150906563, -0.00041839294135570526, 0.0006140554323792458, 0.0016465075314044952, 0.0026789559051394463, 0.0037114042788743973, 0.004743852652609348, 0.005776301026344299, 0.00680874940007925, 0.007841197773814201, 0.008873646147549152, 0.009906094521284103, 0.010938542895019054, 0.011970991268754005, 0.013003439642488956, 0.014035888016223907, 0.015068336389958858, 0.01610078476369381, 0.017133232206106186, 0.01816568151116371, 0.019198130816221237, 0.020230578258633614, 0.02126302570104599, 0.022295475006103516, 0.02332792431116104, 0.024360371753573418, 0.025392819195985794, 0.02642526850104332, 0.027457717806100845, 0.028490165248513222, 0.029522612690925598, 0.030555061995983124, 0.03158751130104065, 0.032619960606098175, 0.0336524061858654, 0.03468485549092293]}, "gradients/roberta.encoder.layer.3.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 7.0, 4.0, 3977.0, 2141.0, 1.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0], "bins": [-0.07878239452838898, -0.07675936073064804, -0.0747363269329071, -0.07271329313516617, -0.07069025933742523, -0.0686672255396843, -0.06664419174194336, -0.06462115794420242, -0.06259812414646149, -0.06057509034872055, -0.058552056550979614, -0.05652902275323868, -0.05450598895549774, -0.052482955157756805, -0.05045992136001587, -0.04843688756227493, -0.046413857489824295, -0.04439082369208336, -0.04236778989434242, -0.040344756096601486, -0.03832172229886055, -0.036298688501119614, -0.034275658428668976, -0.03225262463092804, -0.030229588970541954, -0.028206555172801018, -0.02618352137506008, -0.024160489439964294, -0.022137455642223358, -0.020114421844482422, -0.018091388046741486, -0.01606835424900055, -0.014045320451259613, -0.012022286653518677, -0.00999925285577774, -0.007976219989359379, -0.0059531861916184425, -0.003930152393877506, -0.0019071195274591446, 0.00011591427028179169, 0.002138948068022728, 0.004161981865763664, 0.006185015197843313, 0.008208048529922962, 0.010231082327663898, 0.012254116125404835, 0.014277148991823196, 0.016300182789564133, 0.01832321658730507, 0.020346250385046005, 0.02236928418278694, 0.024392317980527878, 0.026415351778268814, 0.02843838557600975, 0.030461417511105537, 0.032484449446201324, 0.03450748324394226, 0.0365305170416832, 0.03855355083942413, 0.04057658463716507, 0.042599618434906006, 0.04462265223264694, 0.04664568603038788, 0.048668719828128815, 0.05069175362586975]}, "gradients/roberta.encoder.layer.3.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 4.0, 2.0, 4.0, 2.0, 6.0, 3.0, 2.0, 4.0, 3.0, 6.0, 6.0, 20.0, 24.0, 27.0, 53.0, 104.0, 161.0, 374.0, 626.0, 954.0, 1117.0, 1015.0, 690.0, 389.0, 199.0, 108.0, 85.0, 45.0, 23.0, 29.0, 18.0, 10.0, 7.0, 4.0, 2.0, 4.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.006985627114772797, -0.006789505947381258, -0.006593384779989719, -0.006397264078259468, -0.0062011429108679295, -0.006005021743476391, -0.005808900576084852, -0.005612779408693314, -0.005416658706963062, -0.005220537539571524, -0.005024416372179985, -0.004828295670449734, -0.004632174503058195, -0.0044360533356666565, -0.004239932168275118, -0.004043811000883579, -0.0038476900663226843, -0.0036515688989311457, -0.0034554479643702507, -0.003259326796978712, -0.003063205862417817, -0.0028670846950262785, -0.0026709637604653835, -0.002474842593073845, -0.0022787214256823063, -0.0020826002582907677, -0.0018864793237298727, -0.001690358156338334, -0.0014942372217774391, -0.0012981160543859005, -0.0011019950034096837, -0.0009058739524334669, -0.0007097530178725719, -0.0005136319668963552, -0.0003175108868163079, -0.00012138980673626065, 7.473124423995614e-05, 0.00027085235342383385, 0.00046697340440005064, 0.0006630944553762674, 0.0008592155063524842, 0.001055336557328701, 0.0012514576083049178, 0.0014475786592811346, 0.0016436998266726732, 0.00183982087764889, 0.002035941928625107, 0.0022320630960166454, 0.0024281840305775404, 0.002624305197969079, 0.002820426132529974, 0.0030165472999215126, 0.0032126682344824076, 0.003408789401873946, 0.003604910336434841, 0.0038010315038263798, 0.003997152671217918, 0.004193273838609457, 0.004389395006000996, 0.004585515707731247, 0.004781636875122786, 0.004977758042514324, 0.005173879209905863, 0.005370000377297401, 0.005566121079027653]}, "gradients/roberta.encoder.layer.3.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 4.0, 22.0, 139.0, 763.0, 2709.0, 1995.0, 419.0, 65.0, 11.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.004174675792455673, -0.00394028052687645, -0.0037058850284665823, -0.003471489530056715, -0.0032370942644774914, -0.003002698766067624, -0.002768303267657757, -0.002533908002078533, -0.002299512503668666, -0.0020651170052587986, -0.001830721739679575, -0.0015963262412697077, -0.0013619308592751622, -0.0011275354772806168, -0.0008931399788707495, -0.000658744596876204, -0.00042434921488165855, -0.00018995380378328264, 4.444160731509328e-05, 0.00027883704751729965, 0.0005132324295118451, 0.0007476278115063906, 0.0009820233099162579, 0.0012164186919108033, 0.0014508140739053488, 0.0016852094558998942, 0.0019196048378944397, 0.002154000336304307, 0.0023883958347141743, 0.002622791100293398, 0.002857186598703265, 0.0030915820971131325, 0.003325977362692356, 0.0035603728611022234, 0.003794768126681447, 0.004029163625091314, 0.004263558890670538, 0.004497954621911049, 0.0047323498874902725, 0.004966745153069496, 0.00520114041864872, 0.005435535684227943, 0.005669931415468454, 0.005904326681047678, 0.006138721946626902, 0.006373117677867413, 0.006607512943446636, 0.00684190820902586, 0.007076303940266371, 0.007310699205845594, 0.007545094937086105, 0.007779490202665329, 0.008013885468244553, 0.008248280733823776, 0.008482675999403, 0.008717072196304798, 0.008951467461884022, 0.009185862727463245, 0.009420257993042469, 0.009654654189944267, 0.009889049455523491, 0.010123444721102715, 0.010357839986681938, 0.010592235252261162, 0.010826630517840385]}, "gradients/roberta.encoder.layer.2.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 10.0, 2.0, 8.0, 12.0, 13.0, 19.0, 32.0, 34.0, 37.0, 68.0, 59.0, 76.0, 84.0, 109.0, 102.0, 118.0, 163.0, 192.0, 250.0, 284.0, 366.0, 455.0, 511.0, 496.0, 486.0, 386.0, 311.0, 272.0, 193.0, 188.0, 133.0, 111.0, 108.0, 93.0, 75.0, 57.0, 38.0, 40.0, 27.0, 27.0, 18.0, 15.0, 11.0, 8.0, 10.0, 6.0, 5.0, 6.0, 4.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0], "bins": [-0.02733159437775612, -0.026482410728931427, -0.025633227080106735, -0.024784043431282043, -0.023934857919812202, -0.02308567427098751, -0.02223649062216282, -0.021387306973338127, -0.020538121461868286, -0.019688937813043594, -0.018839754164218903, -0.01799057051539421, -0.01714138500392437, -0.016292201355099678, -0.015443017706274986, -0.014593834057450294, -0.013744650408625603, -0.012895466759800911, -0.012046282179653645, -0.011197098530828953, -0.010347913950681686, -0.009498730301856995, -0.008649546653032303, -0.007800362538546324, -0.006951178424060345, -0.006101994309574366, -0.0052528101950883865, -0.004403626546263695, -0.0035544424317777157, -0.0027052583172917366, -0.0018560746684670448, -0.0010068905539810658, -0.0001577083021402359, 0.0006914756959304214, 0.0015406596940010786, 0.002389843575656414, 0.003239027690142393, 0.004088211804628372, 0.004937395453453064, 0.005786579567939043, 0.006635763682425022, 0.007484947796911001, 0.00833413191139698, 0.009183315560221672, 0.010032499209046364, 0.01088168378919363, 0.011730867438018322, 0.012580052018165588, 0.01342923566699028, 0.014278419315814972, 0.015127603895962238, 0.015976786613464355, 0.016825972124934196, 0.017675155773758888, 0.01852433942258358, 0.019373523071408272, 0.020222708582878113, 0.021071892231702805, 0.021921075880527496, 0.022770259529352188, 0.02361944504082203, 0.02446862868964672, 0.025317812338471413, 0.026166995987296104, 0.027016179636120796]}, "gradients/roberta.encoder.layer.2.attention.self.value.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 2039.0, 4055.0, 16.0, 7.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04361309856176376, -0.042163290083408356, -0.040713485330343246, -0.03926367685198784, -0.03781387209892273, -0.03636406362056732, -0.034914255142211914, -0.033464446663856506, -0.0320146419107914, -0.03056483529508114, -0.02911502867937088, -0.027665220201015472, -0.026215413585305214, -0.024765606969594955, -0.023315798491239548, -0.02186599187552929, -0.02041618525981903, -0.018966378644108772, -0.017516572028398514, -0.016066763550043106, -0.014616956934332848, -0.013167150318622589, -0.011717342771589756, -0.010267535224556923, -0.008817728608846664, -0.007367921527475119, -0.005918114446103573, -0.004468307364732027, -0.0030185002833604813, -0.0015686932019889355, -0.00011888612061738968, 0.0013309214264154434, 0.002780728042125702, 0.004230535123497248, 0.0056803422048687935, 0.007130149286240339, 0.008579956367611885, 0.010029762983322144, 0.011479570530354977, 0.01292937807738781, 0.014379184693098068, 0.015828991308808327, 0.017278797924518585, 0.018728606402873993, 0.02017841301858425, 0.02162821963429451, 0.023078028112649918, 0.024527834728360176, 0.025977641344070435, 0.027427447959780693, 0.02887725457549095, 0.03032706305384636, 0.03177686780691147, 0.033226676285266876, 0.034676484763622284, 0.03612629324197769, 0.0375760979950428, 0.03902590647339821, 0.04047571122646332, 0.041925519704818726, 0.04337532818317413, 0.04482513293623924, 0.04627494141459465, 0.04772474616765976, 0.04917455464601517]}, "gradients/roberta.encoder.layer.2.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 8.0, 9.0, 16.0, 21.0, 32.0, 33.0, 64.0, 104.0, 154.0, 319.0, 558.0, 1074.0, 1358.0, 1021.0, 579.0, 293.0, 168.0, 101.0, 67.0, 48.0, 23.0, 18.0, 15.0, 3.0, 8.0, 7.0, 3.0, 2.0, 7.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.006752252113074064, -0.006523360963910818, -0.006294470280408859, -0.006065579131245613, -0.005836687982082367, -0.005607797298580408, -0.005378906149417162, -0.005150015465915203, -0.004921124316751957, -0.004692233167588711, -0.004463342484086752, -0.004234451334923506, -0.004005560651421547, -0.0037766695022583008, -0.0035477783530950546, -0.003318887436762452, -0.0030899965204298496, -0.002861105604097247, -0.0026322146877646446, -0.0024033235386013985, -0.002174432622268796, -0.0019455417059361935, -0.0017166506731882691, -0.0014877596404403448, -0.0012588687241077423, -0.0010299778077751398, -0.0008010867750272155, -0.0005721958004869521, -0.00034330482594668865, -0.00011441390961408615, 0.00011447712313383818, 0.0003433681558817625, 0.0005722595378756523, 0.0008011505124159157, 0.0010300414869561791, 0.0012589325197041035, 0.001487823436036706, 0.0017167143523693085, 0.0019456053851172328, 0.002174496417865157, 0.0024033873341977596, 0.002632278250530362, 0.0028611691668629646, 0.003090060316026211, 0.0033189512323588133, 0.003547842148691416, 0.003776733297854662, 0.004005623981356621, 0.004234515130519867, 0.004463406279683113, 0.004692296963185072, 0.004921188112348318, 0.005150078795850277, 0.005378969945013523, 0.005607861094176769, 0.005836752243340015, 0.006065642926841974, 0.00629453407600522, 0.006523424759507179, 0.006752315908670425, 0.006981207057833672, 0.00721009774133563, 0.007438988890498877, 0.007667879574000835, 0.007896770723164082]}, "gradients/roberta.encoder.layer.2.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 3.0, 6.0, 22.0, 157.0, 3553.0, 2282.0, 95.0, 11.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03590027242898941, -0.03508280590176582, -0.03426533564925194, -0.03344786912202835, -0.032630402594804764, -0.03181293606758118, -0.03099546581506729, -0.030177999287843704, -0.029360532760620117, -0.02854306437075138, -0.027725597843527794, -0.026908129453659058, -0.02609066292643547, -0.025273194536566734, -0.024455726146697998, -0.02363825961947441, -0.022820791229605675, -0.02200332283973694, -0.02118585631251335, -0.020368387922644615, -0.019550921395421028, -0.018733453005552292, -0.017915986478328705, -0.01709851808845997, -0.016281049698591232, -0.01546358224004507, -0.014646114781498909, -0.013828646391630173, -0.013011179864406586, -0.01219371147453785, -0.011376244015991688, -0.010558776557445526, -0.009741311892867088, -0.008923844434320927, -0.008106376975774765, -0.007288909051567316, -0.006471441593021154, -0.005653974134474993, -0.004836506210267544, -0.004019038751721382, -0.0032015712931752205, -0.002384103834629059, -0.0015666361432522535, -0.0007491684518754482, 6.829900667071342e-05, 0.0008857664652168751, 0.001703234389424324, 0.0025207018479704857, 0.0033381693065166473, 0.004155636765062809, 0.004973104223608971, 0.00579057214781642, 0.006608039606362581, 0.007425507064908743, 0.008242974989116192, 0.009060442447662354, 0.009877909906208515, 0.010695377364754677, 0.011512844823300838, 0.012330312281847, 0.013147780671715736, 0.013965247198939323, 0.01478271558880806, 0.015600183047354221, 0.016417650505900383]}, "gradients/roberta.encoder.layer.1.attention.self.value.lora_B": {"_type": "histogram", "values": [3.0, 2.0, 2.0, 5.0, 5.0, 12.0, 12.0, 9.0, 17.0, 29.0, 24.0, 31.0, 27.0, 45.0, 61.0, 59.0, 86.0, 97.0, 126.0, 133.0, 169.0, 193.0, 217.0, 256.0, 270.0, 304.0, 339.0, 388.0, 362.0, 377.0, 326.0, 335.0, 282.0, 229.0, 250.0, 180.0, 151.0, 120.0, 106.0, 95.0, 82.0, 64.0, 43.0, 46.0, 31.0, 34.0, 20.0, 18.0, 17.0, 11.0, 15.0, 7.0, 1.0, 1.0, 4.0, 5.0, 3.0, 0.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0], "bins": [-0.024154845625162125, -0.02330102026462555, -0.022447193041443825, -0.02159336768090725, -0.020739542320370674, -0.01988571509718895, -0.019031889736652374, -0.0181780643761158, -0.017324239015579224, -0.01647041365504265, -0.015616587363183498, -0.014762761071324348, -0.013908935710787773, -0.013055109418928623, -0.012201283127069473, -0.011347457766532898, -0.010493630543351173, -0.009639804251492023, -0.008785978890955448, -0.007932152599096298, -0.007078326772898436, -0.006224500946700573, -0.005370674654841423, -0.00451684882864356, -0.003663023002445698, -0.002809197176247835, -0.001955371117219329, -0.0011015450581908226, -0.00024771923199296, 0.0006061065942049026, 0.0014599328860640526, 0.002313758712261915, 0.003167586401104927, 0.00402141222730279, 0.004875238053500652, 0.005729064345359802, 0.006582890171557665, 0.0074367159977555275, 0.008290542289614677, 0.009144367650151253, 0.009998193942010403, 0.010852020233869553, 0.011705845594406128, 0.012559671886265278, 0.013413498178124428, 0.014267323538661003, 0.015121149830520153, 0.015974976122379303, 0.01682880148291588, 0.017682626843452454, 0.018536454066634178, 0.019390279427170753, 0.02024410478770733, 0.021097932010889053, 0.02195175737142563, 0.022805582731962204, 0.02365940809249878, 0.024513233453035355, 0.02536706067621708, 0.026220886036753654, 0.02707471139729023, 0.027928538620471954, 0.02878236398100853, 0.029636189341545105, 0.03049001656472683]}, "gradients/roberta.encoder.layer.1.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 34.0, 5902.0, 187.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.08280535042285919, -0.08001525700092316, -0.07722515612840652, -0.07443506270647049, -0.07164496183395386, -0.06885486841201782, -0.06606476753950119, -0.06327467411756516, -0.06048457324504852, -0.05769447609782219, -0.054904378950595856, -0.05211428180336952, -0.04932418465614319, -0.046534087508916855, -0.04374399036169052, -0.040953896939754486, -0.03816379979252815, -0.03537370264530182, -0.032583605498075485, -0.02979350835084915, -0.027003411203622818, -0.024213314056396484, -0.0214232187718153, -0.018633121624588966, -0.015843024477362633, -0.0130529273301363, -0.010262830182909966, -0.0074727339670062065, -0.004682636819779873, -0.0018925396725535393, 0.0008975565433502197, 0.0036876536905765533, 0.006477750837802887, 0.00926784798502922, 0.012057945132255554, 0.014848041348159313, 0.01763813942670822, 0.020428236573934555, 0.02321833185851574, 0.026008429005742073, 0.028798526152968407, 0.03158862143754959, 0.034378718584775925, 0.03716881573200226, 0.03995891287922859, 0.042749010026454926, 0.04553910717368126, 0.04832920432090759, 0.051119301468133926, 0.05390939861536026, 0.056699495762586594, 0.05948959290981293, 0.06227969005703926, 0.0650697872042656, 0.06785988062620163, 0.07064998149871826, 0.0734400749206543, 0.07623016834259033, 0.07902026921510696, 0.081810362637043, 0.08460046350955963, 0.08739055693149567, 0.0901806578040123, 0.09297075122594833, 0.09576085209846497]}, "gradients/roberta.encoder.layer.1.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 6.0, 7.0, 8.0, 18.0, 18.0, 31.0, 69.0, 114.0, 261.0, 633.0, 1470.0, 1844.0, 877.0, 402.0, 151.0, 82.0, 48.0, 18.0, 17.0, 10.0, 8.0, 7.0, 5.0, 6.0, 3.0, 3.0, 0.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.010150601156055927, -0.009777320548892021, -0.00940404087305069, -0.009030760265886784, -0.008657479658722878, -0.008284199051558971, -0.00791091937571764, -0.007537638768553734, -0.007164358161389828, -0.006791078019887209, -0.006417797412723303, -0.006044517271220684, -0.005671236664056778, -0.005297956522554159, -0.00492467638105154, -0.004551395773887634, -0.0041781156323850155, -0.003804835258051753, -0.0034315548837184906, -0.003058274742215872, -0.0026849941350519657, -0.002311713993549347, -0.0019384336192160845, -0.001565153244882822, -0.0011918728705495596, -0.0008185924962162971, -0.0004453121800906956, -7.203186396509409e-05, 0.00030124851036816835, 0.0006745288847014308, 0.0010478091426193714, 0.0014210895169526339, 0.0017943698912858963, 0.0021676502656191587, 0.002540930639952421, 0.00291421078145504, 0.003287491388618946, 0.003660771530121565, 0.004034051671624184, 0.00440733227878809, 0.004780612885951996, 0.005153893027454615, 0.005527173634618521, 0.0059004537761211395, 0.006273734383285046, 0.006647014524787664, 0.007020294666290283, 0.007393575273454189, 0.007766855414956808, 0.008140135556459427, 0.008513416163623333, 0.008886696770787239, 0.00925997644662857, 0.009633257053792477, 0.010006537660956383, 0.010379817336797714, 0.01075309794396162, 0.011126378551125526, 0.011499658226966858, 0.011872938834130764, 0.01224621944129467, 0.012619500048458576, 0.012992779724299908, 0.013366060331463814, 0.01373934093862772]}, "gradients/roberta.encoder.layer.1.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 6.0, 31.0, 216.0, 1090.0, 2712.0, 1658.0, 341.0, 56.0, 12.0, 3.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.014781701378524303, -0.014378421939909458, -0.013975142501294613, -0.013571863994002342, -0.013168584555387497, -0.012765305116772652, -0.012362025678157806, -0.011958746239542961, -0.011555466800928116, -0.01115218736231327, -0.010748907923698425, -0.01034562848508358, -0.00994234997779131, -0.009539070539176464, -0.009135791100561619, -0.008732511661946774, -0.008329233154654503, -0.007925953716039658, -0.0075226747430861, -0.007119395304471254, -0.006716116331517696, -0.006312836892902851, -0.005909557454288006, -0.0055062780156731606, -0.005102999042719603, -0.004699719604104757, -0.004296440631151199, -0.003893161192536354, -0.0034898819867521524, -0.003086602780967951, -0.0026833233423531055, -0.002280044136568904, -0.0018767639994621277, -0.001473484793677926, -0.0010702054714784026, -0.0006669261492788792, -0.00026364694349467754, 0.00013963226228952408, 0.0005429117009043694, 0.000946190906688571, 0.0013494701124727726, 0.0017527493182569742, 0.002156028524041176, 0.002559307962656021, 0.0029625871684402227, 0.0033658663742244244, 0.0037691458128392696, 0.004172424785792828, 0.004575704224407673, 0.004978983663022518, 0.005382262635976076, 0.005785542074590921, 0.006188821047544479, 0.006592100486159325, 0.00699537992477417, 0.007398659363389015, 0.007801938336342573, 0.008205217309296131, 0.008608496747910976, 0.009011776186525822, 0.009415055625140667, 0.009818334132432938, 0.010221613571047783, 0.010624893009662628, 0.011028172448277473]}, "gradients/roberta.encoder.layer.0.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 0.0, 0.0, 1.0, 2.0, 3.0, 3.0, 1.0, 4.0, 5.0, 5.0, 12.0, 8.0, 7.0, 21.0, 26.0, 35.0, 42.0, 67.0, 89.0, 162.0, 250.0, 335.0, 485.0, 610.0, 780.0, 766.0, 645.0, 546.0, 377.0, 251.0, 188.0, 129.0, 85.0, 61.0, 30.0, 25.0, 15.0, 19.0, 11.0, 5.0, 10.0, 6.0, 2.0, 1.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.020455198362469673, -0.019799817353487015, -0.019144438207149506, -0.018489057198166847, -0.01783367618918419, -0.01717829518020153, -0.016522914171218872, -0.015867535024881363, -0.015212154015898705, -0.014556773006916046, -0.013901392929255962, -0.013246012851595879, -0.01259063184261322, -0.011935250833630562, -0.011279870755970478, -0.010624490678310394, -0.009969109669327736, -0.009313728660345078, -0.008658348582684994, -0.00800296850502491, -0.007347587496042252, -0.0066922069527208805, -0.006036826409399509, -0.005381445866078138, -0.004726065322756767, -0.004070684779435396, -0.003415304236114025, -0.002759923692792654, -0.002104543149471283, -0.0014491626061499119, -0.0007937820628285408, -0.00013840151950716972, 0.0005169771611690521, 0.0011723577044904232, 0.0018277382478117943, 0.0024831187911331654, 0.0031384993344545364, 0.0037938798777759075, 0.004449260421097279, 0.00510464096441865, 0.005760021507740021, 0.006415402051061392, 0.007070782594382763, 0.007726163137704134, 0.008381543681025505, 0.009036924690008163, 0.009692304767668247, 0.010347684845328331, 0.01100306585431099, 0.011658446863293648, 0.012313826940953732, 0.012969207018613815, 0.013624588027596474, 0.014279969036579132, 0.014935349114239216, 0.0155907291918993, 0.016246110200881958, 0.016901491209864616, 0.017556872218847275, 0.018212251365184784, 0.018867632374167442, 0.0195230133831501, 0.02017839252948761, 0.020833773538470268, 0.021489154547452927]}, "gradients/roberta.encoder.layer.0.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 13.0, 46.0, 232.0, 924.0, 2324.0, 1851.0, 570.0, 134.0, 22.0, 8.0, 4.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.01679484359920025, -0.016144223511219025, -0.01549360528588295, -0.014842985197901726, -0.014192366041243076, -0.013541746884584427, -0.012891126796603203, -0.012240507639944553, -0.011589888483285904, -0.010939269326627254, -0.010288650169968605, -0.009638030081987381, -0.008987410925328732, -0.008336791768670082, -0.007686172146350145, -0.007035552524030209, -0.006384933367371559, -0.00573431421071291, -0.005083694588392973, -0.004433074966073036, -0.0037824558094143867, -0.0031318364199250937, -0.0024812170304358006, -0.0018305974081158638, -0.0011799782514572144, -0.0005293588619679213, 0.00012126052752137184, 0.0007718799170106649, 0.001422499306499958, 0.002073118695989251, 0.0027237380854785442, 0.003374357707798481, 0.004024975001811981, 0.004675594158470631, 0.005326213780790567, 0.005976833403110504, 0.006627452559769154, 0.007278071716427803, 0.007928691804409027, 0.008579310961067677, 0.009229930117726326, 0.009880549274384975, 0.010531168431043625, 0.011181788519024849, 0.011832407675683498, 0.012483026832342148, 0.013133646920323372, 0.013784266076982021, 0.01443488523364067, 0.01508550439029932, 0.01573612354695797, 0.016386743634939194, 0.01703736186027527, 0.017687981948256493, 0.018338602036237717, 0.01898922026157379, 0.019639840349555016, 0.02029046043753624, 0.020941078662872314, 0.02159169875085354, 0.022242318838834763, 0.022892937064170837, 0.02354355715215206, 0.024194177240133286, 0.02484479546546936]}, "gradients/roberta.encoder.layer.0.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 6.0, 7.0, 11.0, 5.0, 11.0, 8.0, 13.0, 17.0, 23.0, 30.0, 49.0, 55.0, 62.0, 75.0, 108.0, 145.0, 229.0, 277.0, 448.0, 705.0, 1066.0, 935.0, 550.0, 362.0, 259.0, 144.0, 110.0, 88.0, 81.0, 49.0, 44.0, 28.0, 22.0, 17.0, 17.0, 15.0, 14.0, 9.0, 5.0, 5.0, 5.0, 7.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.004612983204424381, -0.004452605731785297, -0.0042922282591462135, -0.00413185078650713, -0.003971473779529333, -0.0038110963068902493, -0.0036507188342511654, -0.0034903413616120815, -0.0033299638889729977, -0.003169586416333914, -0.0030092091765254736, -0.0028488317038863897, -0.002688454231247306, -0.0025280769914388657, -0.002367699518799782, -0.002207322046160698, -0.0020469448063522577, -0.0018865674501284957, -0.0017261899774894118, -0.0015658126212656498, -0.001405435148626566, -0.001245057792402804, -0.0010846804361790419, -0.000924302963539958, -0.000763925607316196, -0.000603548192884773, -0.0004431708075571805, -0.00028279342222958803, -0.00012241600779816508, 3.7961406633257866e-05, 0.0001983387628570199, 0.00035871623549610376, 0.0005190935917198658, 0.0006794710061512887, 0.0008398484205827117, 0.0010002257768064737, 0.0011606032494455576, 0.0013209806056693196, 0.0014813579618930817, 0.0016417354345321655, 0.0018021127907559276, 0.0019624901469796896, 0.0021228676196187735, 0.0022832448594272137, 0.0024436223320662975, 0.0026039998047053814, 0.0027643772773444653, 0.002924754749983549, 0.0030851319897919893, 0.003245509462431073, 0.0034058867022395134, 0.0035662641748785973, 0.003726641647517681, 0.003887019120156765, 0.004047396592795849, 0.004207774065434933, 0.004368151072412729, 0.004528528545051813, 0.004688906017690897, 0.0048492830246686935, 0.005009660497307777, 0.005170037969946861, 0.005330415442585945, 0.005490792915225029, 0.005651170387864113]}, "gradients/roberta.encoder.layer.0.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 6.0, 6.0, 12.0, 45.0, 269.0, 1286.0, 3044.0, 1175.0, 236.0, 40.0, 6.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.011247214861214161, -0.010889576748013496, -0.010531939566135406, -0.010174301452934742, -0.009816663339734077, -0.009459025226533413, -0.009101388044655323, -0.008743749931454659, -0.008386111818253994, -0.00802847370505333, -0.007670836057513952, -0.007313198409974575, -0.0069555602967739105, -0.006597922649234533, -0.006240285001695156, -0.005882646888494492, -0.005525009240955114, -0.005167371593415737, -0.004809733480215073, -0.004452095832675695, -0.004094457719475031, -0.0037368200719356537, -0.003379182191565633, -0.003021544311195612, -0.002663906430825591, -0.0023062685504555702, -0.0019486306700855494, -0.0015909929061308503, -0.0012333550257608294, -0.0008757171453908086, -0.0005180793814361095, -0.00016044150106608868, 0.0001971963793039322, 0.0005548342596739531, 0.000912472081836313, 0.001270109903998673, 0.0016277477843686938, 0.001985385548323393, 0.0023430234286934137, 0.0027006613090634346, 0.0030582991894334555, 0.0034159370698034763, 0.003773574950173497, 0.004131212830543518, 0.004488850478082895, 0.00484648859128356, 0.005204126238822937, 0.0055617643520236015, 0.005919401999562979, 0.006277039647102356, 0.0066346777603030205, 0.006992315407842398, 0.007349953521043062, 0.007707591168582439, 0.008065229281783104, 0.008422866463661194, 0.008780504576861858, 0.009138142690062523, 0.009495779871940613, 0.009853417985141277, 0.010211056098341942, 0.010568694211542606, 0.010926331393420696, 0.01128396950662136, 0.011641607619822025]}, "eval/loss": 0.4803914427757263, "eval/matthews_correlation": 0.4608257140340363, "eval/runtime": 6.0433, "eval/samples_per_second": 172.588, "train/train_runtime": 152.1155, "train/train_samples_per_second": 1.762, "train/total_flos": 3289809517651968.0, "_wandb": {"runtime": 152}}