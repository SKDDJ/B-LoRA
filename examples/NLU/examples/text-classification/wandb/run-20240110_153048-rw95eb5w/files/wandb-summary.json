{"Training Loss": 0.06388187408447266, "_timestamp": 1704872985.252413, "Learning rate": 0.0002813393140679581, "epoch": 27, "_runtime": 1137.068920135498, "_step": 7265, "gradients/classifier.out_proj.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-389.5, -377.328125, -365.15625, -352.984375, -340.8125, -328.640625, -316.46875, -304.296875, -292.125, -279.953125, -267.78125, -255.609375, -243.4375, -231.265625, -219.09375, -206.921875, -194.75, -182.578125, -170.40625, -158.234375, -146.0625, -133.890625, -121.71875, -109.546875, -97.375, -85.203125, -73.03125, -60.859375, -48.6875, -36.515625, -24.34375, -12.171875, 0.0, 12.171875, 24.34375, 36.515625, 48.6875, 60.859375, 73.03125, 85.203125, 97.375, 109.546875, 121.71875, 133.890625, 146.0625, 158.234375, 170.40625, 182.578125, 194.75, 206.921875, 219.09375, 231.265625, 243.4375, 255.609375, 267.78125, 279.953125, 292.125, 304.296875, 316.46875, 328.640625, 340.8125, 352.984375, 365.15625, 377.328125, 389.5]}, "gradients/roberta.encoder.layer.11.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 2.0, 6.0, 11.0, 9.0, 13.0, 16.0, 28.0, 26.0, 40.0, 58.0, 71.0, 97.0, 118.0, 180.0, 276.0, 311.0, 447.0, 534.0, 550.0, 617.0, 548.0, 495.0, 416.0, 332.0, 255.0, 186.0, 122.0, 82.0, 66.0, 62.0, 42.0, 30.0, 18.0, 14.0, 17.0, 9.0, 7.0, 5.0, 6.0, 2.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0], "bins": [-46.59375, -45.20068359375, -43.8076171875, -42.41455078125, -41.021484375, -39.62841796875, -38.2353515625, -36.84228515625, -35.44921875, -34.05615234375, -32.6630859375, -31.27001953125, -29.876953125, -28.48388671875, -27.0908203125, -25.69775390625, -24.3046875, -22.91162109375, -21.5185546875, -20.12548828125, -18.732421875, -17.33935546875, -15.9462890625, -14.55322265625, -13.16015625, -11.76708984375, -10.3740234375, -8.98095703125, -7.587890625, -6.19482421875, -4.8017578125, -3.40869140625, -2.015625, -0.62255859375, 0.7705078125, 2.16357421875, 3.556640625, 4.94970703125, 6.3427734375, 7.73583984375, 9.12890625, 10.52197265625, 11.9150390625, 13.30810546875, 14.701171875, 16.09423828125, 17.4873046875, 18.88037109375, 20.2734375, 21.66650390625, 23.0595703125, 24.45263671875, 25.845703125, 27.23876953125, 28.6318359375, 30.02490234375, 31.41796875, 32.81103515625, 34.2041015625, 35.59716796875, 36.990234375, 38.38330078125, 39.7763671875, 41.16943359375, 42.5625]}, "gradients/roberta.encoder.layer.11.attention.self.value.lora_A": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 19.0, 168.0, 4325.0, 1561.0, 37.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-1247.0, -1207.765625, -1168.53125, -1129.296875, -1090.0625, -1050.828125, -1011.59375, -972.359375, -933.125, -893.890625, -854.65625, -815.421875, -776.1875, -736.953125, -697.71875, -658.484375, -619.25, -580.015625, -540.78125, -501.546875, -462.3125, -423.078125, -383.84375, -344.609375, -305.375, -266.140625, -226.90625, -187.671875, -148.4375, -109.203125, -69.96875, -30.734375, 8.5, 47.734375, 86.96875, 126.203125, 165.4375, 204.671875, 243.90625, 283.140625, 322.375, 361.609375, 400.84375, 440.078125, 479.3125, 518.546875, 557.78125, 597.015625, 636.25, 675.484375, 714.71875, 753.953125, 793.1875, 832.421875, 871.65625, 910.890625, 950.125, 989.359375, 1028.59375, 1067.828125, 1107.0625, 1146.296875, 1185.53125, 1224.765625, 1264.0]}, "gradients/roberta.encoder.layer.11.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 5.0, 6.0, 3.0, 6.0, 8.0, 8.0, 14.0, 15.0, 25.0, 32.0, 29.0, 36.0, 56.0, 83.0, 89.0, 92.0, 110.0, 166.0, 225.0, 259.0, 233.0, 297.0, 306.0, 387.0, 463.0, 408.0, 468.0, 326.0, 352.0, 271.0, 246.0, 245.0, 164.0, 169.0, 98.0, 86.0, 81.0, 53.0, 47.0, 33.0, 20.0, 32.0, 14.0, 14.0, 13.0, 12.0, 6.0, 11.0, 1.0, 7.0, 3.0, 1.0, 0.0, 0.0, 1.0, 3.0, 0.0, 1.0], "bins": [-27.40625, -26.5302734375, -25.654296875, -24.7783203125, -23.90234375, -23.0263671875, -22.150390625, -21.2744140625, -20.3984375, -19.5224609375, -18.646484375, -17.7705078125, -16.89453125, -16.0185546875, -15.142578125, -14.2666015625, -13.390625, -12.5146484375, -11.638671875, -10.7626953125, -9.88671875, -9.0107421875, -8.134765625, -7.2587890625, -6.3828125, -5.5068359375, -4.630859375, -3.7548828125, -2.87890625, -2.0029296875, -1.126953125, -0.2509765625, 0.625, 1.5009765625, 2.376953125, 3.2529296875, 4.12890625, 5.0048828125, 5.880859375, 6.7568359375, 7.6328125, 8.5087890625, 9.384765625, 10.2607421875, 11.13671875, 12.0126953125, 12.888671875, 13.7646484375, 14.640625, 15.5166015625, 16.392578125, 17.2685546875, 18.14453125, 19.0205078125, 19.896484375, 20.7724609375, 21.6484375, 22.5244140625, 23.400390625, 24.2763671875, 25.15234375, 26.0283203125, 26.904296875, 27.7802734375, 28.65625]}, "gradients/roberta.encoder.layer.11.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 5.0, 1.0, 3621.0, 2483.0, 4.0, 6.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0], "bins": [-66.8125, -64.7841796875, -62.755859375, -60.7275390625, -58.69921875, -56.6708984375, -54.642578125, -52.6142578125, -50.5859375, -48.5576171875, -46.529296875, -44.5009765625, -42.47265625, -40.4443359375, -38.416015625, -36.3876953125, -34.359375, -32.3310546875, -30.302734375, -28.2744140625, -26.24609375, -24.2177734375, -22.189453125, -20.1611328125, -18.1328125, -16.1044921875, -14.076171875, -12.0478515625, -10.01953125, -7.9912109375, -5.962890625, -3.9345703125, -1.90625, 0.1220703125, 2.150390625, 4.1787109375, 6.20703125, 8.2353515625, 10.263671875, 12.2919921875, 14.3203125, 16.3486328125, 18.376953125, 20.4052734375, 22.43359375, 24.4619140625, 26.490234375, 28.5185546875, 30.546875, 32.5751953125, 34.603515625, 36.6318359375, 38.66015625, 40.6884765625, 42.716796875, 44.7451171875, 46.7734375, 48.8017578125, 50.830078125, 52.8583984375, 54.88671875, 56.9150390625, 58.943359375, 60.9716796875, 63.0]}, "gradients/roberta.encoder.layer.10.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 3.0, 5.0, 6.0, 5.0, 6.0, 2.0, 8.0, 14.0, 11.0, 15.0, 29.0, 30.0, 53.0, 59.0, 87.0, 167.0, 261.0, 344.0, 506.0, 651.0, 896.0, 858.0, 612.0, 494.0, 320.0, 191.0, 154.0, 92.0, 61.0, 42.0, 36.0, 28.0, 20.0, 19.0, 14.0, 7.0, 6.0, 2.0, 5.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-66.1875, -63.7275390625, -61.267578125, -58.8076171875, -56.34765625, -53.8876953125, -51.427734375, -48.9677734375, -46.5078125, -44.0478515625, -41.587890625, -39.1279296875, -36.66796875, -34.2080078125, -31.748046875, -29.2880859375, -26.828125, -24.3681640625, -21.908203125, -19.4482421875, -16.98828125, -14.5283203125, -12.068359375, -9.6083984375, -7.1484375, -4.6884765625, -2.228515625, 0.2314453125, 2.69140625, 5.1513671875, 7.611328125, 10.0712890625, 12.53125, 14.9912109375, 17.451171875, 19.9111328125, 22.37109375, 24.8310546875, 27.291015625, 29.7509765625, 32.2109375, 34.6708984375, 37.130859375, 39.5908203125, 42.05078125, 44.5107421875, 46.970703125, 49.4306640625, 51.890625, 54.3505859375, 56.810546875, 59.2705078125, 61.73046875, 64.1904296875, 66.650390625, 69.1103515625, 71.5703125, 74.0302734375, 76.490234375, 78.9501953125, 81.41015625, 83.8701171875, 86.330078125, 88.7900390625, 91.25]}, "gradients/roberta.encoder.layer.10.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 15.0, 129.0, 5513.0, 436.0, 24.0, 5.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-5080.0, -4948.53125, -4817.0625, -4685.59375, -4554.125, -4422.65625, -4291.1875, -4159.71875, -4028.25, -3896.78125, -3765.3125, -3633.84375, -3502.375, -3370.90625, -3239.4375, -3107.96875, -2976.5, -2845.03125, -2713.5625, -2582.09375, -2450.625, -2319.15625, -2187.6875, -2056.21875, -1924.75, -1793.28125, -1661.8125, -1530.34375, -1398.875, -1267.40625, -1135.9375, -1004.46875, -873.0, -741.53125, -610.0625, -478.59375, -347.125, -215.65625, -84.1875, 47.28125, 178.75, 310.21875, 441.6875, 573.15625, 704.625, 836.09375, 967.5625, 1099.03125, 1230.5, 1361.96875, 1493.4375, 1624.90625, 1756.375, 1887.84375, 2019.3125, 2150.78125, 2282.25, 2413.71875, 2545.1875, 2676.65625, 2808.125, 2939.59375, 3071.0625, 3202.53125, 3334.0]}, "gradients/roberta.encoder.layer.10.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 6.0, 6.0, 12.0, 5.0, 9.0, 4.0, 8.0, 11.0, 29.0, 24.0, 22.0, 40.0, 47.0, 36.0, 57.0, 76.0, 107.0, 122.0, 166.0, 210.0, 251.0, 312.0, 477.0, 793.0, 902.0, 603.0, 408.0, 247.0, 264.0, 168.0, 150.0, 119.0, 84.0, 66.0, 46.0, 40.0, 41.0, 34.0, 21.0, 25.0, 16.0, 13.0, 9.0, 7.0, 9.0, 11.0, 4.0, 5.0, 5.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0], "bins": [-148.0, -143.412109375, -138.82421875, -134.236328125, -129.6484375, -125.060546875, -120.47265625, -115.884765625, -111.296875, -106.708984375, -102.12109375, -97.533203125, -92.9453125, -88.357421875, -83.76953125, -79.181640625, -74.59375, -70.005859375, -65.41796875, -60.830078125, -56.2421875, -51.654296875, -47.06640625, -42.478515625, -37.890625, -33.302734375, -28.71484375, -24.126953125, -19.5390625, -14.951171875, -10.36328125, -5.775390625, -1.1875, 3.400390625, 7.98828125, 12.576171875, 17.1640625, 21.751953125, 26.33984375, 30.927734375, 35.515625, 40.103515625, 44.69140625, 49.279296875, 53.8671875, 58.455078125, 63.04296875, 67.630859375, 72.21875, 76.806640625, 81.39453125, 85.982421875, 90.5703125, 95.158203125, 99.74609375, 104.333984375, 108.921875, 113.509765625, 118.09765625, 122.685546875, 127.2734375, 131.861328125, 136.44921875, 141.037109375, 145.625]}, "gradients/roberta.encoder.layer.10.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 8.0, 26.0, 1594.0, 4462.0, 29.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0], "bins": [-270.0, -261.84765625, -253.6953125, -245.54296875, -237.390625, -229.23828125, -221.0859375, -212.93359375, -204.78125, -196.62890625, -188.4765625, -180.32421875, -172.171875, -164.01953125, -155.8671875, -147.71484375, -139.5625, -131.41015625, -123.2578125, -115.10546875, -106.953125, -98.80078125, -90.6484375, -82.49609375, -74.34375, -66.19140625, -58.0390625, -49.88671875, -41.734375, -33.58203125, -25.4296875, -17.27734375, -9.125, -0.97265625, 7.1796875, 15.33203125, 23.484375, 31.63671875, 39.7890625, 47.94140625, 56.09375, 64.24609375, 72.3984375, 80.55078125, 88.703125, 96.85546875, 105.0078125, 113.16015625, 121.3125, 129.46484375, 137.6171875, 145.76953125, 153.921875, 162.07421875, 170.2265625, 178.37890625, 186.53125, 194.68359375, 202.8359375, 210.98828125, 219.140625, 227.29296875, 235.4453125, 243.59765625, 251.75]}, "gradients/roberta.encoder.layer.9.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 6.0, 3.0, 2.0, 5.0, 9.0, 11.0, 19.0, 28.0, 33.0, 54.0, 94.0, 115.0, 191.0, 236.0, 364.0, 513.0, 641.0, 866.0, 809.0, 624.0, 454.0, 331.0, 234.0, 151.0, 118.0, 69.0, 41.0, 31.0, 27.0, 11.0, 13.0, 7.0, 6.0, 8.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-141.0, -136.091796875, -131.18359375, -126.275390625, -121.3671875, -116.458984375, -111.55078125, -106.642578125, -101.734375, -96.826171875, -91.91796875, -87.009765625, -82.1015625, -77.193359375, -72.28515625, -67.376953125, -62.46875, -57.560546875, -52.65234375, -47.744140625, -42.8359375, -37.927734375, -33.01953125, -28.111328125, -23.203125, -18.294921875, -13.38671875, -8.478515625, -3.5703125, 1.337890625, 6.24609375, 11.154296875, 16.0625, 20.970703125, 25.87890625, 30.787109375, 35.6953125, 40.603515625, 45.51171875, 50.419921875, 55.328125, 60.236328125, 65.14453125, 70.052734375, 74.9609375, 79.869140625, 84.77734375, 89.685546875, 94.59375, 99.501953125, 104.41015625, 109.318359375, 114.2265625, 119.134765625, 124.04296875, 128.951171875, 133.859375, 138.767578125, 143.67578125, 148.583984375, 153.4921875, 158.400390625, 163.30859375, 168.216796875, 173.125]}, "gradients/roberta.encoder.layer.9.attention.self.value.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 9.0, 19.0, 220.0, 4472.0, 1347.0, 38.0, 15.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-2490.0, -2406.21875, -2322.4375, -2238.65625, -2154.875, -2071.09375, -1987.3125, -1903.53125, -1819.75, -1735.96875, -1652.1875, -1568.40625, -1484.625, -1400.84375, -1317.0625, -1233.28125, -1149.5, -1065.71875, -981.9375, -898.15625, -814.375, -730.59375, -646.8125, -563.03125, -479.25, -395.46875, -311.6875, -227.90625, -144.125, -60.34375, 23.4375, 107.21875, 191.0, 274.78125, 358.5625, 442.34375, 526.125, 609.90625, 693.6875, 777.46875, 861.25, 945.03125, 1028.8125, 1112.59375, 1196.375, 1280.15625, 1363.9375, 1447.71875, 1531.5, 1615.28125, 1699.0625, 1782.84375, 1866.625, 1950.40625, 2034.1875, 2117.96875, 2201.75, 2285.53125, 2369.3125, 2453.09375, 2536.875, 2620.65625, 2704.4375, 2788.21875, 2872.0]}, "gradients/roberta.encoder.layer.9.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 5.0, 7.0, 13.0, 5.0, 18.0, 21.0, 30.0, 42.0, 59.0, 96.0, 146.0, 207.0, 307.0, 411.0, 705.0, 1523.0, 903.0, 515.0, 339.0, 266.0, 157.0, 112.0, 62.0, 60.0, 28.0, 17.0, 23.0, 13.0, 5.0, 5.0, 6.0, 1.0, 8.0, 3.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-206.75, -200.228515625, -193.70703125, -187.185546875, -180.6640625, -174.142578125, -167.62109375, -161.099609375, -154.578125, -148.056640625, -141.53515625, -135.013671875, -128.4921875, -121.970703125, -115.44921875, -108.927734375, -102.40625, -95.884765625, -89.36328125, -82.841796875, -76.3203125, -69.798828125, -63.27734375, -56.755859375, -50.234375, -43.712890625, -37.19140625, -30.669921875, -24.1484375, -17.626953125, -11.10546875, -4.583984375, 1.9375, 8.458984375, 14.98046875, 21.501953125, 28.0234375, 34.544921875, 41.06640625, 47.587890625, 54.109375, 60.630859375, 67.15234375, 73.673828125, 80.1953125, 86.716796875, 93.23828125, 99.759765625, 106.28125, 112.802734375, 119.32421875, 125.845703125, 132.3671875, 138.888671875, 145.41015625, 151.931640625, 158.453125, 164.974609375, 171.49609375, 178.017578125, 184.5390625, 191.060546875, 197.58203125, 204.103515625, 210.625]}, "gradients/roberta.encoder.layer.9.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 3.0, 2.0, 12.0, 97.0, 2037.0, 3705.0, 256.0, 16.0, 2.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-446.0, -429.5625, -413.125, -396.6875, -380.25, -363.8125, -347.375, -330.9375, -314.5, -298.0625, -281.625, -265.1875, -248.75, -232.3125, -215.875, -199.4375, -183.0, -166.5625, -150.125, -133.6875, -117.25, -100.8125, -84.375, -67.9375, -51.5, -35.0625, -18.625, -2.1875, 14.25, 30.6875, 47.125, 63.5625, 80.0, 96.4375, 112.875, 129.3125, 145.75, 162.1875, 178.625, 195.0625, 211.5, 227.9375, 244.375, 260.8125, 277.25, 293.6875, 310.125, 326.5625, 343.0, 359.4375, 375.875, 392.3125, 408.75, 425.1875, 441.625, 458.0625, 474.5, 490.9375, 507.375, 523.8125, 540.25, 556.6875, 573.125, 589.5625, 606.0]}, "gradients/roberta.encoder.layer.8.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 3.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 9.0, 12.0, 3.0, 13.0, 15.0, 20.0, 25.0, 30.0, 34.0, 51.0, 90.0, 141.0, 232.0, 399.0, 765.0, 1305.0, 1230.0, 728.0, 353.0, 235.0, 117.0, 85.0, 53.0, 50.0, 25.0, 23.0, 11.0, 15.0, 12.0, 9.0, 5.0, 3.0, 3.0, 4.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-309.25, -298.17578125, -287.1015625, -276.02734375, -264.953125, -253.87890625, -242.8046875, -231.73046875, -220.65625, -209.58203125, -198.5078125, -187.43359375, -176.359375, -165.28515625, -154.2109375, -143.13671875, -132.0625, -120.98828125, -109.9140625, -98.83984375, -87.765625, -76.69140625, -65.6171875, -54.54296875, -43.46875, -32.39453125, -21.3203125, -10.24609375, 0.828125, 11.90234375, 22.9765625, 34.05078125, 45.125, 56.19921875, 67.2734375, 78.34765625, 89.421875, 100.49609375, 111.5703125, 122.64453125, 133.71875, 144.79296875, 155.8671875, 166.94140625, 178.015625, 189.08984375, 200.1640625, 211.23828125, 222.3125, 233.38671875, 244.4609375, 255.53515625, 266.609375, 277.68359375, 288.7578125, 299.83203125, 310.90625, 321.98046875, 333.0546875, 344.12890625, 355.203125, 366.27734375, 377.3515625, 388.42578125, 399.5]}, "gradients/roberta.encoder.layer.8.attention.self.value.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 5.0, 5.0, 14.0, 411.0, 5480.0, 191.0, 18.0, 3.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1591.0, -1504.421875, -1417.84375, -1331.265625, -1244.6875, -1158.109375, -1071.53125, -984.953125, -898.375, -811.796875, -725.21875, -638.640625, -552.0625, -465.484375, -378.90625, -292.328125, -205.75, -119.171875, -32.59375, 53.984375, 140.5625, 227.140625, 313.71875, 400.296875, 486.875, 573.453125, 660.03125, 746.609375, 833.1875, 919.765625, 1006.34375, 1092.921875, 1179.5, 1266.078125, 1352.65625, 1439.234375, 1525.8125, 1612.390625, 1698.96875, 1785.546875, 1872.125, 1958.703125, 2045.28125, 2131.859375, 2218.4375, 2305.015625, 2391.59375, 2478.171875, 2564.75, 2651.328125, 2737.90625, 2824.484375, 2911.0625, 2997.640625, 3084.21875, 3170.796875, 3257.375, 3343.953125, 3430.53125, 3517.109375, 3603.6875, 3690.265625, 3776.84375, 3863.421875, 3950.0]}, "gradients/roberta.encoder.layer.8.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 5.0, 5.0, 6.0, 9.0, 14.0, 33.0, 68.0, 102.0, 285.0, 666.0, 2182.0, 1712.0, 576.0, 244.0, 112.0, 48.0, 28.0, 13.0, 7.0, 5.0, 4.0, 3.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-464.0, -447.375, -430.75, -414.125, -397.5, -380.875, -364.25, -347.625, -331.0, -314.375, -297.75, -281.125, -264.5, -247.875, -231.25, -214.625, -198.0, -181.375, -164.75, -148.125, -131.5, -114.875, -98.25, -81.625, -65.0, -48.375, -31.75, -15.125, 1.5, 18.125, 34.75, 51.375, 68.0, 84.625, 101.25, 117.875, 134.5, 151.125, 167.75, 184.375, 201.0, 217.625, 234.25, 250.875, 267.5, 284.125, 300.75, 317.375, 334.0, 350.625, 367.25, 383.875, 400.5, 417.125, 433.75, 450.375, 467.0, 483.625, 500.25, 516.875, 533.5, 550.125, 566.75, 583.375, 600.0]}, "gradients/roberta.encoder.layer.8.attention.self.query.lora_A": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 18.0, 203.0, 3608.0, 2166.0, 106.0, 14.0, 6.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-521.0, -500.8671875, -480.734375, -460.6015625, -440.46875, -420.3359375, -400.203125, -380.0703125, -359.9375, -339.8046875, -319.671875, -299.5390625, -279.40625, -259.2734375, -239.140625, -219.0078125, -198.875, -178.7421875, -158.609375, -138.4765625, -118.34375, -98.2109375, -78.078125, -57.9453125, -37.8125, -17.6796875, 2.453125, 22.5859375, 42.71875, 62.8515625, 82.984375, 103.1171875, 123.25, 143.3828125, 163.515625, 183.6484375, 203.78125, 223.9140625, 244.046875, 264.1796875, 284.3125, 304.4453125, 324.578125, 344.7109375, 364.84375, 384.9765625, 405.109375, 425.2421875, 445.375, 465.5078125, 485.640625, 505.7734375, 525.90625, 546.0390625, 566.171875, 586.3046875, 606.4375, 626.5703125, 646.703125, 666.8359375, 686.96875, 707.1015625, 727.234375, 747.3671875, 767.5]}, "gradients/roberta.encoder.layer.7.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 5.0, 3.0, 5.0, 9.0, 14.0, 11.0, 22.0, 27.0, 57.0, 69.0, 144.0, 197.0, 343.0, 568.0, 775.0, 1018.0, 987.0, 667.0, 482.0, 266.0, 175.0, 85.0, 64.0, 39.0, 34.0, 19.0, 13.0, 11.0, 4.0, 8.0, 4.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-329.75, -319.39453125, -309.0390625, -298.68359375, -288.328125, -277.97265625, -267.6171875, -257.26171875, -246.90625, -236.55078125, -226.1953125, -215.83984375, -205.484375, -195.12890625, -184.7734375, -174.41796875, -164.0625, -153.70703125, -143.3515625, -132.99609375, -122.640625, -112.28515625, -101.9296875, -91.57421875, -81.21875, -70.86328125, -60.5078125, -50.15234375, -39.796875, -29.44140625, -19.0859375, -8.73046875, 1.625, 11.98046875, 22.3359375, 32.69140625, 43.046875, 53.40234375, 63.7578125, 74.11328125, 84.46875, 94.82421875, 105.1796875, 115.53515625, 125.890625, 136.24609375, 146.6015625, 156.95703125, 167.3125, 177.66796875, 188.0234375, 198.37890625, 208.734375, 219.08984375, 229.4453125, 239.80078125, 250.15625, 260.51171875, 270.8671875, 281.22265625, 291.578125, 301.93359375, 312.2890625, 322.64453125, 333.0]}, "gradients/roberta.encoder.layer.7.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 4.0, 18.0, 3504.0, 2580.0, 17.0, 4.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-6408.0, -6262.28125, -6116.5625, -5970.84375, -5825.125, -5679.40625, -5533.6875, -5387.96875, -5242.25, -5096.53125, -4950.8125, -4805.09375, -4659.375, -4513.65625, -4367.9375, -4222.21875, -4076.5, -3930.78125, -3785.0625, -3639.34375, -3493.625, -3347.90625, -3202.1875, -3056.46875, -2910.75, -2765.03125, -2619.3125, -2473.59375, -2327.875, -2182.15625, -2036.4375, -1890.71875, -1745.0, -1599.28125, -1453.5625, -1307.84375, -1162.125, -1016.40625, -870.6875, -724.96875, -579.25, -433.53125, -287.8125, -142.09375, 3.625, 149.34375, 295.0625, 440.78125, 586.5, 732.21875, 877.9375, 1023.65625, 1169.375, 1315.09375, 1460.8125, 1606.53125, 1752.25, 1897.96875, 2043.6875, 2189.40625, 2335.125, 2480.84375, 2626.5625, 2772.28125, 2918.0]}, "gradients/roberta.encoder.layer.7.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 6.0, 4.0, 11.0, 9.0, 21.0, 37.0, 51.0, 104.0, 297.0, 968.0, 2715.0, 1261.0, 361.0, 121.0, 64.0, 29.0, 22.0, 10.0, 11.0, 6.0, 6.0, 2.0, 6.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0], "bins": [-392.0, -382.34375, -372.6875, -363.03125, -353.375, -343.71875, -334.0625, -324.40625, -314.75, -305.09375, -295.4375, -285.78125, -276.125, -266.46875, -256.8125, -247.15625, -237.5, -227.84375, -218.1875, -208.53125, -198.875, -189.21875, -179.5625, -169.90625, -160.25, -150.59375, -140.9375, -131.28125, -121.625, -111.96875, -102.3125, -92.65625, -83.0, -73.34375, -63.6875, -54.03125, -44.375, -34.71875, -25.0625, -15.40625, -5.75, 3.90625, 13.5625, 23.21875, 32.875, 42.53125, 52.1875, 61.84375, 71.5, 81.15625, 90.8125, 100.46875, 110.125, 119.78125, 129.4375, 139.09375, 148.75, 158.40625, 168.0625, 177.71875, 187.375, 197.03125, 206.6875, 216.34375, 226.0]}, "gradients/roberta.encoder.layer.7.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 6.0, 28.0, 1042.0, 4890.0, 137.0, 16.0, 5.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1700.0, -1639.84375, -1579.6875, -1519.53125, -1459.375, -1399.21875, -1339.0625, -1278.90625, -1218.75, -1158.59375, -1098.4375, -1038.28125, -978.125, -917.96875, -857.8125, -797.65625, -737.5, -677.34375, -617.1875, -557.03125, -496.875, -436.71875, -376.5625, -316.40625, -256.25, -196.09375, -135.9375, -75.78125, -15.625, 44.53125, 104.6875, 164.84375, 225.0, 285.15625, 345.3125, 405.46875, 465.625, 525.78125, 585.9375, 646.09375, 706.25, 766.40625, 826.5625, 886.71875, 946.875, 1007.03125, 1067.1875, 1127.34375, 1187.5, 1247.65625, 1307.8125, 1367.96875, 1428.125, 1488.28125, 1548.4375, 1608.59375, 1668.75, 1728.90625, 1789.0625, 1849.21875, 1909.375, 1969.53125, 2029.6875, 2089.84375, 2150.0]}, "gradients/roberta.encoder.layer.6.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 4.0, 5.0, 8.0, 9.0, 11.0, 24.0, 17.0, 27.0, 34.0, 43.0, 67.0, 94.0, 107.0, 153.0, 240.0, 328.0, 432.0, 577.0, 705.0, 752.0, 638.0, 506.0, 352.0, 274.0, 197.0, 148.0, 102.0, 54.0, 45.0, 41.0, 39.0, 22.0, 25.0, 14.0, 7.0, 8.0, 5.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0], "bins": [-204.125, -197.787109375, -191.44921875, -185.111328125, -178.7734375, -172.435546875, -166.09765625, -159.759765625, -153.421875, -147.083984375, -140.74609375, -134.408203125, -128.0703125, -121.732421875, -115.39453125, -109.056640625, -102.71875, -96.380859375, -90.04296875, -83.705078125, -77.3671875, -71.029296875, -64.69140625, -58.353515625, -52.015625, -45.677734375, -39.33984375, -33.001953125, -26.6640625, -20.326171875, -13.98828125, -7.650390625, -1.3125, 5.025390625, 11.36328125, 17.701171875, 24.0390625, 30.376953125, 36.71484375, 43.052734375, 49.390625, 55.728515625, 62.06640625, 68.404296875, 74.7421875, 81.080078125, 87.41796875, 93.755859375, 100.09375, 106.431640625, 112.76953125, 119.107421875, 125.4453125, 131.783203125, 138.12109375, 144.458984375, 150.796875, 157.134765625, 163.47265625, 169.810546875, 176.1484375, 182.486328125, 188.82421875, 195.162109375, 201.5]}, "gradients/roberta.encoder.layer.6.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 5.0, 161.0, 5927.0, 24.0, 6.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-3018.0, -2945.015625, -2872.03125, -2799.046875, -2726.0625, -2653.078125, -2580.09375, -2507.109375, -2434.125, -2361.140625, -2288.15625, -2215.171875, -2142.1875, -2069.203125, -1996.21875, -1923.234375, -1850.25, -1777.265625, -1704.28125, -1631.296875, -1558.3125, -1485.328125, -1412.34375, -1339.359375, -1266.375, -1193.390625, -1120.40625, -1047.421875, -974.4375, -901.453125, -828.46875, -755.484375, -682.5, -609.515625, -536.53125, -463.546875, -390.5625, -317.578125, -244.59375, -171.609375, -98.625, -25.640625, 47.34375, 120.328125, 193.3125, 266.296875, 339.28125, 412.265625, 485.25, 558.234375, 631.21875, 704.203125, 777.1875, 850.171875, 923.15625, 996.140625, 1069.125, 1142.109375, 1215.09375, 1288.078125, 1361.0625, 1434.046875, 1507.03125, 1580.015625, 1653.0]}, "gradients/roberta.encoder.layer.6.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 5.0, 3.0, 1.0, 3.0, 4.0, 9.0, 16.0, 33.0, 24.0, 41.0, 102.0, 477.0, 3658.0, 1406.0, 176.0, 53.0, 31.0, 29.0, 19.0, 10.0, 8.0, 7.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-798.0, -773.59375, -749.1875, -724.78125, -700.375, -675.96875, -651.5625, -627.15625, -602.75, -578.34375, -553.9375, -529.53125, -505.125, -480.71875, -456.3125, -431.90625, -407.5, -383.09375, -358.6875, -334.28125, -309.875, -285.46875, -261.0625, -236.65625, -212.25, -187.84375, -163.4375, -139.03125, -114.625, -90.21875, -65.8125, -41.40625, -17.0, 7.40625, 31.8125, 56.21875, 80.625, 105.03125, 129.4375, 153.84375, 178.25, 202.65625, 227.0625, 251.46875, 275.875, 300.28125, 324.6875, 349.09375, 373.5, 397.90625, 422.3125, 446.71875, 471.125, 495.53125, 519.9375, 544.34375, 568.75, 593.15625, 617.5625, 641.96875, 666.375, 690.78125, 715.1875, 739.59375, 764.0]}, "gradients/roberta.encoder.layer.6.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 6.0, 21.0, 379.0, 4617.0, 994.0, 91.0, 16.0, 1.0, 4.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-1608.0, -1537.0625, -1466.125, -1395.1875, -1324.25, -1253.3125, -1182.375, -1111.4375, -1040.5, -969.5625, -898.625, -827.6875, -756.75, -685.8125, -614.875, -543.9375, -473.0, -402.0625, -331.125, -260.1875, -189.25, -118.3125, -47.375, 23.5625, 94.5, 165.4375, 236.375, 307.3125, 378.25, 449.1875, 520.125, 591.0625, 662.0, 732.9375, 803.875, 874.8125, 945.75, 1016.6875, 1087.625, 1158.5625, 1229.5, 1300.4375, 1371.375, 1442.3125, 1513.25, 1584.1875, 1655.125, 1726.0625, 1797.0, 1867.9375, 1938.875, 2009.8125, 2080.75, 2151.6875, 2222.625, 2293.5625, 2364.5, 2435.4375, 2506.375, 2577.3125, 2648.25, 2719.1875, 2790.125, 2861.0625, 2932.0]}, "gradients/roberta.encoder.layer.5.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 5.0, 2.0, 4.0, 4.0, 8.0, 6.0, 12.0, 9.0, 25.0, 25.0, 33.0, 50.0, 50.0, 81.0, 127.0, 148.0, 217.0, 291.0, 403.0, 541.0, 710.0, 733.0, 690.0, 495.0, 395.0, 274.0, 209.0, 142.0, 115.0, 84.0, 49.0, 46.0, 42.0, 19.0, 22.0, 15.0, 17.0, 11.0, 8.0, 3.0, 2.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-257.25, -248.8046875, -240.359375, -231.9140625, -223.46875, -215.0234375, -206.578125, -198.1328125, -189.6875, -181.2421875, -172.796875, -164.3515625, -155.90625, -147.4609375, -139.015625, -130.5703125, -122.125, -113.6796875, -105.234375, -96.7890625, -88.34375, -79.8984375, -71.453125, -63.0078125, -54.5625, -46.1171875, -37.671875, -29.2265625, -20.78125, -12.3359375, -3.890625, 4.5546875, 13.0, 21.4453125, 29.890625, 38.3359375, 46.78125, 55.2265625, 63.671875, 72.1171875, 80.5625, 89.0078125, 97.453125, 105.8984375, 114.34375, 122.7890625, 131.234375, 139.6796875, 148.125, 156.5703125, 165.015625, 173.4609375, 181.90625, 190.3515625, 198.796875, 207.2421875, 215.6875, 224.1328125, 232.578125, 241.0234375, 249.46875, 257.9140625, 266.359375, 274.8046875, 283.25]}, "gradients/roberta.encoder.layer.5.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 4.0, 39.0, 6056.0, 29.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-4006.0, -3874.59375, -3743.1875, -3611.78125, -3480.375, -3348.96875, -3217.5625, -3086.15625, -2954.75, -2823.34375, -2691.9375, -2560.53125, -2429.125, -2297.71875, -2166.3125, -2034.90625, -1903.5, -1772.09375, -1640.6875, -1509.28125, -1377.875, -1246.46875, -1115.0625, -983.65625, -852.25, -720.84375, -589.4375, -458.03125, -326.625, -195.21875, -63.8125, 67.59375, 199.0, 330.40625, 461.8125, 593.21875, 724.625, 856.03125, 987.4375, 1118.84375, 1250.25, 1381.65625, 1513.0625, 1644.46875, 1775.875, 1907.28125, 2038.6875, 2170.09375, 2301.5, 2432.90625, 2564.3125, 2695.71875, 2827.125, 2958.53125, 3089.9375, 3221.34375, 3352.75, 3484.15625, 3615.5625, 3746.96875, 3878.375, 4009.78125, 4141.1875, 4272.59375, 4404.0]}, "gradients/roberta.encoder.layer.5.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 4.0, 2.0, 2.0, 6.0, 5.0, 9.0, 19.0, 11.0, 28.0, 51.0, 71.0, 208.0, 648.0, 1890.0, 2031.0, 632.0, 239.0, 105.0, 59.0, 30.0, 19.0, 13.0, 15.0, 9.0, 4.0, 6.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-289.5, -280.171875, -270.84375, -261.515625, -252.1875, -242.859375, -233.53125, -224.203125, -214.875, -205.546875, -196.21875, -186.890625, -177.5625, -168.234375, -158.90625, -149.578125, -140.25, -130.921875, -121.59375, -112.265625, -102.9375, -93.609375, -84.28125, -74.953125, -65.625, -56.296875, -46.96875, -37.640625, -28.3125, -18.984375, -9.65625, -0.328125, 9.0, 18.328125, 27.65625, 36.984375, 46.3125, 55.640625, 64.96875, 74.296875, 83.625, 92.953125, 102.28125, 111.609375, 120.9375, 130.265625, 139.59375, 148.921875, 158.25, 167.578125, 176.90625, 186.234375, 195.5625, 204.890625, 214.21875, 223.546875, 232.875, 242.203125, 251.53125, 260.859375, 270.1875, 279.515625, 288.84375, 298.171875, 307.5]}, "gradients/roberta.encoder.layer.5.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 16.0, 99.0, 1674.0, 3997.0, 291.0, 42.0, 5.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1453.0, -1390.390625, -1327.78125, -1265.171875, -1202.5625, -1139.953125, -1077.34375, -1014.734375, -952.125, -889.515625, -826.90625, -764.296875, -701.6875, -639.078125, -576.46875, -513.859375, -451.25, -388.640625, -326.03125, -263.421875, -200.8125, -138.203125, -75.59375, -12.984375, 49.625, 112.234375, 174.84375, 237.453125, 300.0625, 362.671875, 425.28125, 487.890625, 550.5, 613.109375, 675.71875, 738.328125, 800.9375, 863.546875, 926.15625, 988.765625, 1051.375, 1113.984375, 1176.59375, 1239.203125, 1301.8125, 1364.421875, 1427.03125, 1489.640625, 1552.25, 1614.859375, 1677.46875, 1740.078125, 1802.6875, 1865.296875, 1927.90625, 1990.515625, 2053.125, 2115.734375, 2178.34375, 2240.953125, 2303.5625, 2366.171875, 2428.78125, 2491.390625, 2554.0]}, "gradients/roberta.encoder.layer.4.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 3.0, 2.0, 4.0, 2.0, 3.0, 9.0, 16.0, 12.0, 18.0, 16.0, 28.0, 39.0, 47.0, 61.0, 106.0, 107.0, 212.0, 319.0, 481.0, 746.0, 1011.0, 888.0, 629.0, 457.0, 260.0, 198.0, 122.0, 95.0, 67.0, 37.0, 36.0, 28.0, 14.0, 15.0, 20.0, 5.0, 4.0, 6.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-464.25, -449.203125, -434.15625, -419.109375, -404.0625, -389.015625, -373.96875, -358.921875, -343.875, -328.828125, -313.78125, -298.734375, -283.6875, -268.640625, -253.59375, -238.546875, -223.5, -208.453125, -193.40625, -178.359375, -163.3125, -148.265625, -133.21875, -118.171875, -103.125, -88.078125, -73.03125, -57.984375, -42.9375, -27.890625, -12.84375, 2.203125, 17.25, 32.296875, 47.34375, 62.390625, 77.4375, 92.484375, 107.53125, 122.578125, 137.625, 152.671875, 167.71875, 182.765625, 197.8125, 212.859375, 227.90625, 242.953125, 258.0, 273.046875, 288.09375, 303.140625, 318.1875, 333.234375, 348.28125, 363.328125, 378.375, 393.421875, 408.46875, 423.515625, 438.5625, 453.609375, 468.65625, 483.703125, 498.75]}, "gradients/roberta.encoder.layer.4.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 25.0, 6037.0, 64.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5416.0, -5238.875, -5061.75, -4884.625, -4707.5, -4530.375, -4353.25, -4176.125, -3999.0, -3821.875, -3644.75, -3467.625, -3290.5, -3113.375, -2936.25, -2759.125, -2582.0, -2404.875, -2227.75, -2050.625, -1873.5, -1696.375, -1519.25, -1342.125, -1165.0, -987.875, -810.75, -633.625, -456.5, -279.375, -102.25, 74.875, 252.0, 429.125, 606.25, 783.375, 960.5, 1137.625, 1314.75, 1491.875, 1669.0, 1846.125, 2023.25, 2200.375, 2377.5, 2554.625, 2731.75, 2908.875, 3086.0, 3263.125, 3440.25, 3617.375, 3794.5, 3971.625, 4148.75, 4325.875, 4503.0, 4680.125, 4857.25, 5034.375, 5211.5, 5388.625, 5565.75, 5742.875, 5920.0]}, "gradients/roberta.encoder.layer.4.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 7.0, 8.0, 7.0, 7.0, 14.0, 15.0, 14.0, 36.0, 32.0, 57.0, 69.0, 96.0, 134.0, 202.0, 339.0, 489.0, 762.0, 1045.0, 941.0, 614.0, 379.0, 234.0, 169.0, 119.0, 76.0, 68.0, 44.0, 34.0, 26.0, 13.0, 15.0, 12.0, 13.0, 9.0, 4.0, 10.0, 6.0, 3.0, 2.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-178.875, -172.865234375, -166.85546875, -160.845703125, -154.8359375, -148.826171875, -142.81640625, -136.806640625, -130.796875, -124.787109375, -118.77734375, -112.767578125, -106.7578125, -100.748046875, -94.73828125, -88.728515625, -82.71875, -76.708984375, -70.69921875, -64.689453125, -58.6796875, -52.669921875, -46.66015625, -40.650390625, -34.640625, -28.630859375, -22.62109375, -16.611328125, -10.6015625, -4.591796875, 1.41796875, 7.427734375, 13.4375, 19.447265625, 25.45703125, 31.466796875, 37.4765625, 43.486328125, 49.49609375, 55.505859375, 61.515625, 67.525390625, 73.53515625, 79.544921875, 85.5546875, 91.564453125, 97.57421875, 103.583984375, 109.59375, 115.603515625, 121.61328125, 127.623046875, 133.6328125, 139.642578125, 145.65234375, 151.662109375, 157.671875, 163.681640625, 169.69140625, 175.701171875, 181.7109375, 187.720703125, 193.73046875, 199.740234375, 205.75]}, "gradients/roberta.encoder.layer.4.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 4.0, 5.0, 27.0, 74.0, 314.0, 1509.0, 3000.0, 907.0, 224.0, 51.0, 13.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-266.0, -250.6484375, -235.296875, -219.9453125, -204.59375, -189.2421875, -173.890625, -158.5390625, -143.1875, -127.8359375, -112.484375, -97.1328125, -81.78125, -66.4296875, -51.078125, -35.7265625, -20.375, -5.0234375, 10.328125, 25.6796875, 41.03125, 56.3828125, 71.734375, 87.0859375, 102.4375, 117.7890625, 133.140625, 148.4921875, 163.84375, 179.1953125, 194.546875, 209.8984375, 225.25, 240.6015625, 255.953125, 271.3046875, 286.65625, 302.0078125, 317.359375, 332.7109375, 348.0625, 363.4140625, 378.765625, 394.1171875, 409.46875, 424.8203125, 440.171875, 455.5234375, 470.875, 486.2265625, 501.578125, 516.9296875, 532.28125, 547.6328125, 562.984375, 578.3359375, 593.6875, 609.0390625, 624.390625, 639.7421875, 655.09375, 670.4453125, 685.796875, 701.1484375, 716.5]}, "gradients/roberta.encoder.layer.3.attention.self.value.lora_B": {"_type": "histogram", "values": [3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 8.0, 10.0, 11.0, 11.0, 12.0, 17.0, 20.0, 34.0, 28.0, 44.0, 61.0, 83.0, 94.0, 110.0, 173.0, 199.0, 266.0, 373.0, 490.0, 615.0, 741.0, 662.0, 492.0, 366.0, 278.0, 204.0, 171.0, 109.0, 99.0, 66.0, 73.0, 51.0, 41.0, 25.0, 17.0, 16.0, 16.0, 10.0, 4.0, 9.0, 4.0, 3.0, 2.0, 2.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-256.75, -247.4296875, -238.109375, -228.7890625, -219.46875, -210.1484375, -200.828125, -191.5078125, -182.1875, -172.8671875, -163.546875, -154.2265625, -144.90625, -135.5859375, -126.265625, -116.9453125, -107.625, -98.3046875, -88.984375, -79.6640625, -70.34375, -61.0234375, -51.703125, -42.3828125, -33.0625, -23.7421875, -14.421875, -5.1015625, 4.21875, 13.5390625, 22.859375, 32.1796875, 41.5, 50.8203125, 60.140625, 69.4609375, 78.78125, 88.1015625, 97.421875, 106.7421875, 116.0625, 125.3828125, 134.703125, 144.0234375, 153.34375, 162.6640625, 171.984375, 181.3046875, 190.625, 199.9453125, 209.265625, 218.5859375, 227.90625, 237.2265625, 246.546875, 255.8671875, 265.1875, 274.5078125, 283.828125, 293.1484375, 302.46875, 311.7890625, 321.109375, 330.4296875, 339.75]}, "gradients/roberta.encoder.layer.3.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 8.0, 1884.0, 4219.0, 14.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1488.0, -1395.3125, -1302.625, -1209.9375, -1117.25, -1024.5625, -931.875, -839.1875, -746.5, -653.8125, -561.125, -468.4375, -375.75, -283.0625, -190.375, -97.6875, -5.0, 87.6875, 180.375, 273.0625, 365.75, 458.4375, 551.125, 643.8125, 736.5, 829.1875, 921.875, 1014.5625, 1107.25, 1199.9375, 1292.625, 1385.3125, 1478.0, 1570.6875, 1663.375, 1756.0625, 1848.75, 1941.4375, 2034.125, 2126.8125, 2219.5, 2312.1875, 2404.875, 2497.5625, 2590.25, 2682.9375, 2775.625, 2868.3125, 2961.0, 3053.6875, 3146.375, 3239.0625, 3331.75, 3424.4375, 3517.125, 3609.8125, 3702.5, 3795.1875, 3887.875, 3980.5625, 4073.25, 4165.9375, 4258.625, 4351.3125, 4444.0]}, "gradients/roberta.encoder.layer.3.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 3.0, 5.0, 2.0, 3.0, 5.0, 9.0, 15.0, 20.0, 32.0, 50.0, 73.0, 114.0, 222.0, 411.0, 903.0, 1763.0, 1298.0, 512.0, 253.0, 165.0, 97.0, 56.0, 38.0, 16.0, 13.0, 8.0, 10.0, 4.0, 3.0, 4.0, 3.0, 0.0, 5.0, 1.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-186.375, -180.4921875, -174.609375, -168.7265625, -162.84375, -156.9609375, -151.078125, -145.1953125, -139.3125, -133.4296875, -127.546875, -121.6640625, -115.78125, -109.8984375, -104.015625, -98.1328125, -92.25, -86.3671875, -80.484375, -74.6015625, -68.71875, -62.8359375, -56.953125, -51.0703125, -45.1875, -39.3046875, -33.421875, -27.5390625, -21.65625, -15.7734375, -9.890625, -4.0078125, 1.875, 7.7578125, 13.640625, 19.5234375, 25.40625, 31.2890625, 37.171875, 43.0546875, 48.9375, 54.8203125, 60.703125, 66.5859375, 72.46875, 78.3515625, 84.234375, 90.1171875, 96.0, 101.8828125, 107.765625, 113.6484375, 119.53125, 125.4140625, 131.296875, 137.1796875, 143.0625, 148.9453125, 154.828125, 160.7109375, 166.59375, 172.4765625, 178.359375, 184.2421875, 190.125]}, "gradients/roberta.encoder.layer.3.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 25.0, 586.0, 4872.0, 612.0, 31.0, 4.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-692.0, -650.046875, -608.09375, -566.140625, -524.1875, -482.234375, -440.28125, -398.328125, -356.375, -314.421875, -272.46875, -230.515625, -188.5625, -146.609375, -104.65625, -62.703125, -20.75, 21.203125, 63.15625, 105.109375, 147.0625, 189.015625, 230.96875, 272.921875, 314.875, 356.828125, 398.78125, 440.734375, 482.6875, 524.640625, 566.59375, 608.546875, 650.5, 692.453125, 734.40625, 776.359375, 818.3125, 860.265625, 902.21875, 944.171875, 986.125, 1028.078125, 1070.03125, 1111.984375, 1153.9375, 1195.890625, 1237.84375, 1279.796875, 1321.75, 1363.703125, 1405.65625, 1447.609375, 1489.5625, 1531.515625, 1573.46875, 1615.421875, 1657.375, 1699.328125, 1741.28125, 1783.234375, 1825.1875, 1867.140625, 1909.09375, 1951.046875, 1993.0]}, "gradients/roberta.encoder.layer.2.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 4.0, 3.0, 3.0, 14.0, 12.0, 31.0, 34.0, 52.0, 74.0, 98.0, 116.0, 209.0, 308.0, 390.0, 612.0, 757.0, 876.0, 816.0, 546.0, 358.0, 253.0, 164.0, 122.0, 83.0, 57.0, 31.0, 31.0, 31.0, 19.0, 11.0, 6.0, 4.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-276.25, -268.65234375, -261.0546875, -253.45703125, -245.859375, -238.26171875, -230.6640625, -223.06640625, -215.46875, -207.87109375, -200.2734375, -192.67578125, -185.078125, -177.48046875, -169.8828125, -162.28515625, -154.6875, -147.08984375, -139.4921875, -131.89453125, -124.296875, -116.69921875, -109.1015625, -101.50390625, -93.90625, -86.30859375, -78.7109375, -71.11328125, -63.515625, -55.91796875, -48.3203125, -40.72265625, -33.125, -25.52734375, -17.9296875, -10.33203125, -2.734375, 4.86328125, 12.4609375, 20.05859375, 27.65625, 35.25390625, 42.8515625, 50.44921875, 58.046875, 65.64453125, 73.2421875, 80.83984375, 88.4375, 96.03515625, 103.6328125, 111.23046875, 118.828125, 126.42578125, 134.0234375, 141.62109375, 149.21875, 156.81640625, 164.4140625, 172.01171875, 179.609375, 187.20703125, 194.8046875, 202.40234375, 210.0]}, "gradients/roberta.encoder.layer.2.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 6.0, 17.0, 6098.0, 11.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-5084.0, -4951.71875, -4819.4375, -4687.15625, -4554.875, -4422.59375, -4290.3125, -4158.03125, -4025.75, -3893.46875, -3761.1875, -3628.90625, -3496.625, -3364.34375, -3232.0625, -3099.78125, -2967.5, -2835.21875, -2702.9375, -2570.65625, -2438.375, -2306.09375, -2173.8125, -2041.53125, -1909.25, -1776.96875, -1644.6875, -1512.40625, -1380.125, -1247.84375, -1115.5625, -983.28125, -851.0, -718.71875, -586.4375, -454.15625, -321.875, -189.59375, -57.3125, 74.96875, 207.25, 339.53125, 471.8125, 604.09375, 736.375, 868.65625, 1000.9375, 1133.21875, 1265.5, 1397.78125, 1530.0625, 1662.34375, 1794.625, 1926.90625, 2059.1875, 2191.46875, 2323.75, 2456.03125, 2588.3125, 2720.59375, 2852.875, 2985.15625, 3117.4375, 3249.71875, 3382.0]}, "gradients/roberta.encoder.layer.2.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 6.0, 7.0, 8.0, 12.0, 16.0, 21.0, 48.0, 60.0, 154.0, 282.0, 614.0, 1468.0, 1892.0, 776.0, 367.0, 156.0, 112.0, 55.0, 19.0, 12.0, 12.0, 10.0, 0.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-172.5, -166.37109375, -160.2421875, -154.11328125, -147.984375, -141.85546875, -135.7265625, -129.59765625, -123.46875, -117.33984375, -111.2109375, -105.08203125, -98.953125, -92.82421875, -86.6953125, -80.56640625, -74.4375, -68.30859375, -62.1796875, -56.05078125, -49.921875, -43.79296875, -37.6640625, -31.53515625, -25.40625, -19.27734375, -13.1484375, -7.01953125, -0.890625, 5.23828125, 11.3671875, 17.49609375, 23.625, 29.75390625, 35.8828125, 42.01171875, 48.140625, 54.26953125, 60.3984375, 66.52734375, 72.65625, 78.78515625, 84.9140625, 91.04296875, 97.171875, 103.30078125, 109.4296875, 115.55859375, 121.6875, 127.81640625, 133.9453125, 140.07421875, 146.203125, 152.33203125, 158.4609375, 164.58984375, 170.71875, 176.84765625, 182.9765625, 189.10546875, 195.234375, 201.36328125, 207.4921875, 213.62109375, 219.75]}, "gradients/roberta.encoder.layer.2.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 10.0, 50.0, 171.0, 975.0, 2721.0, 1729.0, 362.0, 87.0, 14.0, 7.0, 5.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-556.5, -538.375, -520.25, -502.125, -484.0, -465.875, -447.75, -429.625, -411.5, -393.375, -375.25, -357.125, -339.0, -320.875, -302.75, -284.625, -266.5, -248.375, -230.25, -212.125, -194.0, -175.875, -157.75, -139.625, -121.5, -103.375, -85.25, -67.125, -49.0, -30.875, -12.75, 5.375, 23.5, 41.625, 59.75, 77.875, 96.0, 114.125, 132.25, 150.375, 168.5, 186.625, 204.75, 222.875, 241.0, 259.125, 277.25, 295.375, 313.5, 331.625, 349.75, 367.875, 386.0, 404.125, 422.25, 440.375, 458.5, 476.625, 494.75, 512.875, 531.0, 549.125, 567.25, 585.375, 603.5]}, "gradients/roberta.encoder.layer.1.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 6.0, 3.0, 6.0, 7.0, 3.0, 8.0, 13.0, 17.0, 20.0, 55.0, 67.0, 105.0, 191.0, 311.0, 576.0, 943.0, 1224.0, 995.0, 624.0, 378.0, 232.0, 127.0, 73.0, 40.0, 31.0, 18.0, 19.0, 7.0, 5.0, 7.0, 3.0, 4.0, 5.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0], "bins": [-394.5, -384.0078125, -373.515625, -363.0234375, -352.53125, -342.0390625, -331.546875, -321.0546875, -310.5625, -300.0703125, -289.578125, -279.0859375, -268.59375, -258.1015625, -247.609375, -237.1171875, -226.625, -216.1328125, -205.640625, -195.1484375, -184.65625, -174.1640625, -163.671875, -153.1796875, -142.6875, -132.1953125, -121.703125, -111.2109375, -100.71875, -90.2265625, -79.734375, -69.2421875, -58.75, -48.2578125, -37.765625, -27.2734375, -16.78125, -6.2890625, 4.203125, 14.6953125, 25.1875, 35.6796875, 46.171875, 56.6640625, 67.15625, 77.6484375, 88.140625, 98.6328125, 109.125, 119.6171875, 130.109375, 140.6015625, 151.09375, 161.5859375, 172.078125, 182.5703125, 193.0625, 203.5546875, 214.046875, 224.5390625, 235.03125, 245.5234375, 256.015625, 266.5078125, 277.0]}, "gradients/roberta.encoder.layer.1.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 78.0, 5932.0, 95.0, 13.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-1648.0, -1574.625, -1501.25, -1427.875, -1354.5, -1281.125, -1207.75, -1134.375, -1061.0, -987.625, -914.25, -840.875, -767.5, -694.125, -620.75, -547.375, -474.0, -400.625, -327.25, -253.875, -180.5, -107.125, -33.75, 39.625, 113.0, 186.375, 259.75, 333.125, 406.5, 479.875, 553.25, 626.625, 700.0, 773.375, 846.75, 920.125, 993.5, 1066.875, 1140.25, 1213.625, 1287.0, 1360.375, 1433.75, 1507.125, 1580.5, 1653.875, 1727.25, 1800.625, 1874.0, 1947.375, 2020.75, 2094.125, 2167.5, 2240.875, 2314.25, 2387.625, 2461.0, 2534.375, 2607.75, 2681.125, 2754.5, 2827.875, 2901.25, 2974.625, 3048.0]}, "gradients/roberta.encoder.layer.1.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 5.0, 6.0, 7.0, 19.0, 24.0, 34.0, 51.0, 86.0, 149.0, 377.0, 901.0, 2258.0, 1230.0, 452.0, 213.0, 119.0, 68.0, 39.0, 29.0, 18.0, 13.0, 4.0, 6.0, 7.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0], "bins": [-224.875, -219.34375, -213.8125, -208.28125, -202.75, -197.21875, -191.6875, -186.15625, -180.625, -175.09375, -169.5625, -164.03125, -158.5, -152.96875, -147.4375, -141.90625, -136.375, -130.84375, -125.3125, -119.78125, -114.25, -108.71875, -103.1875, -97.65625, -92.125, -86.59375, -81.0625, -75.53125, -70.0, -64.46875, -58.9375, -53.40625, -47.875, -42.34375, -36.8125, -31.28125, -25.75, -20.21875, -14.6875, -9.15625, -3.625, 1.90625, 7.4375, 12.96875, 18.5, 24.03125, 29.5625, 35.09375, 40.625, 46.15625, 51.6875, 57.21875, 62.75, 68.28125, 73.8125, 79.34375, 84.875, 90.40625, 95.9375, 101.46875, 107.0, 112.53125, 118.0625, 123.59375, 129.125]}, "gradients/roberta.encoder.layer.1.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 9.0, 21.0, 137.0, 618.0, 1968.0, 2319.0, 767.0, 202.0, 67.0, 12.0, 7.0, 4.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-187.5, -176.53125, -165.5625, -154.59375, -143.625, -132.65625, -121.6875, -110.71875, -99.75, -88.78125, -77.8125, -66.84375, -55.875, -44.90625, -33.9375, -22.96875, -12.0, -1.03125, 9.9375, 20.90625, 31.875, 42.84375, 53.8125, 64.78125, 75.75, 86.71875, 97.6875, 108.65625, 119.625, 130.59375, 141.5625, 152.53125, 163.5, 174.46875, 185.4375, 196.40625, 207.375, 218.34375, 229.3125, 240.28125, 251.25, 262.21875, 273.1875, 284.15625, 295.125, 306.09375, 317.0625, 328.03125, 339.0, 349.96875, 360.9375, 371.90625, 382.875, 393.84375, 404.8125, 415.78125, 426.75, 437.71875, 448.6875, 459.65625, 470.625, 481.59375, 492.5625, 503.53125, 514.5]}, "gradients/roberta.encoder.layer.0.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 4.0, 4.0, 6.0, 12.0, 21.0, 18.0, 32.0, 36.0, 47.0, 95.0, 143.0, 221.0, 363.0, 552.0, 812.0, 1074.0, 938.0, 638.0, 408.0, 230.0, 168.0, 99.0, 66.0, 40.0, 26.0, 21.0, 14.0, 10.0, 6.0, 4.0, 7.0, 5.0, 5.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-441.75, -427.79296875, -413.8359375, -399.87890625, -385.921875, -371.96484375, -358.0078125, -344.05078125, -330.09375, -316.13671875, -302.1796875, -288.22265625, -274.265625, -260.30859375, -246.3515625, -232.39453125, -218.4375, -204.48046875, -190.5234375, -176.56640625, -162.609375, -148.65234375, -134.6953125, -120.73828125, -106.78125, -92.82421875, -78.8671875, -64.91015625, -50.953125, -36.99609375, -23.0390625, -9.08203125, 4.875, 18.83203125, 32.7890625, 46.74609375, 60.703125, 74.66015625, 88.6171875, 102.57421875, 116.53125, 130.48828125, 144.4453125, 158.40234375, 172.359375, 186.31640625, 200.2734375, 214.23046875, 228.1875, 242.14453125, 256.1015625, 270.05859375, 284.015625, 297.97265625, 311.9296875, 325.88671875, 339.84375, 353.80078125, 367.7578125, 381.71484375, 395.671875, 409.62890625, 423.5859375, 437.54296875, 451.5]}, "gradients/roberta.encoder.layer.0.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 2.0, 2.0, 4.0, 1.0, 11.0, 31.0, 151.0, 583.0, 1695.0, 2104.0, 1108.0, 317.0, 85.0, 25.0, 11.0, 3.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-193.375, -176.259765625, -159.14453125, -142.029296875, -124.9140625, -107.798828125, -90.68359375, -73.568359375, -56.453125, -39.337890625, -22.22265625, -5.107421875, 12.0078125, 29.123046875, 46.23828125, 63.353515625, 80.46875, 97.583984375, 114.69921875, 131.814453125, 148.9296875, 166.044921875, 183.16015625, 200.275390625, 217.390625, 234.505859375, 251.62109375, 268.736328125, 285.8515625, 302.966796875, 320.08203125, 337.197265625, 354.3125, 371.427734375, 388.54296875, 405.658203125, 422.7734375, 439.888671875, 457.00390625, 474.119140625, 491.234375, 508.349609375, 525.46484375, 542.580078125, 559.6953125, 576.810546875, 593.92578125, 611.041015625, 628.15625, 645.271484375, 662.38671875, 679.501953125, 696.6171875, 713.732421875, 730.84765625, 747.962890625, 765.078125, 782.193359375, 799.30859375, 816.423828125, 833.5390625, 850.654296875, 867.76953125, 884.884765625, 902.0]}, "gradients/roberta.encoder.layer.0.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 5.0, 2.0, 1.0, 3.0, 7.0, 8.0, 6.0, 16.0, 20.0, 9.0, 28.0, 44.0, 54.0, 77.0, 116.0, 133.0, 193.0, 263.0, 416.0, 525.0, 787.0, 1098.0, 683.0, 448.0, 313.0, 269.0, 173.0, 116.0, 78.0, 55.0, 49.0, 35.0, 22.0, 26.0, 18.0, 12.0, 8.0, 3.0, 2.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-80.6875, -77.7333984375, -74.779296875, -71.8251953125, -68.87109375, -65.9169921875, -62.962890625, -60.0087890625, -57.0546875, -54.1005859375, -51.146484375, -48.1923828125, -45.23828125, -42.2841796875, -39.330078125, -36.3759765625, -33.421875, -30.4677734375, -27.513671875, -24.5595703125, -21.60546875, -18.6513671875, -15.697265625, -12.7431640625, -9.7890625, -6.8349609375, -3.880859375, -0.9267578125, 2.02734375, 4.9814453125, 7.935546875, 10.8896484375, 13.84375, 16.7978515625, 19.751953125, 22.7060546875, 25.66015625, 28.6142578125, 31.568359375, 34.5224609375, 37.4765625, 40.4306640625, 43.384765625, 46.3388671875, 49.29296875, 52.2470703125, 55.201171875, 58.1552734375, 61.109375, 64.0634765625, 67.017578125, 69.9716796875, 72.92578125, 75.8798828125, 78.833984375, 81.7880859375, 84.7421875, 87.6962890625, 90.650390625, 93.6044921875, 96.55859375, 99.5126953125, 102.466796875, 105.4208984375, 108.375]}, "gradients/roberta.encoder.layer.0.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 22.0, 102.0, 219.0, 554.0, 1114.0, 1463.0, 1272.0, 806.0, 365.0, 142.0, 42.0, 14.0, 10.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-118.625, -113.626953125, -108.62890625, -103.630859375, -98.6328125, -93.634765625, -88.63671875, -83.638671875, -78.640625, -73.642578125, -68.64453125, -63.646484375, -58.6484375, -53.650390625, -48.65234375, -43.654296875, -38.65625, -33.658203125, -28.66015625, -23.662109375, -18.6640625, -13.666015625, -8.66796875, -3.669921875, 1.328125, 6.326171875, 11.32421875, 16.322265625, 21.3203125, 26.318359375, 31.31640625, 36.314453125, 41.3125, 46.310546875, 51.30859375, 56.306640625, 61.3046875, 66.302734375, 71.30078125, 76.298828125, 81.296875, 86.294921875, 91.29296875, 96.291015625, 101.2890625, 106.287109375, 111.28515625, 116.283203125, 121.28125, 126.279296875, 131.27734375, 136.275390625, 141.2734375, 146.271484375, 151.26953125, 156.267578125, 161.265625, 166.263671875, 171.26171875, 176.259765625, 181.2578125, 186.255859375, 191.25390625, 196.251953125, 201.25]}, "eval_metroc": {"matthews_correlation": 0.6006236595789939}, "_wandb": {"runtime": 1133}}