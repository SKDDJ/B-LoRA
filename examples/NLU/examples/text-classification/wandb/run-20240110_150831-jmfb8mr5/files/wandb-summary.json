{"Training Loss": 0.3303155303001404, "_timestamp": 1704870882.8649943, "Learning rate": 0.00034993251825976503, "epoch": 14, "_runtime": 371.42723631858826, "_step": 3809, "gradients/classifier.out_proj.bias": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07595638930797577, -0.07358275353908539, -0.07120911777019501, -0.06883547455072403, -0.06646183878183365, -0.06408820301294327, -0.06171456724405289, -0.059340931475162506, -0.05696729198098183, -0.054593656212091446, -0.05222001671791077, -0.049846380949020386, -0.047472745180130005, -0.045099105685949326, -0.042725469917058945, -0.040351830422878265, -0.037978194653987885, -0.035604558885097504, -0.033230919390916824, -0.030857283622026443, -0.028483645990490913, -0.026110008358955383, -0.023736372590065002, -0.021362734958529472, -0.018989097326993942, -0.016615459695458412, -0.014241822995245457, -0.011868186295032501, -0.009494548663496971, -0.007120911031961441, -0.0047472743317484856, -0.00237363763153553, -7.450580596923828e-09, 0.002373629715293646, 0.004747266881167889, 0.007120904047042131, 0.009494541212916374, 0.011868178844451904, 0.01424181554466486, 0.016615452244877815, 0.018989089876413345, 0.021362727507948875, 0.023736365139484406, 0.026110000908374786, 0.028483638539910316, 0.030857276171445847, 0.03323091194033623, 0.03560455143451691, 0.03797818720340729, 0.04035182297229767, 0.04272546246647835, 0.04509909823536873, 0.04747273772954941, 0.04984637349843979, 0.05222000926733017, 0.05459364503622055, 0.05696728453040123, 0.05934092029929161, 0.06171455979347229, 0.06408819556236267, 0.06646183133125305, 0.06883546710014343, 0.07120911031961441, 0.07358274608850479, 0.07595638185739517]}, "gradients/roberta.encoder.layer.11.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 3.0, 2.0, 1.0, 4.0, 7.0, 8.0, 6.0, 14.0, 16.0, 14.0, 15.0, 31.0, 32.0, 40.0, 57.0, 85.0, 92.0, 131.0, 185.0, 274.0, 355.0, 459.0, 593.0, 624.0, 649.0, 570.0, 481.0, 364.0, 262.0, 187.0, 123.0, 117.0, 68.0, 59.0, 51.0, 38.0, 21.0, 26.0, 16.0, 15.0, 5.0, 6.0, 2.0, 3.0, 3.0, 1.0, 2.0, 6.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0], "bins": [-0.005366713274270296, -0.005194052588194609, -0.005021392367780209, -0.004848731681704521, -0.004676071461290121, -0.004503410775214434, -0.004330750554800034, -0.004158089868724346, -0.003985429182648659, -0.003812768729403615, -0.0036401082761585712, -0.003467447590082884, -0.0032947873696684837, -0.0031221266835927963, -0.0029494662303477526, -0.002776805777102709, -0.0026041455566883087, -0.002431485103443265, -0.002258824650198221, -0.002086163964122534, -0.0019135036272928119, -0.0017408431740477681, -0.0015681826043874025, -0.0013955221511423588, -0.001222861697897315, -0.0010502012446522713, -0.0008775407331995666, -0.0007048802217468619, -0.0005322197685018182, -0.0003595593152567744, -0.00018689874559640884, -1.423829235136509e-05, 0.00015842262655496597, 0.0003310831089038402, 0.0005037435912527144, 0.0006764041027054191, 0.0008490645559504628, 0.0010217250091955066, 0.0011943855788558722, 0.001367046032100916, 0.0015397064853459597, 0.0017123669385910034, 0.0018850273918360472, 0.002057687845081091, 0.0022303485311567783, 0.0024030087515711784, 0.002575669437646866, 0.0027483298908919096, 0.0029209903441369534, 0.003093650797381997, 0.003266311250627041, 0.0034389719367027283, 0.0036116321571171284, 0.0037842928431928158, 0.003956953063607216, 0.004129613749682903, 0.004302274435758591, 0.004474935121834278, 0.004647595342248678, 0.004820256028324366, 0.004992916248738766, 0.005165576934814453, 0.0053382376208901405, 0.005510897841304541, 0.005683558061718941]}, "gradients/roberta.encoder.layer.11.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.0, 9.0, 23.0, 180.0, 4460.0, 1404.0, 28.0, 10.0, 8.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0], "bins": [-0.24442249536514282, -0.23695887625217438, -0.22949524223804474, -0.2220316231250763, -0.21456800401210785, -0.2071043848991394, -0.19964075088500977, -0.19217713177204132, -0.18471351265907288, -0.17724989354610443, -0.1697862595319748, -0.16232264041900635, -0.1548590213060379, -0.14739540219306946, -0.13993176817893982, -0.13246814906597137, -0.12500452995300293, -0.11754090338945389, -0.11007728427648544, -0.1026136577129364, -0.09515003859996796, -0.08768641203641891, -0.08022278547286987, -0.07275916635990143, -0.06529553234577179, -0.057831909507513046, -0.0503682866692543, -0.04290466010570526, -0.035441040992736816, -0.027977414429187775, -0.02051379159092903, -0.013050168752670288, -0.005586549639701843, 0.0018770736642181873, 0.009340696968138218, 0.016804320737719536, 0.02426794357597828, 0.03173156827688217, 0.039195191115140915, 0.04665881395339966, 0.0541224367916584, 0.061586059629917145, 0.06904968619346619, 0.07651330530643463, 0.08397693186998367, 0.09144055843353271, 0.09890417754650116, 0.1063677966594696, 0.11383142322301865, 0.12129504978656769, 0.12875866889953613, 0.13622228801250458, 0.14368592202663422, 0.15114954113960266, 0.1586131602525711, 0.16607677936553955, 0.1735404133796692, 0.18100403249263763, 0.18846766650676727, 0.19593128561973572, 0.20339490473270416, 0.2108585238456726, 0.21832215785980225, 0.2257857769727707, 0.23324939608573914]}, "gradients/roberta.encoder.layer.11.attention.self.query.lora_B": {"_type": "histogram", "values": [3.0, 0.0, 2.0, 1.0, 0.0, 4.0, 2.0, 0.0, 3.0, 2.0, 6.0, 3.0, 5.0, 2.0, 6.0, 10.0, 19.0, 21.0, 12.0, 32.0, 54.0, 76.0, 70.0, 107.0, 140.0, 177.0, 282.0, 372.0, 342.0, 489.0, 535.0, 481.0, 551.0, 507.0, 360.0, 367.0, 304.0, 191.0, 167.0, 107.0, 73.0, 60.0, 58.0, 28.0, 22.0, 19.0, 22.0, 10.0, 7.0, 9.0, 2.0, 1.0, 4.0, 2.0, 5.0, 0.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0], "bins": [-0.009712470695376396, -0.009405173361301422, -0.009097876027226448, -0.008790578693151474, -0.0084832813590765, -0.008175984025001526, -0.007868686690926552, -0.007561388425529003, -0.007254091091454029, -0.006946793757379055, -0.006639496423304081, -0.006332199089229107, -0.0060249012894928455, -0.0057176039554178715, -0.005410306621342897, -0.005103008821606636, -0.004795711953192949, -0.004488414619117975, -0.004181117285043001, -0.0038738197181373835, -0.0035665221512317657, -0.0032592248171567917, -0.0029519274830818176, -0.0026446299161762, -0.002337332582101226, -0.002030035248026252, -0.001722737681120634, -0.00141544034704566, -0.0011081428965553641, -0.0008008454460650682, -0.0004935481119900942, -0.00018625054508447647, 0.00012104678899049759, 0.000428344210376963, 0.0007356416317634284, 0.0010429390240460634, 0.0013502364745363593, 0.0016575339250266552, 0.0019648312591016293, 0.002272128826007247, 0.002579426160082221, 0.002886723494157195, 0.003194021061062813, 0.003501318395137787, 0.003808615729212761, 0.004115913063287735, 0.004423210397362709, 0.00473050819709897, 0.0050378055311739445, 0.0053451028652489185, 0.005652400199323893, 0.005959697999060154, 0.006266995333135128, 0.006574292667210102, 0.006881590001285076, 0.00718888733536005, 0.007496184669435024, 0.007803482003509998, 0.008110779337584972, 0.008418076671659946, 0.00872537400573492, 0.00903267227113247, 0.009339969605207443, 0.009647266939282417, 0.009954564273357391]}, "gradients/roberta.encoder.layer.11.attention.self.query.lora_A": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0, 5.0, 25.0, 6071.0, 16.0, 4.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0], "bins": [-0.01849968358874321, -0.017910713329911232, -0.017321743071079254, -0.016732772812247276, -0.0161438025534153, -0.015554831363260746, -0.014965860173106194, -0.014376889914274216, -0.013787919655442238, -0.01319894939661026, -0.012609979137778282, -0.01202100794762373, -0.011432037688791752, -0.010843067429959774, -0.010254096239805222, -0.009665125980973244, -0.009076155722141266, -0.008487185463309288, -0.00789821520447731, -0.007309244014322758, -0.00672027375549078, -0.006131303496658802, -0.005542332772165537, -0.004953362047672272, -0.004364391788840294, -0.0037754212971776724, -0.003186450805515051, -0.0025974803138524294, -0.002008509822189808, -0.0014195393305271864, -0.0008305688388645649, -0.00024159811437129974, 0.0003473721444606781, 0.0009363426361232996, 0.001525313127785921, 0.0021142836194485426, 0.002703254111111164, 0.0032922246027737856, 0.003881195094436407, 0.004470165818929672, 0.00505913607776165, 0.005648106336593628, 0.006237077061086893, 0.006826047785580158, 0.007415018044412136, 0.008003988303244114, 0.008592959493398666, 0.009181929752230644, 0.009770900011062622, 0.0103598702698946, 0.010948840528726578, 0.01153781171888113, 0.012126781977713108, 0.012715752236545086, 0.013304723426699638, 0.013893693685531616, 0.014482663944363594, 0.015071634203195572, 0.01566060446202755, 0.016249574720859528, 0.016838546842336655, 0.017427517101168633, 0.01801648736000061, 0.018605457618832588, 0.019194427877664566]}, "gradients/roberta.encoder.layer.10.attention.self.value.lora_B": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 7.0, 2.0, 2.0, 4.0, 4.0, 1.0, 4.0, 10.0, 17.0, 19.0, 22.0, 19.0, 33.0, 40.0, 47.0, 59.0, 96.0, 106.0, 148.0, 184.0, 253.0, 338.0, 417.0, 647.0, 701.0, 695.0, 567.0, 420.0, 313.0, 232.0, 173.0, 129.0, 83.0, 68.0, 68.0, 45.0, 39.0, 23.0, 26.0, 12.0, 9.0, 16.0, 7.0, 6.0, 5.0, 7.0, 3.0, 3.0, 4.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0], "bins": [-0.01208084262907505, -0.011688772588968277, -0.011296701617538929, -0.010904631577432156, -0.010512560606002808, -0.010120490565896034, -0.00972842052578926, -0.009336349554359913, -0.008944278582930565, -0.008552208542823792, -0.008160137571394444, -0.00776806753128767, -0.007375996559858322, -0.006983926519751549, -0.006591856013983488, -0.006199785508215427, -0.005807715468108654, -0.005415644962340593, -0.005023574456572533, -0.004631504416465759, -0.004239433445036411, -0.0038473631720989943, -0.0034552928991615772, -0.0030632223933935165, -0.002671151887625456, -0.002279081381857395, -0.0018870109925046563, -0.0014949406031519175, -0.0011028700973838568, -0.0007107995916157961, -0.00031872931867837906, 7.334118708968163e-05, 0.0004654116928577423, 0.0008574821404181421, 0.0012495525879785419, 0.0016416229773312807, 0.0020336934830993414, 0.002425763988867402, 0.002817834261804819, 0.00320990476757288, 0.0036019752733409405, 0.003994045779109001, 0.004386116284877062, 0.0047781867906451225, 0.005170256830751896, 0.005562327802181244, 0.005954397842288017, 0.006346468348056078, 0.006738538853824139, 0.007130609359592199, 0.00752267986536026, 0.007914749905467033, 0.008306820876896381, 0.008698890917003155, 0.009090961888432503, 0.009483031928539276, 0.00987510196864605, 0.010267172008752823, 0.010659242980182171, 0.011051313020288944, 0.011443383991718292, 0.011835454031825066, 0.012227524071931839, 0.012619595043361187, 0.013011666014790535]}, "gradients/roberta.encoder.layer.10.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 7.0, 22.0, 1121.0, 4918.0, 44.0, 9.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.9506033658981323, -0.9235987663269043, -0.8965941667556763, -0.869589626789093, -0.842585027217865, -0.815580427646637, -0.7885758876800537, -0.7615712881088257, -0.7345666885375977, -0.7075620889663696, -0.6805574893951416, -0.6535529494285583, -0.6265483498573303, -0.5995437502861023, -0.572539210319519, -0.545534610748291, -0.518530011177063, -0.49152541160583496, -0.4645208418369293, -0.4375162720680237, -0.41051167249679565, -0.3835070729255676, -0.356502503156662, -0.32949793338775635, -0.3024933338165283, -0.2754887342453003, -0.24848416447639465, -0.22147957980632782, -0.194474995136261, -0.16747041046619415, -0.14046582579612732, -0.11346124112606049, -0.08645671606063843, -0.059452131390571594, -0.03244754672050476, -0.005442962050437927, 0.021561622619628906, 0.04856620728969574, 0.07557079195976257, 0.1025753766298294, 0.12957996129989624, 0.15658454596996307, 0.1835891306400299, 0.21059371531009674, 0.23759829998016357, 0.2646028995513916, 0.29160746932029724, 0.3186120390892029, 0.3456166386604309, 0.37262123823165894, 0.3996258080005646, 0.4266303777694702, 0.45363497734069824, 0.48063957691192627, 0.5076441764831543, 0.5346487164497375, 0.5616533160209656, 0.5886579155921936, 0.6156624555587769, 0.6426670551300049, 0.6696716547012329, 0.6966762542724609, 0.723680853843689, 0.7506853938102722, 0.7776899933815002]}, "gradients/roberta.encoder.layer.10.attention.self.query.lora_B": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 6.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 11.0, 11.0, 16.0, 17.0, 19.0, 21.0, 24.0, 46.0, 56.0, 94.0, 137.0, 211.0, 299.0, 567.0, 857.0, 1057.0, 968.0, 603.0, 362.0, 219.0, 141.0, 114.0, 61.0, 44.0, 29.0, 27.0, 18.0, 14.0, 17.0, 7.0, 8.0, 7.0, 3.0, 5.0, 3.0, 0.0, 2.0, 4.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0], "bins": [-0.038042545318603516, -0.036839377135038376, -0.035636208951473236, -0.0344330370426178, -0.03322986885905266, -0.03202670067548752, -0.03082353249192238, -0.02962036244571209, -0.0284171923995018, -0.02721402421593666, -0.026010854169726372, -0.024807685986161232, -0.023604515939950943, -0.022401347756385803, -0.021198179572820663, -0.019995009526610374, -0.018791841343045235, -0.017588673159480095, -0.016385503113269806, -0.015182334929704666, -0.013979164883494377, -0.012775996699929237, -0.011572827585041523, -0.010369658470153809, -0.009166489355266094, -0.00796332024037838, -0.0067601511254906654, -0.005556982476264238, -0.004353813361376524, -0.0031506442464888096, -0.0019474755972623825, -0.0007443064823746681, 0.00045886263251304626, 0.0016620316309854388, 0.0028652006294578314, 0.004068369511514902, 0.0052715386264026165, 0.006474707741290331, 0.007677876390516758, 0.008881045505404472, 0.010084214620292187, 0.011287383735179901, 0.012490552850067616, 0.01369372196495533, 0.01489689014852047, 0.01610006019473076, 0.0173032283782959, 0.018506396561861038, 0.019709566608071327, 0.020912734791636467, 0.022115904837846756, 0.023319073021411896, 0.024522243067622185, 0.025725411251187325, 0.026928581297397614, 0.028131749480962753, 0.029334917664527893, 0.030538085848093033, 0.03174125403165817, 0.03294442594051361, 0.03414759412407875, 0.03535076230764389, 0.03655393049120903, 0.03775709867477417, 0.03896027058362961]}, "gradients/roberta.encoder.layer.10.attention.self.query.lora_A": {"_type": "histogram", "values": [3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 29.0, 907.0, 5035.0, 112.0, 25.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0], "bins": [-0.08203218132257462, -0.07949447631835938, -0.07695676386356354, -0.0744190588593483, -0.07188135385513306, -0.06934364140033722, -0.06680593639612198, -0.06426823139190674, -0.0617305189371109, -0.05919281020760536, -0.05665510147809982, -0.05411739647388458, -0.051579687744379044, -0.049041979014873505, -0.046504274010658264, -0.043966565281152725, -0.041428856551647186, -0.03889114782214165, -0.03635343909263611, -0.03381573408842087, -0.03127802535891533, -0.02874031662940979, -0.0262026097625494, -0.02366490289568901, -0.02112719416618347, -0.018589485436677933, -0.016051778569817543, -0.013514070771634579, -0.010976362973451614, -0.00843865517526865, -0.005900947377085686, -0.003363240510225296, -0.0008255243301391602, 0.0017121834680438042, 0.0042498912662267685, 0.006787599064409733, 0.009325306862592697, 0.011863014660775661, 0.014400722458958626, 0.016938429325819016, 0.019476138055324554, 0.022013846784830093, 0.024551553651690483, 0.027089260518550873, 0.029626969248056412, 0.03216467797756195, 0.03470238298177719, 0.03724009171128273, 0.03977780044078827, 0.04231550917029381, 0.04485321789979935, 0.04739092290401459, 0.049928631633520126, 0.052466340363025665, 0.055004045367240906, 0.057541754096746445, 0.060079462826251984, 0.06261716783046722, 0.06515488028526306, 0.0676925852894783, 0.07023029029369354, 0.07276800274848938, 0.07530570775270462, 0.07784341275691986, 0.0803811252117157]}, "gradients/roberta.encoder.layer.9.attention.self.value.lora_B": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 4.0, 5.0, 4.0, 9.0, 10.0, 11.0, 28.0, 23.0, 28.0, 64.0, 81.0, 91.0, 147.0, 211.0, 260.0, 454.0, 675.0, 1099.0, 968.0, 641.0, 456.0, 255.0, 179.0, 128.0, 84.0, 63.0, 36.0, 37.0, 19.0, 16.0, 9.0, 6.0, 5.0, 8.0, 1.0, 2.0, 3.0, 1.0, 0.0, 4.0, 3.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.0350954644382, -0.03373994305729866, -0.03238442540168762, -0.031028904020786285, -0.02967338263988495, -0.028317861258983612, -0.026962341740727425, -0.025606822222471237, -0.0242513008415699, -0.022895779460668564, -0.021540259942412376, -0.02018474042415619, -0.018829219043254852, -0.017473697662353516, -0.016118178144097328, -0.014762657694518566, -0.013407137244939804, -0.012051616795361042, -0.01069609634578228, -0.009340575896203518, -0.007985055446624756, -0.006629534997045994, -0.005274014547467232, -0.00391849409788847, -0.0025629736483097076, -0.0012074531987309456, 0.00014806725084781647, 0.0015035877004265785, 0.0028591081500053406, 0.004214628599584103, 0.005570149049162865, 0.006925669498741627, 0.008281189948320389, 0.00963671039789915, 0.010992230847477913, 0.012347751297056675, 0.013703271746635437, 0.015058792196214199, 0.01641431264579296, 0.01776983216404915, 0.019125353544950485, 0.020480874925851822, 0.02183639444410801, 0.023191913962364197, 0.024547435343265533, 0.02590295672416687, 0.027258476242423058, 0.028613995760679245, 0.02996951714158058, 0.03132503852248192, 0.03268055617809296, 0.03403607755899429, 0.03539159893989563, 0.03674712032079697, 0.0381026417016983, 0.03945815935730934, 0.04081368073821068, 0.042169202119112015, 0.04352471977472305, 0.04488024115562439, 0.046235762536525726, 0.04759128391742706, 0.0489468052983284, 0.05030232295393944, 0.051657844334840775]}, "gradients/roberta.encoder.layer.9.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 9.0, 211.0, 5395.0, 488.0, 14.0, 5.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5677729845046997, -0.5522551536560059, -0.536737322807312, -0.5212194919586182, -0.5057016611099243, -0.49018383026123047, -0.4746659994125366, -0.45914819836616516, -0.4436303675174713, -0.42811253666877747, -0.4125947058200836, -0.39707687497138977, -0.3815590441226959, -0.36604124307632446, -0.3505234122276306, -0.33500558137893677, -0.3194877505302429, -0.3039699196815491, -0.2884520888328552, -0.2729342579841614, -0.25741642713546753, -0.24189861118793488, -0.22638078033924103, -0.21086296439170837, -0.19534510374069214, -0.1798272728919983, -0.16430944204330444, -0.1487916111946106, -0.13327379524707794, -0.1177559643983841, -0.10223813354969025, -0.086720310151577, -0.07120248675346375, -0.055684659630060196, -0.04016683250665665, -0.0246490016579628, -0.00913117453455925, 0.006386652588844299, 0.021904483437538147, 0.0374223068356514, 0.052940137684345245, 0.06845796853303909, 0.08397579193115234, 0.09949362277984619, 0.11501145362854004, 0.1305292844772339, 0.14604711532592773, 0.1615649312734604, 0.17708276212215424, 0.19260059297084808, 0.20811842381954193, 0.22363623976707458, 0.23915407061576843, 0.2546719014644623, 0.27018973231315613, 0.28570756316185, 0.3012253940105438, 0.31674322485923767, 0.3322610557079315, 0.34777888655662537, 0.3632967174053192, 0.3788145184516907, 0.3943323493003845, 0.40985018014907837, 0.4253680109977722]}, "gradients/roberta.encoder.layer.9.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 6.0, 2.0, 5.0, 6.0, 6.0, 14.0, 9.0, 9.0, 31.0, 43.0, 67.0, 105.0, 159.0, 313.0, 508.0, 992.0, 1662.0, 950.0, 480.0, 291.0, 169.0, 94.0, 69.0, 46.0, 14.0, 13.0, 13.0, 15.0, 7.0, 9.0, 7.0, 2.0, 5.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.04247213900089264, -0.04116430506110191, -0.03985647112131119, -0.038548633456230164, -0.03724079951643944, -0.03593296557664871, -0.03462512791156769, -0.03331729397177696, -0.03200946003198624, -0.03070162609219551, -0.029393790289759636, -0.02808595448732376, -0.026778120547533035, -0.02547028660774231, -0.024162450805306435, -0.02285461500287056, -0.021546781063079834, -0.02023894712328911, -0.018931111320853233, -0.01762327551841736, -0.016315441578626633, -0.015007606707513332, -0.013699771836400032, -0.012391936965286732, -0.011084102094173431, -0.009776267223060131, -0.00846843235194683, -0.00716059748083353, -0.00585276260972023, -0.00454492773860693, -0.0032370928674936295, -0.0019292579963803291, -0.0006214268505573273, 0.000686408020555973, 0.0019942428916692734, 0.0033020777627825737, 0.004609912633895874, 0.005917747505009174, 0.007225582376122475, 0.008533417247235775, 0.009841252118349075, 0.011149086989462376, 0.012456921860575676, 0.013764756731688976, 0.015072591602802277, 0.016380425542593002, 0.017688261345028877, 0.018996097147464752, 0.020303931087255478, 0.021611765027046204, 0.02291960082948208, 0.024227436631917953, 0.02553527057170868, 0.026843104511499405, 0.02815094031393528, 0.029458776116371155, 0.03076661005616188, 0.032074443995952606, 0.03338228166103363, 0.034690115600824356, 0.03599794954061508, 0.03730578348040581, 0.03861361742019653, 0.03992145508527756, 0.04122928902506828]}, "gradients/roberta.encoder.layer.9.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 9.0, 8.0, 38.0, 1808.0, 4139.0, 98.0, 13.0, 4.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0], "bins": [-0.14287704229354858, -0.13913333415985107, -0.13538964092731476, -0.13164593279361725, -0.12790222465991974, -0.12415852397680283, -0.12041482329368591, -0.1166711151599884, -0.11292741447687149, -0.10918371379375458, -0.10544000566005707, -0.10169630497694016, -0.09795260429382324, -0.09420889616012573, -0.09046519547700882, -0.0867214947938919, -0.0829777866601944, -0.07923408597707748, -0.07549037784337997, -0.07174667716026306, -0.06800297647714615, -0.06425926834344864, -0.060515567660331726, -0.056771863251924515, -0.0530281662940979, -0.04928446188569069, -0.045540761202573776, -0.041797056794166565, -0.038053352385759354, -0.03430964797735214, -0.03056594729423523, -0.026822242885828018, -0.023078538477420807, -0.019334835931658745, -0.015591131523251534, -0.011847428977489471, -0.008103725500404835, -0.004360022023320198, -0.000616319477558136, 0.0031273849308490753, 0.006871087476611137, 0.010614790953695774, 0.01435849443078041, 0.018102196976542473, 0.021845899522304535, 0.025589603930711746, 0.02933330647647381, 0.03307700902223587, 0.03682071343064308, 0.04056441783905029, 0.044308118522167206, 0.04805182293057442, 0.05179552733898163, 0.05553922802209854, 0.05928293243050575, 0.06302663683891296, 0.06677033752202988, 0.07051403820514679, 0.0742577463388443, 0.07800144702196121, 0.08174514770507812, 0.08548885583877563, 0.08923255652189255, 0.09297625720500946, 0.09671996533870697]}, "gradients/roberta.encoder.layer.8.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 5.0, 6.0, 4.0, 17.0, 23.0, 30.0, 48.0, 96.0, 148.0, 215.0, 324.0, 486.0, 756.0, 824.0, 835.0, 725.0, 575.0, 347.0, 233.0, 172.0, 93.0, 58.0, 20.0, 22.0, 15.0, 18.0, 2.0, 4.0, 2.0, 6.0, 5.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.08523714542388916, -0.0822099819779396, -0.07918282598257065, -0.0761556625366211, -0.07312849909067154, -0.07010133564472198, -0.06707417964935303, -0.06404701620340347, -0.06101985648274422, -0.05799269676208496, -0.054965533316135406, -0.05193837359547615, -0.048911213874816895, -0.04588405042886734, -0.042856890708208084, -0.03982973098754883, -0.036802567541599274, -0.03377540782094002, -0.030748244374990463, -0.027721084654331207, -0.024693923071026802, -0.021666761487722397, -0.01863960176706314, -0.015612440183758736, -0.01258527860045433, -0.009558117017149925, -0.006530956365168095, -0.003503795713186264, -0.0004766341298818588, 0.0025505274534225464, 0.005577687174081802, 0.008604848757386208, 0.011632002890110016, 0.014659164473414421, 0.017686326056718826, 0.020713485777378082, 0.023740647360682487, 0.026767808943986893, 0.02979496866464615, 0.0328221321105957, 0.03584929183125496, 0.038876451551914215, 0.04190361499786377, 0.044930774718523026, 0.04795793443918228, 0.050985097885131836, 0.05401225760579109, 0.05703941732645035, 0.0600665807723999, 0.06309374421834946, 0.06612090021371841, 0.06914806365966797, 0.07217522710561752, 0.07520239055156708, 0.07822954654693604, 0.08125670999288559, 0.08428387343883514, 0.0873110368847847, 0.09033819288015366, 0.09336535632610321, 0.09639251977205276, 0.09941968321800232, 0.10244683921337128, 0.10547400265932083, 0.10850115865468979]}, "gradients/roberta.encoder.layer.8.attention.self.value.lora_A": {"_type": "histogram", "values": [2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 10.0, 14.0, 667.0, 5269.0, 142.0, 8.0, 7.0, 2.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.19765909016132355, -0.18742439150810242, -0.1771896928548813, -0.16695499420166016, -0.15672029554843903, -0.1464855968952179, -0.13625088334083557, -0.12601619958877563, -0.11578149348497391, -0.10554679483175278, -0.09531209617853165, -0.08507739007472992, -0.07484269142150879, -0.06460799276828766, -0.05437329411506653, -0.0441385954618454, -0.03390389680862427, -0.023669198155403137, -0.013434497639536858, -0.003199797123670578, 0.007034901529550552, 0.017269600182771683, 0.02750430256128311, 0.03773900121450424, 0.04797369986772537, 0.0582083985209465, 0.06844309717416763, 0.07867780327796936, 0.08891250193119049, 0.09914720058441162, 0.10938189923763275, 0.11961659789085388, 0.1298513114452362, 0.14008601009845734, 0.15032070875167847, 0.1605554074048996, 0.17079010605812073, 0.18102480471134186, 0.191259503364563, 0.2014942169189453, 0.21172890067100525, 0.22196359932422638, 0.2321982979774475, 0.24243299663066864, 0.25266769528388977, 0.2629024088382721, 0.27313709259033203, 0.28337180614471436, 0.2936065196990967, 0.303841233253479, 0.31407591700553894, 0.32431063055992126, 0.3345453143119812, 0.3447800278663635, 0.35501471161842346, 0.3652494251728058, 0.3754841089248657, 0.38571882247924805, 0.395953506231308, 0.4061882197856903, 0.41642290353775024, 0.42665761709213257, 0.4368923008441925, 0.44712701439857483, 0.45736169815063477]}, "gradients/roberta.encoder.layer.8.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 2.0, 0.0, 0.0, 8.0, 5.0, 5.0, 17.0, 26.0, 17.0, 43.0, 76.0, 115.0, 173.0, 308.0, 586.0, 1213.0, 1549.0, 850.0, 464.0, 256.0, 151.0, 79.0, 64.0, 25.0, 30.0, 12.0, 11.0, 7.0, 13.0, 6.0, 5.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.04093131795525551, -0.03948341682553291, -0.03803551569581032, -0.03658761456608772, -0.035139717161655426, -0.03369181603193283, -0.032243914902210236, -0.03079601377248764, -0.029348112642765045, -0.02790021151304245, -0.026452310383319855, -0.02500441111624241, -0.023556509986519814, -0.02210860885679722, -0.020660709589719772, -0.019212808459997177, -0.017764907330274582, -0.016317006200551987, -0.014869106002151966, -0.013421205803751945, -0.01197330467402935, -0.010525403544306755, -0.009077503345906734, -0.007629603147506714, -0.006181702017784119, -0.004733801353722811, -0.003285900689661503, -0.001838000025600195, -0.000390099361538887, 0.0010578013025224209, 0.002505701966583729, 0.003953602164983749, 0.005401503294706345, 0.0068494039587676525, 0.00829730462282896, 0.009745204821228981, 0.011193105950951576, 0.012641007080674171, 0.014088907279074192, 0.015536807477474213, 0.016984708607196808, 0.018432609736919403, 0.019880510866642, 0.021328410133719444, 0.02277631126344204, 0.024224212393164635, 0.02567211166024208, 0.027120012789964676, 0.02856791391968727, 0.030015815049409866, 0.03146371617913246, 0.03291161730885506, 0.034359514713287354, 0.03580741584300995, 0.037255316972732544, 0.03870321810245514, 0.040151119232177734, 0.04159902036190033, 0.043046921491622925, 0.04449482262134552, 0.045942723751068115, 0.04739062115550041, 0.04883852228522301, 0.0502864234149456, 0.0517343245446682]}, "gradients/roberta.encoder.layer.8.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 3.0, 10.0, 39.0, 461.0, 5055.0, 497.0, 42.0, 13.0, 6.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0], "bins": [-0.1572498083114624, -0.15305912494659424, -0.14886842668056488, -0.14467774331569672, -0.14048704504966736, -0.1362963616847992, -0.13210567831993103, -0.12791498005390167, -0.12372429668903351, -0.11953360587358475, -0.11534291505813599, -0.11115223169326782, -0.10696154087781906, -0.1027708500623703, -0.09858016669750214, -0.09438947588205338, -0.09019878506660461, -0.08600809425115585, -0.08181740343570709, -0.07762672007083893, -0.07343602925539017, -0.0692453384399414, -0.06505465507507324, -0.06086396425962448, -0.05667327344417572, -0.05248258262872696, -0.0482918955385685, -0.044101208448410034, -0.03991051763296127, -0.03571982681751251, -0.03152913972735405, -0.027338450774550438, -0.023147769272327423, -0.01895708031952381, -0.0147663913667202, -0.010575702413916588, -0.006385013461112976, -0.0021943245083093643, 0.0019963644444942474, 0.006187053397297859, 0.010377742350101471, 0.014568431302905083, 0.018759120255708694, 0.022949809208512306, 0.027140498161315918, 0.03133118897676468, 0.03552187606692314, 0.039712563157081604, 0.043903253972530365, 0.048093944787979126, 0.05228463187813759, 0.05647531896829605, 0.06066600978374481, 0.06485670059919357, 0.06904739141464233, 0.0732380747795105, 0.07742876559495926, 0.08161945641040802, 0.08581013977527618, 0.09000083059072495, 0.0941915214061737, 0.09838221222162247, 0.10257290303707123, 0.10676358640193939, 0.11095427721738815]}, "gradients/roberta.encoder.layer.7.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0, 4.0, 4.0, 7.0, 8.0, 9.0, 18.0, 33.0, 40.0, 79.0, 122.0, 238.0, 404.0, 645.0, 849.0, 1067.0, 944.0, 696.0, 384.0, 234.0, 147.0, 69.0, 49.0, 33.0, 10.0, 13.0, 7.0, 5.0, 7.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07325363159179688, -0.07100284099578857, -0.06875205039978027, -0.06650125235319138, -0.06425046175718307, -0.061999671161174774, -0.05974888056516647, -0.057498086243867874, -0.055247291922569275, -0.052996501326560974, -0.050745707005262375, -0.048494916409254074, -0.046244122087955475, -0.043993331491947174, -0.04174254089593887, -0.039491746574640274, -0.03724095597863197, -0.03499016538262367, -0.03273937106132507, -0.030488580465316772, -0.028237786144018173, -0.025986995548009872, -0.023736203089356422, -0.021485410630702972, -0.019234618172049522, -0.016983825713396072, -0.014733033254742622, -0.012482241727411747, -0.010231449268758297, -0.007980656810104847, -0.0057298652827739716, -0.0034790728241205215, -0.0012282803654670715, 0.0010225118603557348, 0.003273304086178541, 0.005524096079170704, 0.007774888537824154, 0.010025680996477604, 0.01227647252380848, 0.01452726498246193, 0.01677805744111538, 0.01902884989976883, 0.02127964235842228, 0.02353043481707573, 0.02578122541308403, 0.02803201973438263, 0.03028281033039093, 0.03253360092639923, 0.03478439524769783, 0.03703518584370613, 0.03928598016500473, 0.04153677076101303, 0.04378756508231163, 0.04603835567831993, 0.04828914999961853, 0.05053994059562683, 0.05279073119163513, 0.05504152178764343, 0.05729231610894203, 0.05954310670495033, 0.06179390102624893, 0.06404469162225723, 0.06629548221826553, 0.06854628026485443, 0.07079707086086273]}, "gradients/roberta.encoder.layer.7.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 6.0, 13.0, 139.0, 5899.0, 55.0, 10.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.5132454633712769, -0.4963797926902771, -0.47951412200927734, -0.4626484513282776, -0.44578278064727783, -0.4289171099662781, -0.4120514690876007, -0.39518579840660095, -0.3783201277256012, -0.36145445704460144, -0.3445887863636017, -0.32772311568260193, -0.31085747480392456, -0.2939918041229248, -0.27712613344192505, -0.2602604627609253, -0.24339479207992554, -0.22652912139892578, -0.20966345071792603, -0.19279779493808746, -0.1759321242570877, -0.15906645357608795, -0.1422007977962494, -0.12533512711524963, -0.10846945643424988, -0.09160378575325012, -0.07473812252283096, -0.057872455567121506, -0.04100678861141205, -0.024141117930412292, -0.0072754546999931335, 0.009590208530426025, 0.02645587921142578, 0.04332154616713524, 0.060187213122844696, 0.07705287635326385, 0.09391854703426361, 0.11078421771526337, 0.12764987349510193, 0.14451554417610168, 0.16138121485710144, 0.1782468855381012, 0.19511255621910095, 0.21197821199893951, 0.22884388267993927, 0.24570955336093903, 0.2625752091407776, 0.27944087982177734, 0.2963065505027771, 0.31317222118377686, 0.3300378918647766, 0.34690356254577637, 0.3637692332267761, 0.3806349039077759, 0.39750054478645325, 0.414366215467453, 0.43123188614845276, 0.4480975568294525, 0.46496322751045227, 0.481828898191452, 0.4986945390701294, 0.5155602097511292, 0.5324258804321289, 0.5492915511131287, 0.5661572217941284]}, "gradients/roberta.encoder.layer.7.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 2.0, 13.0, 10.0, 13.0, 21.0, 29.0, 76.0, 139.0, 476.0, 3339.0, 1481.0, 290.0, 95.0, 49.0, 29.0, 13.0, 8.0, 11.0, 5.0, 7.0, 3.0, 0.0, 2.0, 2.0, 3.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0], "bins": [-0.19139128923416138, -0.18604625761508942, -0.18070121109485626, -0.1753561794757843, -0.17001113295555115, -0.1646661013364792, -0.15932106971740723, -0.15397602319717407, -0.14863097667694092, -0.14328594505786896, -0.1379408985376358, -0.13259586691856384, -0.1272508203983307, -0.12190578877925873, -0.11656074970960617, -0.11121571063995361, -0.10587067902088165, -0.1005256399512291, -0.09518060088157654, -0.08983556926250458, -0.08449052274227142, -0.07914549112319946, -0.0738004520535469, -0.06845541298389435, -0.06311037391424179, -0.05776533484458923, -0.052420295774936676, -0.04707526043057442, -0.04173022136092186, -0.0363851822912693, -0.031040146946907043, -0.025695107877254486, -0.020350053906440735, -0.015005015768110752, -0.00965997762978077, -0.004314940422773361, 0.0010300986468791962, 0.0063751377165317535, 0.011720173060894012, 0.01706521213054657, 0.022410251200199127, 0.027755290269851685, 0.03310032933950424, 0.0384453646838665, 0.04379040375351906, 0.049135442823171616, 0.054480478167533875, 0.05982551723718643, 0.06517055630683899, 0.07051559537649155, 0.0758606344461441, 0.08120566606521606, 0.08655071258544922, 0.09189574420452118, 0.09724078327417374, 0.1025858223438263, 0.10793086141347885, 0.11327590048313141, 0.11862093955278397, 0.12396597862243652, 0.12931101024150848, 0.13465605676174164, 0.1400010883808136, 0.14534613490104675, 0.1506911665201187]}, "gradients/roberta.encoder.layer.7.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 5.0, 20.0, 742.0, 5234.0, 108.0, 9.0, 4.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.5397009253501892, -0.5252201557159424, -0.5107393860816956, -0.49625861644744873, -0.4817778170108795, -0.4672970473766327, -0.45281627774238586, -0.43833550810813904, -0.4238547384738922, -0.4093739688396454, -0.39489319920539856, -0.38041239976882935, -0.3659316301345825, -0.3514508605003357, -0.33697009086608887, -0.32248932123184204, -0.3080085515975952, -0.2935277819633484, -0.27904701232910156, -0.26456624269485474, -0.2500854432582855, -0.2356046736240387, -0.22112390398979187, -0.20664313435554504, -0.19216233491897583, -0.177681565284729, -0.16320078074932098, -0.14872001111507416, -0.13423924148082733, -0.11975846439599991, -0.10527768731117249, -0.09079691767692566, -0.07631614804267883, -0.06183537468314171, -0.047354601323604584, -0.03287382423877716, -0.018393050879240036, -0.003912277519702911, 0.010568499565124512, 0.025049269199371338, 0.03953004628419876, 0.054010819643735886, 0.06849159300327301, 0.08297237008810043, 0.09745314717292786, 0.11193391680717468, 0.1264146864414215, 0.14089545607566833, 0.15537624061107635, 0.16985701024532318, 0.1843377947807312, 0.19881856441497803, 0.21329933404922485, 0.22778010368347168, 0.2422608882188797, 0.25674164295196533, 0.27122244238853455, 0.28570321202278137, 0.3001839816570282, 0.3146647810935974, 0.32914555072784424, 0.34362632036209106, 0.3581070899963379, 0.3725878596305847, 0.38706862926483154]}, "gradients/roberta.encoder.layer.6.attention.self.value.lora_B": {"_type": "histogram", "values": [2.0, 0.0, 0.0, 0.0, 6.0, 1.0, 1.0, 2.0, 3.0, 7.0, 6.0, 10.0, 7.0, 7.0, 21.0, 16.0, 28.0, 30.0, 53.0, 63.0, 69.0, 100.0, 158.0, 173.0, 221.0, 303.0, 437.0, 497.0, 610.0, 612.0, 559.0, 462.0, 383.0, 297.0, 244.0, 176.0, 151.0, 95.0, 79.0, 63.0, 45.0, 34.0, 21.0, 13.0, 14.0, 14.0, 11.0, 10.0, 6.0, 3.0, 7.0, 3.0, 3.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05690809711813927, -0.05497312545776367, -0.05303815379738808, -0.05110318213701248, -0.04916821047663689, -0.04723323881626129, -0.045298267155885696, -0.0433632954955101, -0.041428323835134506, -0.03949335217475891, -0.037558380514383316, -0.03562340885400772, -0.033688437193632126, -0.03175346553325653, -0.029818493872880936, -0.02788352221250534, -0.025948550552129745, -0.02401357889175415, -0.022078607231378555, -0.02014363557100296, -0.018208663910627365, -0.01627369225025177, -0.014338720589876175, -0.01240374892950058, -0.010468777269124985, -0.00853380560874939, -0.0065988339483737946, -0.0046638622879981995, -0.0027288906276226044, -0.0007939189672470093, 0.0011410526931285858, 0.003076024353504181, 0.0050109997391700745, 0.0069459713995456696, 0.008880943059921265, 0.01081591472029686, 0.012750886380672455, 0.01468585804104805, 0.016620829701423645, 0.01855580136179924, 0.020490773022174835, 0.02242574468255043, 0.024360716342926025, 0.02629568800330162, 0.028230659663677216, 0.03016563132405281, 0.032100602984428406, 0.034035574644804, 0.035970546305179596, 0.03790551796555519, 0.039840489625930786, 0.04177546128630638, 0.043710432946681976, 0.04564540460705757, 0.047580376267433167, 0.04951534792780876, 0.05145031958818436, 0.05338529124855995, 0.05532026290893555, 0.05725523456931114, 0.05919020622968674, 0.06112517789006233, 0.06306014955043793, 0.06499512493610382, 0.06693009287118912]}, "gradients/roberta.encoder.layer.6.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 9.0, 18.0, 4099.0, 1968.0, 16.0, 8.0, 1.0, 2.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.15349332988262177, -0.1438385248184204, -0.13418373465538025, -0.1245289295911789, -0.11487413197755814, -0.10521933436393738, -0.09556452929973602, -0.08590973168611526, -0.0762549340724945, -0.06660013645887375, -0.05694533511996269, -0.047290533781051636, -0.03763573616743088, -0.02798093855381012, -0.018326137214899063, -0.008671335875988007, 0.0009834617376327515, 0.010638261213898659, 0.020293060690164566, 0.029947860166430473, 0.03960265964269638, 0.04925745725631714, 0.058912258595228195, 0.06856705993413925, 0.07822185754776001, 0.08787665516138077, 0.09753145277500153, 0.10718625783920288, 0.11684105545282364, 0.1264958530664444, 0.13615065813064575, 0.1458054482936859, 0.15546026825904846, 0.16511507332324982, 0.17476986348628998, 0.18442466855049133, 0.1940794587135315, 0.20373426377773285, 0.2133890688419342, 0.22304385900497437, 0.23269866406917572, 0.24235346913337708, 0.25200825929641724, 0.2616630494594574, 0.27131786942481995, 0.2809726595878601, 0.29062744975090027, 0.3002822697162628, 0.309937059879303, 0.31959185004234314, 0.3292466700077057, 0.33890146017074585, 0.348556250333786, 0.35821104049682617, 0.3678658604621887, 0.3775206506252289, 0.38717544078826904, 0.3968302309513092, 0.40648505091667175, 0.4161398410797119, 0.4257946312427521, 0.43544942140579224, 0.4451042413711548, 0.45475903153419495, 0.4644138514995575]}, "gradients/roberta.encoder.layer.6.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 9.0, 11.0, 20.0, 27.0, 46.0, 76.0, 122.0, 264.0, 796.0, 2485.0, 1415.0, 431.0, 164.0, 73.0, 60.0, 34.0, 24.0, 13.0, 12.0, 8.0, 6.0, 4.0, 5.0, 2.0, 5.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0], "bins": [-0.10806221514940262, -0.10511936992406845, -0.10217652469873428, -0.09923367202281952, -0.09629082679748535, -0.09334798157215118, -0.09040513634681702, -0.08746229112148285, -0.08451944589614868, -0.08157660067081451, -0.07863375544548035, -0.07569091022014618, -0.07274805754423141, -0.06980521231889725, -0.06686236709356308, -0.06391952186822891, -0.060976672917604446, -0.05803382769227028, -0.05509097874164581, -0.052148133516311646, -0.04920528829097748, -0.04626244306564331, -0.043319594115018845, -0.04037674888968468, -0.03743389993906021, -0.034491054713726044, -0.03154820576310158, -0.02860536053776741, -0.025662515312433243, -0.022719668224453926, -0.01977682113647461, -0.016833975911140442, -0.013891130685806274, -0.010948284529149532, -0.00800543837249279, -0.0050625912845134735, -0.0021197451278567314, 0.0008231010288000107, 0.0037659481167793274, 0.006708793342113495, 0.009651640430092812, 0.012594486586749554, 0.015537332743406296, 0.018480179831385612, 0.02142302691936493, 0.024365872144699097, 0.027308719232678413, 0.03025156445801258, 0.0331944115459919, 0.036137256771326065, 0.03908010572195053, 0.0420229509472847, 0.044965796172618866, 0.04790864139795303, 0.0508514903485775, 0.05379433557391167, 0.05673718452453613, 0.0596800297498703, 0.06262287497520447, 0.06556572020053864, 0.0685085728764534, 0.07145141810178757, 0.07439426332712173, 0.0773371085524559, 0.08027995377779007]}, "gradients/roberta.encoder.layer.6.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 5.0, 6.0, 83.0, 2417.0, 3454.0, 140.0, 17.0, 8.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.11964228004217148, -0.11336496472358704, -0.107087641954422, -0.10081032663583755, -0.09453300386667252, -0.08825568854808807, -0.08197836577892303, -0.07570105046033859, -0.06942373514175415, -0.06314641982316971, -0.05686909705400467, -0.05059178173542023, -0.04431445896625519, -0.038037143647670746, -0.031759824603796005, -0.025482505559921265, -0.019205182790756226, -0.012927863746881485, -0.006650545634329319, -0.000373227521777153, 0.005904091522097588, 0.012181408703327179, 0.01845872774720192, 0.02473604679107666, 0.0310133658349514, 0.03729068487882614, 0.04356800392270088, 0.04984532296657562, 0.056122638285160065, 0.062399957329034805, 0.06867727637290955, 0.07495459914207458, 0.08123190701007843, 0.08750922232866287, 0.09378654509782791, 0.10006386041641235, 0.10634118318557739, 0.11261849850416183, 0.11889581382274628, 0.12517313659191132, 0.13145045936107635, 0.1377277821302414, 0.14400508999824524, 0.15028241276741028, 0.15655973553657532, 0.16283705830574036, 0.1691143661737442, 0.17539168894290924, 0.18166899681091309, 0.18794631958007812, 0.19422362744808197, 0.200500950217247, 0.20677827298641205, 0.2130555808544159, 0.21933290362358093, 0.22561022639274597, 0.231887549161911, 0.23816487193107605, 0.2444421797990799, 0.25071951746940613, 0.2569968104362488, 0.2632741332054138, 0.26955145597457886, 0.2758287787437439, 0.28210610151290894]}, "gradients/roberta.encoder.layer.5.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 5.0, 7.0, 17.0, 24.0, 19.0, 35.0, 32.0, 78.0, 93.0, 126.0, 188.0, 311.0, 527.0, 729.0, 986.0, 995.0, 670.0, 422.0, 276.0, 188.0, 103.0, 93.0, 68.0, 52.0, 29.0, 22.0, 9.0, 6.0, 4.0, 6.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.06583454459905624, -0.06347449868917465, -0.06111445650458336, -0.058754414319992065, -0.056394368410110474, -0.05403432622551918, -0.05167428404092789, -0.049314238131046295, -0.046954195946455, -0.04459415376186371, -0.04223410785198212, -0.03987406566739082, -0.03751402348279953, -0.03515397757291794, -0.032793935388326645, -0.030433891341090202, -0.02807384729385376, -0.025713803246617317, -0.023353759199380875, -0.02099371701478958, -0.01863367296755314, -0.016273628920316696, -0.013913585804402828, -0.01155354268848896, -0.009193498641252518, -0.0068334550596773624, -0.004473411478102207, -0.002113367896527052, 0.00024667568504810333, 0.002606719732284546, 0.004966762848198414, 0.007326805964112282, 0.009686842560768127, 0.01204688660800457, 0.014406929723918438, 0.016766972839832306, 0.01912701688706875, 0.02148706093430519, 0.023847103118896484, 0.026207147166132927, 0.02856719121336937, 0.030927235260605812, 0.033287279307842255, 0.03564732149243355, 0.03800736367702484, 0.04036740958690643, 0.042727451771497726, 0.04508749395608902, 0.04744753986597061, 0.049807582050561905, 0.0521676279604435, 0.05452767014503479, 0.05688771605491638, 0.059247758239507675, 0.06160780042409897, 0.06396784633398056, 0.06632788479328156, 0.06868793070316315, 0.07104796916246414, 0.07340801507234573, 0.07576806098222733, 0.07812809944152832, 0.08048814535140991, 0.0828481912612915, 0.0852082371711731]}, "gradients/roberta.encoder.layer.5.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 6.0, 30.0, 6059.0, 31.0, 3.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-1.4725512266159058, -1.4322904348373413, -1.3920297622680664, -1.351768970489502, -1.3115081787109375, -1.271247386932373, -1.2309865951538086, -1.1907259225845337, -1.1504651308059692, -1.1102043390274048, -1.0699436664581299, -1.0296828746795654, -0.989422082901001, -0.9491612911224365, -0.9089005589485168, -0.8686398267745972, -0.8283790349960327, -0.7881182432174683, -0.7478575110435486, -0.7075967788696289, -0.6673359870910645, -0.6270751953125, -0.5868144631385803, -0.5465537309646606, -0.5062929391860962, -0.4660321772098541, -0.42577141523361206, -0.38551065325737, -0.34524989128112793, -0.30498912930488586, -0.2647283673286438, -0.22446760535240173, -0.18420684337615967, -0.1439460813999176, -0.10368531942367554, -0.06342455744743347, -0.023163795471191406, 0.01709696650505066, 0.057357728481292725, 0.09761849045753479, 0.13787925243377686, 0.17814001441001892, 0.218400776386261, 0.25866153836250305, 0.2989223003387451, 0.3391830623149872, 0.37944382429122925, 0.4197045862674713, 0.4599653482437134, 0.5002261400222778, 0.5404868721961975, 0.5807476043701172, 0.6210083961486816, 0.6612691879272461, 0.7015299201011658, 0.7417906522750854, 0.7820514440536499, 0.8223122358322144, 0.862572968006134, 0.9028337001800537, 0.9430944919586182, 0.9833552837371826, 1.023616075515747, 1.063876748085022, 1.1041375398635864]}, "gradients/roberta.encoder.layer.5.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 4.0, 3.0, 14.0, 14.0, 23.0, 48.0, 78.0, 190.0, 682.0, 2678.0, 1700.0, 377.0, 142.0, 79.0, 34.0, 16.0, 17.0, 7.0, 4.0, 7.0, 2.0, 3.0, 1.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05228499695658684, -0.050175849348306656, -0.048066698014736176, -0.045957550406455994, -0.04384840279817581, -0.04173925518989563, -0.03963010385632515, -0.03752095624804497, -0.03541180491447449, -0.033302657306194305, -0.031193507835268974, -0.029084358364343643, -0.02697521075606346, -0.02486606128513813, -0.0227569118142128, -0.020647764205932617, -0.018538616597652435, -0.016429467126727104, -0.014320319518446922, -0.012211170047521591, -0.010102021507918835, -0.007992872968316078, -0.005883723497390747, -0.0037745749577879906, -0.001665426418185234, 0.0004437223542481661, 0.0025528711266815662, 0.00466202013194561, 0.0067711686715483665, 0.008880317211151123, 0.010989466682076454, 0.01309861522167921, 0.015207767486572266, 0.017316916957497597, 0.01942606456577778, 0.02153521403670311, 0.02364436164498329, 0.025753511115908623, 0.027862660586833954, 0.029971808195114136, 0.03208095580339432, 0.0341901034116745, 0.03629925474524498, 0.03840840235352516, 0.040517549961805344, 0.042626701295375824, 0.044735848903656006, 0.04684499651193619, 0.04895414784550667, 0.05106329545378685, 0.05317244678735733, 0.05528159439563751, 0.057390742003917694, 0.059499889612197876, 0.061609040945768356, 0.06371819227933884, 0.06582733988761902, 0.0679364874958992, 0.07004563510417938, 0.07215479016304016, 0.07426393777132034, 0.07637308537960052, 0.0784822329878807, 0.08059138059616089, 0.08270052820444107]}, "gradients/roberta.encoder.layer.5.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 9.0, 47.0, 4105.0, 1932.0, 25.0, 6.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.37025707960128784, -0.3569882810115814, -0.343719482421875, -0.33045071363449097, -0.31718191504478455, -0.3039131164550781, -0.2906443476676941, -0.27737554907798767, -0.26410675048828125, -0.25083795189857483, -0.2375691682100296, -0.22430038452148438, -0.21103158593177795, -0.19776278734207153, -0.1844940036535263, -0.17122521996498108, -0.15795642137527466, -0.14468762278556824, -0.131418839097023, -0.11815004795789719, -0.10488125681877136, -0.09161246567964554, -0.07834367454051971, -0.06507488340139389, -0.051806092262268066, -0.03853730112314224, -0.02526850998401642, -0.011999718844890594, 0.0012690722942352295, 0.014537863433361053, 0.027806654572486877, 0.0410754457116127, 0.054344236850738525, 0.06761302798986435, 0.08088181912899017, 0.094150610268116, 0.10741940140724182, 0.12068819254636765, 0.13395698368549347, 0.1472257673740387, 0.16049456596374512, 0.17376336455345154, 0.18703214824199677, 0.200300931930542, 0.2135697305202484, 0.22683852910995483, 0.24010731279850006, 0.2533760964870453, 0.2666448950767517, 0.27991369366645813, 0.29318249225616455, 0.3064512610435486, 0.319720059633255, 0.3329888582229614, 0.34625762701034546, 0.3595264256000519, 0.3727952241897583, 0.3860640227794647, 0.39933282136917114, 0.4126015901565552, 0.4258703887462616, 0.439139187335968, 0.45240795612335205, 0.46567675471305847, 0.4789455533027649]}, "gradients/roberta.encoder.layer.4.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 2.0, 7.0, 3.0, 3.0, 18.0, 25.0, 15.0, 36.0, 52.0, 75.0, 90.0, 159.0, 239.0, 373.0, 500.0, 749.0, 906.0, 837.0, 675.0, 444.0, 338.0, 192.0, 126.0, 77.0, 54.0, 45.0, 32.0, 16.0, 8.0, 9.0, 7.0, 4.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0], "bins": [-0.08226566016674042, -0.08019737899303436, -0.07812909781932831, -0.07606081664562225, -0.0739925354719162, -0.07192425429821014, -0.06985597312450409, -0.06778769195079803, -0.06571941077709198, -0.06365112960338593, -0.06158284842967987, -0.059514567255973816, -0.05744628608226776, -0.05537800490856171, -0.05330972373485565, -0.0512414425611496, -0.04917316138744354, -0.04710488021373749, -0.04503659904003143, -0.04296831786632538, -0.040900036692619324, -0.03883175551891327, -0.036763474345207214, -0.03469519317150116, -0.032626911997795105, -0.03055863082408905, -0.028490349650382996, -0.02642206847667694, -0.024353787302970886, -0.02228550612926483, -0.020217224955558777, -0.018148943781852722, -0.01608065888285637, -0.014012377709150314, -0.01194409653544426, -0.009875815361738205, -0.00780753418803215, -0.005739253014326096, -0.003670971840620041, -0.0016026906669139862, 0.0004655905067920685, 0.002533871680498123, 0.004602152854204178, 0.0066704340279102325, 0.008738715201616287, 0.010806996375322342, 0.012875277549028397, 0.014943558722734451, 0.017011839896440506, 0.01908012107014656, 0.021148402243852615, 0.02321668341755867, 0.025284964591264725, 0.02735324576497078, 0.029421526938676834, 0.03148980811238289, 0.033558089286088943, 0.035626370459795, 0.03769465163350105, 0.03976293280720711, 0.04183121398091316, 0.04389949515461922, 0.04596777632832527, 0.048036057502031326, 0.05010433867573738]}, "gradients/roberta.encoder.layer.4.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 5.0, 22.0, 4030.0, 2047.0, 17.0, 1.0, 4.0, 3.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.4169599711894989, -0.4046688377857208, -0.39237770438194275, -0.3800865709781647, -0.3677954375743866, -0.3555043041706085, -0.34321317076683044, -0.33092203736305237, -0.3186309039592743, -0.3063397705554962, -0.29404863715171814, -0.28175750374794006, -0.269466370344162, -0.2571752369403839, -0.24488410353660583, -0.23259297013282776, -0.22030183672904968, -0.2080107033252716, -0.19571956992149353, -0.18342843651771545, -0.17113730311393738, -0.1588461697101593, -0.14655503630638123, -0.13426390290260315, -0.12197276949882507, -0.109681636095047, -0.09739050269126892, -0.08509936928749084, -0.07280823588371277, -0.06051710247993469, -0.048225969076156616, -0.03593483567237854, -0.02364373207092285, -0.011352598667144775, 0.0009385347366333008, 0.013229668140411377, 0.025520801544189453, 0.03781193494796753, 0.050103068351745605, 0.06239420175552368, 0.07468533515930176, 0.08697646856307983, 0.09926760196685791, 0.11155873537063599, 0.12384986877441406, 0.13614100217819214, 0.14843213558197021, 0.1607232689857483, 0.17301440238952637, 0.18530553579330444, 0.19759666919708252, 0.2098878026008606, 0.22217893600463867, 0.23447006940841675, 0.24676120281219482, 0.2590523362159729, 0.271343469619751, 0.28363460302352905, 0.29592573642730713, 0.3082168698310852, 0.3205080032348633, 0.33279913663864136, 0.34509027004241943, 0.3573814034461975, 0.3696725368499756]}, "gradients/roberta.encoder.layer.4.attention.self.query.lora_B": {"_type": "histogram", "values": [2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 4.0, 5.0, 2.0, 5.0, 6.0, 12.0, 34.0, 37.0, 56.0, 91.0, 218.0, 419.0, 921.0, 1606.0, 1316.0, 680.0, 327.0, 144.0, 83.0, 61.0, 37.0, 21.0, 17.0, 4.0, 7.0, 4.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.02675461955368519, -0.02571723982691765, -0.02467986010015011, -0.02364248037338257, -0.02260509878396988, -0.02156771905720234, -0.0205303393304348, -0.01949295960366726, -0.01845557987689972, -0.01741820015013218, -0.01638082042336464, -0.015343439765274525, -0.01430605910718441, -0.01326867938041687, -0.01223129965364933, -0.01119391992688179, -0.010156538337469101, -0.009119158610701561, -0.008081777952611446, -0.007044398225843906, -0.006007018033415079, -0.004969637840986252, -0.003932258114218712, -0.0028948779217898846, -0.0018574977293610573, -0.0008201176533475518, 0.00021726242266595364, 0.0012546423822641373, 0.0022920225746929646, 0.003329402767121792, 0.004366782493889332, 0.005404162686318159, 0.006441541016101837, 0.0074789212085306644, 0.008516301400959492, 0.009553681127727032, 0.010591061785817146, 0.011628441512584686, 0.012665821239352226, 0.013703200966119766, 0.01474058162420988, 0.015777962282299995, 0.016815342009067535, 0.017852721735835075, 0.018890101462602615, 0.019927483052015305, 0.020964860916137695, 0.022002242505550385, 0.023039622232317924, 0.024077001959085464, 0.025114381685853004, 0.026151761412620544, 0.027189143002033234, 0.028226522728800774, 0.029263902455568314, 0.030301282182335854, 0.031338661909103394, 0.03237604349851608, 0.033413421362638474, 0.03445080295205116, 0.03548818081617355, 0.03652556240558624, 0.03756294399499893, 0.03860032185912132, 0.03963770344853401]}, "gradients/roberta.encoder.layer.4.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 4.0, 6.0, 34.0, 208.0, 2331.0, 3268.0, 244.0, 29.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0], "bins": [-0.1874815821647644, -0.18313021957874298, -0.17877885699272156, -0.17442747950553894, -0.17007611691951752, -0.1657247543334961, -0.16137339174747467, -0.15702202916145325, -0.15267065167427063, -0.1483192890882492, -0.14396792650222778, -0.13961654901504517, -0.13526518642902374, -0.13091382384300232, -0.1265624612569809, -0.12221109867095947, -0.11785973608493805, -0.11350837349891663, -0.1091570034623146, -0.10480564087629318, -0.10045427083969116, -0.09610290825366974, -0.09175154566764832, -0.08740018308162689, -0.08304881304502487, -0.07869745045900345, -0.07434608042240143, -0.06999471783638, -0.06564335525035858, -0.06129198521375656, -0.05694062262773514, -0.052589256316423416, -0.048237890005111694, -0.04388652369379997, -0.03953515738248825, -0.03518379479646683, -0.030832428485155106, -0.026481062173843384, -0.02212969772517681, -0.01777833327651024, -0.013426966965198517, -0.00907560158520937, -0.0047242362052202225, -0.0003728708252310753, 0.003978494554758072, 0.008329860866069794, 0.012681225314736366, 0.01703258976340294, 0.02138395607471466, 0.025735322386026382, 0.030086686834692955, 0.03443805128335953, 0.03878941759467125, 0.04314078390598297, 0.047492146492004395, 0.051843512803316116, 0.05619487911462784, 0.06054624542593956, 0.06489761173725128, 0.0692489743232727, 0.07360033690929413, 0.07795170694589615, 0.08230306953191757, 0.08665443956851959, 0.09100580215454102]}, "gradients/roberta.encoder.layer.3.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 0.0, 1.0, 4.0, 2.0, 9.0, 8.0, 8.0, 8.0, 16.0, 29.0, 29.0, 42.0, 59.0, 69.0, 102.0, 133.0, 154.0, 233.0, 265.0, 353.0, 400.0, 496.0, 537.0, 543.0, 517.0, 467.0, 366.0, 305.0, 245.0, 198.0, 137.0, 97.0, 80.0, 62.0, 42.0, 31.0, 21.0, 14.0, 11.0, 15.0, 9.0, 4.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.029607251286506653, -0.028428353369235992, -0.02724945731461048, -0.02607055939733982, -0.02489166334271431, -0.02371276542544365, -0.02253386750817299, -0.02135496959090233, -0.020176073536276817, -0.018997175619006157, -0.017818279564380646, -0.016639381647109985, -0.0154604846611619, -0.014281587675213814, -0.013102689757943153, -0.011923792771995068, -0.010744895786046982, -0.009565998800098896, -0.00838710181415081, -0.00720820389688015, -0.006029306910932064, -0.004850409924983978, -0.003671512473374605, -0.002492615021765232, -0.0013137180358171463, -0.00013482081703841686, 0.0010440764017403126, 0.002222973620519042, 0.0034018708392977715, 0.004580767825245857, 0.00575966527685523, 0.006938562728464603, 0.00811745971441269, 0.009296356700360775, 0.01047525368630886, 0.011654151603579521, 0.012833048589527607, 0.014011945575475693, 0.015190843492746353, 0.016369741410017014, 0.017548637464642525, 0.018727535381913185, 0.019906431436538696, 0.021085329353809357, 0.022264227271080017, 0.023443123325705528, 0.02462202124297619, 0.0258009172976017, 0.02697981521487236, 0.02815871313214302, 0.029337609186768532, 0.030516507104039192, 0.0316954031586647, 0.032874301075935364, 0.034053198993206024, 0.035232096910476685, 0.036410994827747345, 0.037589892745018005, 0.038768790662288666, 0.03994768485426903, 0.04112658277153969, 0.04230548068881035, 0.04348437860608101, 0.04466327652335167, 0.04584217071533203]}, "gradients/roberta.encoder.layer.3.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 3.0, 4814.0, 1303.0, 7.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.8047198057174683, -0.7778376340866089, -0.7509554028511047, -0.7240732312202454, -0.697191059589386, -0.6703088283538818, -0.6434266567230225, -0.6165444850921631, -0.5896623134613037, -0.5627801418304443, -0.5358979105949402, -0.5090157389640808, -0.48213356733322144, -0.4552513659000397, -0.4283691644668579, -0.40148699283599854, -0.3746047616004944, -0.3477225601673126, -0.32084038853645325, -0.2939581871032715, -0.2670760154724121, -0.24019381403923035, -0.21331161260604858, -0.18642942607402802, -0.15954723954200745, -0.13266505300998688, -0.10578285902738571, -0.07890066504478455, -0.05201847851276398, -0.025136291980743408, 0.0017459094524383545, 0.028628095984458923, 0.05551034212112427, 0.08239252865314484, 0.109274722635746, 0.13615691661834717, 0.16303910315036774, 0.1899212896823883, 0.21680349111557007, 0.24368567764759064, 0.2705678641796112, 0.29745006561279297, 0.32433223724365234, 0.3512144386768341, 0.37809664011001587, 0.40497881174087524, 0.431861013174057, 0.45874321460723877, 0.48562538623809814, 0.5125075578689575, 0.5393897891044617, 0.566271960735321, 0.5931541323661804, 0.6200363636016846, 0.646918535232544, 0.6738007068634033, 0.7006828784942627, 0.7275650501251221, 0.7544472813606262, 0.7813294529914856, 0.808211624622345, 0.8350938558578491, 0.8619760274887085, 0.8888581991195679, 0.915740430355072]}, "gradients/roberta.encoder.layer.3.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 4.0, 1.0, 4.0, 2.0, 3.0, 2.0, 5.0, 12.0, 16.0, 15.0, 30.0, 39.0, 67.0, 113.0, 247.0, 519.0, 911.0, 1475.0, 1232.0, 657.0, 347.0, 169.0, 98.0, 59.0, 34.0, 25.0, 9.0, 10.0, 9.0, 4.0, 4.0, 6.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.029107946902513504, -0.02827044390141964, -0.027432940900325775, -0.02659543789923191, -0.025757934898138046, -0.024920430034399033, -0.024082928895950317, -0.023245424032211304, -0.02240792103111744, -0.021570418030023575, -0.02073291502892971, -0.019895412027835846, -0.01905790902674198, -0.018220406025648117, -0.017382901161909103, -0.01654539816081524, -0.015707895159721375, -0.01487039215862751, -0.014032889157533646, -0.013195386156439781, -0.012357882224023342, -0.011520379222929478, -0.010682876221835613, -0.009845372289419174, -0.009007871150970459, -0.008170368149876595, -0.007332864683121443, -0.006495361682027578, -0.005657858215272427, -0.004820355214178562, -0.003982852213084698, -0.003145348746329546, -0.0023078452795743942, -0.0014703420456498861, -0.0006328389281406999, 0.0002046641893684864, 0.0010421674232929945, 0.0018796706572175026, 0.002717173658311367, 0.003554677125066519, 0.004392180126160383, 0.005229683127254248, 0.006067186594009399, 0.006904689595103264, 0.007742192596197128, 0.008579695597290993, 0.009417198598384857, 0.010254702530801296, 0.01109220553189516, 0.011929708532989025, 0.01276721153408289, 0.013604715466499329, 0.014442218467593193, 0.015279721468687057, 0.016117224469780922, 0.016954727470874786, 0.01779223047196865, 0.018629733473062515, 0.01946723647415638, 0.020304739475250244, 0.02114224247634411, 0.021979745477437973, 0.022817250341176987, 0.02365475334227085, 0.024492256343364716]}, "gradients/roberta.encoder.layer.3.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 32.0, 391.0, 4463.0, 1159.0, 77.0, 7.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.15270499885082245, -0.14842505753040314, -0.14414510130882263, -0.13986515998840332, -0.13558520376682281, -0.1313052624464035, -0.127025306224823, -0.12274536490440369, -0.11846542358398438, -0.11418547481298447, -0.10990552604198456, -0.10562558472156525, -0.10134563595056534, -0.09706568717956543, -0.09278573840856552, -0.08850578963756561, -0.0842258408665657, -0.0799458920955658, -0.07566594332456589, -0.07138599455356598, -0.06710605323314667, -0.06282610446214676, -0.05854615569114685, -0.05426620692014694, -0.04998626187443733, -0.045706313103437424, -0.041426368057727814, -0.037146419286727905, -0.032866470515728, -0.028586525470018387, -0.02430657669901848, -0.02002662979066372, -0.01574668288230896, -0.0114667359739542, -0.007186788134276867, -0.002906840294599533, 0.0013731066137552261, 0.005653053522109985, 0.009933002293109894, 0.014212949201464653, 0.018492896109819412, 0.02277284301817417, 0.02705278992652893, 0.03133273869752884, 0.03561268746852875, 0.03989263251423836, 0.044172581285238266, 0.048452526330947876, 0.052732475101947784, 0.05701242387294769, 0.0612923689186573, 0.06557232141494751, 0.06985226273536682, 0.07413221150636673, 0.07841216027736664, 0.08269210904836655, 0.08697205781936646, 0.09125200659036636, 0.09553195536136627, 0.09981189668178558, 0.10409184545278549, 0.1083717942237854, 0.11265174299478531, 0.11693169176578522, 0.12121163308620453]}, "gradients/roberta.encoder.layer.2.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 4.0, 9.0, 3.0, 17.0, 9.0, 16.0, 20.0, 24.0, 24.0, 40.0, 40.0, 61.0, 82.0, 120.0, 114.0, 160.0, 198.0, 243.0, 310.0, 342.0, 460.0, 495.0, 513.0, 496.0, 468.0, 358.0, 322.0, 254.0, 202.0, 156.0, 117.0, 88.0, 64.0, 66.0, 53.0, 45.0, 26.0, 26.0, 13.0, 15.0, 10.0, 8.0, 9.0, 5.0, 6.0, 2.0, 2.0, 0.0, 2.0, 0.0, 1.0, 4.0, 0.0, 2.0, 1.0], "bins": [-0.03738998994231224, -0.036199767142534256, -0.03500954806804657, -0.033819325268268585, -0.0326291024684906, -0.031438879668712616, -0.03024866059422493, -0.029058437794446945, -0.02786821685731411, -0.026677995920181274, -0.02548777312040329, -0.024297552183270454, -0.02310733124613762, -0.021917108446359634, -0.0207268875092268, -0.019536666572093964, -0.01834644377231598, -0.017156222835183144, -0.01596600003540516, -0.014775779098272324, -0.013585557229816914, -0.012395335361361504, -0.011205114424228668, -0.010014892555773258, -0.008824670687317848, -0.007634448818862438, -0.0064442274160683155, -0.005254006013274193, -0.004063784144818783, -0.002873562276363373, -0.00168334087356925, -0.0004931194707751274, 0.0006970986723899841, 0.0018873203080147505, 0.003077541943639517, 0.0042677633464336395, 0.0054579852148890495, 0.0066482070833444595, 0.007838428020477295, 0.009028649888932705, 0.010218871757388115, 0.011409093625843525, 0.012599315494298935, 0.01378953643143177, 0.01497975829988718, 0.01616998016834259, 0.017360201105475426, 0.01855042204260826, 0.019740644842386246, 0.02093086577951908, 0.022121088579297066, 0.0233113095164299, 0.024501532316207886, 0.02569175325334072, 0.026881974190473557, 0.02807219699025154, 0.029262417927384377, 0.030452638864517212, 0.0316428616642952, 0.03283308446407318, 0.03402330353856087, 0.03521352633833885, 0.03640374913811684, 0.03759396821260452, 0.03878419101238251]}, "gradients/roberta.encoder.layer.2.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 5.0, 1.0, 3.0, 5097.0, 1022.0, 5.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.16343934834003448, -0.1496838927268982, -0.1359284371137619, -0.12217298150062561, -0.10841752588748932, -0.09466206282377243, -0.08090660721063614, -0.06715115159749985, -0.053395695984363556, -0.039640240371227264, -0.025884782895445824, -0.012129325419664383, 0.0016261301934719086, 0.015381589531898499, 0.02913704514503479, 0.04289250075817108, 0.05664795637130737, 0.07040341198444366, 0.08415886759757996, 0.09791432321071625, 0.11166977882385254, 0.12542524933815002, 0.13918069005012512, 0.1529361605644226, 0.1666916012763977, 0.180447056889534, 0.1942025125026703, 0.20795796811580658, 0.22171342372894287, 0.23546889424324036, 0.24922433495521545, 0.26297980546951294, 0.2767352759838104, 0.2904907464981079, 0.304246187210083, 0.3180016577243805, 0.3317570984363556, 0.3455125689506531, 0.3592680096626282, 0.37302348017692566, 0.38677892088890076, 0.40053439140319824, 0.41428983211517334, 0.4280453026294708, 0.4418007433414459, 0.4555562138557434, 0.4693116545677185, 0.483067125082016, 0.4968225955963135, 0.5105780363082886, 0.5243335366249084, 0.5380889773368835, 0.5518444180488586, 0.5655998587608337, 0.5793553590774536, 0.5931107997894287, 0.6068662405014038, 0.6206216812133789, 0.6343771815299988, 0.6481326222419739, 0.661888062953949, 0.6756435036659241, 0.689399003982544, 0.703154444694519, 0.7169098854064941]}, "gradients/roberta.encoder.layer.2.attention.self.query.lora_B": {"_type": "histogram", "values": [3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 4.0, 7.0, 19.0, 23.0, 35.0, 63.0, 88.0, 181.0, 335.0, 653.0, 1169.0, 1350.0, 1004.0, 545.0, 295.0, 147.0, 71.0, 49.0, 27.0, 16.0, 11.0, 7.0, 8.0, 9.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], "bins": [-0.023498836904764175, -0.02266959846019745, -0.02184036187827587, -0.021011123433709145, -0.020181884989142418, -0.01935264840722084, -0.018523409962654114, -0.017694171518087387, -0.01686493493616581, -0.016035696491599083, -0.015206458978354931, -0.014377221465110779, -0.013547983951866627, -0.012718746438622475, -0.011889507994055748, -0.011060270480811596, -0.01023103203624487, -0.009401794523000717, -0.00857255607843399, -0.007743318565189838, -0.006914081051945686, -0.006084843073040247, -0.005255605094134808, -0.0044263675808906555, -0.003597129601985216, -0.0027678918559104204, -0.0019386539934203029, -0.0011094161309301853, -0.0002801783848553896, 0.0005490593612194061, 0.0013782973401248455, 0.0022075348533689976, 0.003036772832274437, 0.0038660105783492327, 0.004695248324424028, 0.005524486303329468, 0.00635372381657362, 0.007182961795479059, 0.008012199774384499, 0.00884143728762865, 0.009670674800872803, 0.010499912314116955, 0.011329150758683681, 0.012158388271927834, 0.012987625785171986, 0.013816863298416138, 0.014646101742982864, 0.015475339256227016, 0.016304578632116318, 0.017133817076683044, 0.017963053658604622, 0.01879229210317135, 0.019621530547738075, 0.020450767129659653, 0.02128000557422638, 0.022109244018793106, 0.022938480600714684, 0.02376771904528141, 0.024596955627202988, 0.025426194071769714, 0.02625543251633644, 0.02708466909825802, 0.027913907542824745, 0.028743144124746323, 0.02957238256931305]}, "gradients/roberta.encoder.layer.2.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 15.0, 142.0, 1919.0, 3699.0, 330.0, 21.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.16188672184944153, -0.1570080667734146, -0.1521293967962265, -0.14725074172019958, -0.14237207174301147, -0.13749341666698456, -0.13261474668979645, -0.12773609161376953, -0.12285742908716202, -0.1179787665605545, -0.11310010403394699, -0.10822144150733948, -0.10334278643131256, -0.09846411645412445, -0.09358546137809753, -0.08870679885149002, -0.08382813632488251, -0.078949473798275, -0.07407081127166748, -0.06919214874505997, -0.06431348621845245, -0.05943482741713524, -0.054556168615818024, -0.04967750608921051, -0.044798843562603, -0.03992018103599548, -0.03504151850938797, -0.030162859708070755, -0.02528419718146324, -0.020405534654855728, -0.015526873990893364, -0.010648213326931, -0.005769550800323486, -0.0008908892050385475, 0.003987772390246391, 0.00886643398553133, 0.013745095580816269, 0.018623758107423782, 0.023502418771386147, 0.02838107943534851, 0.033259741961956024, 0.03813840448856354, 0.04301706701517105, 0.047895725816488266, 0.05277438834309578, 0.05765305086970329, 0.06253170967102051, 0.06741037219762802, 0.07228903472423553, 0.07716769725084305, 0.08204635977745056, 0.08692502230405807, 0.09180368483066559, 0.0966823399066925, 0.10156100243330002, 0.10643966495990753, 0.11131832748651505, 0.11619699001312256, 0.12107565253973007, 0.12595431506633759, 0.1308329701423645, 0.1357116401195526, 0.14059029519557953, 0.14546895027160645, 0.15034762024879456]}, "gradients/roberta.encoder.layer.1.attention.self.value.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 5.0, 6.0, 14.0, 7.0, 25.0, 15.0, 43.0, 47.0, 83.0, 114.0, 193.0, 288.0, 484.0, 686.0, 874.0, 921.0, 808.0, 504.0, 360.0, 221.0, 159.0, 79.0, 68.0, 41.0, 26.0, 20.0, 15.0, 12.0, 3.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.07606307417154312, -0.07389839738607407, -0.07173371315002441, -0.06956903636455536, -0.0674043521285057, -0.06523967534303665, -0.063074991106987, -0.060910314321517944, -0.05874563381075859, -0.05658095329999924, -0.05441627278923988, -0.05225159227848053, -0.050086915493011475, -0.04792223125696182, -0.04575755447149277, -0.043592873960733414, -0.04142819344997406, -0.039263512939214706, -0.03709883242845535, -0.034934151917696, -0.032769471406936646, -0.03060479275882244, -0.028440114110708237, -0.026275433599948883, -0.02411075308918953, -0.021946072578430176, -0.019781392067670822, -0.017616713419556618, -0.015452032908797264, -0.01328735239803791, -0.011122672818601131, -0.008957993239164352, -0.0067933090031147, -0.004628628958016634, -0.0024639489129185677, -0.00029926886782050133, 0.001865411177277565, 0.004030091688036919, 0.006194771267473698, 0.008359450846910477, 0.01052413135766983, 0.012688811868429184, 0.014853491447865963, 0.017018171027302742, 0.019182851538062096, 0.02134753204882145, 0.023512210696935654, 0.025676891207695007, 0.02784157171845436, 0.030006252229213715, 0.03217093273997307, 0.03433561325073242, 0.03650029003620148, 0.03866497427225113, 0.040829651057720184, 0.04299433156847954, 0.04515901207923889, 0.047323692589998245, 0.0494883731007576, 0.05165305361151695, 0.053817734122276306, 0.05598241090774536, 0.058147091418504715, 0.06031177192926407, 0.06247645244002342]}, "gradients/roberta.encoder.layer.1.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 4.0, 36.0, 4603.0, 1471.0, 10.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.3940945267677307, -0.3833959102630615, -0.37269729375839233, -0.36199867725372314, -0.35130006074905396, -0.3406014144420624, -0.3299027979373932, -0.319204181432724, -0.3085055649280548, -0.2978069484233856, -0.28710833191871643, -0.27640971541404724, -0.26571106910705566, -0.2550124526023865, -0.24431383609771729, -0.2336152195930481, -0.2229166030883789, -0.21221798658370972, -0.20151937007904053, -0.19082073867321014, -0.18012212216854095, -0.16942350566387177, -0.15872487425804138, -0.1480262577533722, -0.137327641248703, -0.1266290247440338, -0.11593040078878403, -0.10523177683353424, -0.09453316032886505, -0.08383454382419586, -0.07313591986894608, -0.06243729591369629, -0.05173870921134949, -0.04104008898139, -0.03034146875143051, -0.019642848521471024, -0.008944228291511536, 0.0017543919384479523, 0.01245301216840744, 0.023151636123657227, 0.033850252628326416, 0.044548872858285904, 0.05524749308824539, 0.06594611704349518, 0.07664473354816437, 0.08734335005283356, 0.09804197400808334, 0.10874059796333313, 0.11943921446800232, 0.1301378309726715, 0.1408364474773407, 0.15153507888317108, 0.16223369538784027, 0.17293231189250946, 0.18363094329833984, 0.19432955980300903, 0.20502817630767822, 0.2157267928123474, 0.2264254093170166, 0.23712404072284698, 0.24782265722751617, 0.25852128863334656, 0.26921990513801575, 0.27991852164268494, 0.2906171381473541]}, "gradients/roberta.encoder.layer.1.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 5.0, 1.0, 2.0, 3.0, 6.0, 7.0, 4.0, 9.0, 16.0, 18.0, 15.0, 35.0, 33.0, 68.0, 117.0, 216.0, 418.0, 816.0, 1810.0, 1099.0, 620.0, 323.0, 193.0, 101.0, 64.0, 39.0, 30.0, 13.0, 13.0, 7.0, 5.0, 5.0, 2.0, 3.0, 2.0, 6.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03111610747873783, -0.03029230795800686, -0.029468510299921036, -0.028644710779190063, -0.02782091125845909, -0.02699711173772812, -0.026173312216997147, -0.025349514558911324, -0.02452571503818035, -0.02370191551744938, -0.022878117859363556, -0.022054318338632584, -0.02123051881790161, -0.02040671929717064, -0.019582919776439667, -0.018759122118353844, -0.01793532259762287, -0.0171115230768919, -0.016287725418806076, -0.015463925898075104, -0.014640126377344131, -0.01381632685661316, -0.012992528267204762, -0.012168729677796364, -0.011344930157065392, -0.01052113063633442, -0.009697332046926022, -0.008873533457517624, -0.008049733936786652, -0.007225934881716967, -0.006402135826647282, -0.005578336771577597, -0.0047545358538627625, -0.0039307367987930775, -0.0031069377437233925, -0.0022831386886537075, -0.0014593396335840225, -0.0006355405785143375, 0.00018825847655534744, 0.0010120575316250324, 0.0018358565866947174, 0.0026596556417644024, 0.0034834546968340874, 0.004307253751903772, 0.005131052806973457, 0.005954851862043142, 0.006778650917112827, 0.007602449972182512, 0.008426249027252197, 0.00925004854798317, 0.010073847137391567, 0.010897645726799965, 0.011721445247530937, 0.01254524476826191, 0.013369043357670307, 0.014192841947078705, 0.015016641467809677, 0.01584044098854065, 0.01666424050927162, 0.017488038167357445, 0.018311837688088417, 0.01913563720881939, 0.019959434866905212, 0.020783234387636185, 0.021607033908367157]}, "gradients/roberta.encoder.layer.1.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 4.0, 27.0, 138.0, 758.0, 2320.0, 2100.0, 638.0, 122.0, 19.0, 7.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.05944118648767471, -0.05745607987046242, -0.05547097325325012, -0.05348586663603783, -0.05150076001882553, -0.049515653401613235, -0.04753054678440094, -0.045545440167188644, -0.04356033354997635, -0.04157522693276405, -0.03959012031555176, -0.03760501369833946, -0.03561990708112717, -0.03363480046391487, -0.031649693846702576, -0.02966458722949028, -0.027679480612277985, -0.02569437399506569, -0.023709267377853394, -0.021724160760641098, -0.019739054143428802, -0.017753947526216507, -0.01576884090900421, -0.013783734291791916, -0.01179862767457962, -0.009813521057367325, -0.00782841444015503, -0.005843307822942734, -0.0038582012057304382, -0.0018730945885181427, 0.00011201202869415283, 0.0020971186459064484, 0.004082217812538147, 0.0060673244297504425, 0.008052431046962738, 0.010037537664175034, 0.012022644281387329, 0.014007750898599625, 0.01599285751581192, 0.017977964133024216, 0.01996307075023651, 0.021948177367448807, 0.023933283984661102, 0.025918390601873398, 0.027903497219085693, 0.02988860383629799, 0.031873710453510284, 0.03385881707072258, 0.035843923687934875, 0.03782903030514717, 0.03981413692235947, 0.04179924353957176, 0.04378435015678406, 0.04576945677399635, 0.04775456339120865, 0.049739670008420944, 0.05172477662563324, 0.053709883242845535, 0.05569498986005783, 0.057680096477270126, 0.05966520309448242, 0.06165030971169472, 0.06363541632890701, 0.0656205266714096, 0.0676056295633316]}, "gradients/roberta.encoder.layer.0.attention.self.value.lora_B": {"_type": "histogram", "values": [2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 6.0, 7.0, 6.0, 8.0, 17.0, 21.0, 18.0, 30.0, 32.0, 51.0, 86.0, 118.0, 179.0, 255.0, 340.0, 563.0, 739.0, 804.0, 719.0, 623.0, 449.0, 330.0, 220.0, 171.0, 103.0, 76.0, 48.0, 35.0, 18.0, 16.0, 12.0, 5.0, 2.0, 7.0, 3.0, 1.0, 5.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.04978082701563835, -0.04776832088828087, -0.045755814760923386, -0.0437433086335659, -0.04173079878091812, -0.03971829265356064, -0.037705786526203156, -0.03569328039884567, -0.03368077427148819, -0.03166826814413071, -0.029655762016773224, -0.027643254026770592, -0.02563074789941311, -0.023618241772055626, -0.021605733782052994, -0.01959322765469551, -0.017580721527338028, -0.015568215399980545, -0.013555708341300488, -0.01154320128262043, -0.009530695155262947, -0.007518189027905464, -0.005505681969225407, -0.003493174910545349, -0.0014806687831878662, 0.000531837809830904, 0.0025443444028496742, 0.0045568509958684444, 0.006569357588887215, 0.008581863716244698, 0.010594370774924755, 0.012606877833604813, 0.014619380235671997, 0.01663188636302948, 0.018644392490386963, 0.020656900480389595, 0.022669406607747078, 0.02468191273510456, 0.026694420725107193, 0.028706926852464676, 0.03071943297982216, 0.03273193910717964, 0.034744445234537125, 0.03675695136189461, 0.03876946121454239, 0.04078196734189987, 0.042794473469257355, 0.04480697959661484, 0.04681948572397232, 0.0488319918513298, 0.050844497978687286, 0.05285700410604477, 0.05486951023340225, 0.056882016360759735, 0.058894526213407516, 0.060907032340765, 0.06291954219341278, 0.06493204832077026, 0.06694455444812775, 0.06895706057548523, 0.07096956670284271, 0.0729820728302002, 0.07499457895755768, 0.07700708508491516, 0.07901959121227264]}, "gradients/roberta.encoder.layer.0.attention.self.value.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 14.0, 30.0, 226.0, 1572.0, 3006.0, 1116.0, 132.0, 25.0, 6.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.1294788271188736, -0.12369741499423981, -0.11791600286960602, -0.11213458329439163, -0.10635317116975784, -0.10057175904512405, -0.09479033946990967, -0.08900892734527588, -0.08322751522064209, -0.0774461030960083, -0.07166469097137451, -0.06588327139616013, -0.06010185927152634, -0.05432044714689255, -0.04853903129696846, -0.04275761544704437, -0.036976203322410583, -0.031194789335131645, -0.025413375347852707, -0.01963196136057377, -0.01385054737329483, -0.008069133386015892, -0.0022877193987369537, 0.003493696451187134, 0.009275108575820923, 0.015056522563099861, 0.0208379365503788, 0.026619350537657738, 0.032400764524936676, 0.038182176649570465, 0.04396359249949455, 0.04974500834941864, 0.05552642047405243, 0.06130783259868622, 0.06708924472332001, 0.0728706642985344, 0.07865207642316818, 0.08443348854780197, 0.09021490812301636, 0.09599632024765015, 0.10177773237228394, 0.10755914449691772, 0.11334055662155151, 0.1191219761967659, 0.12490338832139969, 0.13068480789661407, 0.13646622002124786, 0.14224763214588165, 0.14802904427051544, 0.15381045639514923, 0.15959186851978302, 0.1653732806444168, 0.1711547076702118, 0.17693611979484558, 0.18271753191947937, 0.18849894404411316, 0.19428035616874695, 0.20006176829338074, 0.20584318041801453, 0.21162459254264832, 0.2174060046672821, 0.2231874316930771, 0.22896884381771088, 0.23475025594234467, 0.24053166806697845]}, "gradients/roberta.encoder.layer.0.attention.self.query.lora_B": {"_type": "histogram", "values": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 3.0, 4.0, 5.0, 2.0, 12.0, 15.0, 20.0, 37.0, 54.0, 78.0, 133.0, 227.0, 414.0, 792.0, 1494.0, 1335.0, 669.0, 325.0, 203.0, 118.0, 63.0, 39.0, 23.0, 20.0, 16.0, 9.0, 5.0, 6.0, 2.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.03267068788409233, -0.031576890498399734, -0.030483093112707138, -0.02938929572701454, -0.028295498341321945, -0.02720170095562935, -0.026107903569936752, -0.025014106184244156, -0.02392030879855156, -0.022826511412858963, -0.021732714027166367, -0.02063891664147377, -0.019545119255781174, -0.018451321870088577, -0.01735752448439598, -0.016263727098703384, -0.015169929713010788, -0.014076132327318192, -0.012982334941625595, -0.011888537555932999, -0.010794740170240402, -0.009700942784547806, -0.00860714539885521, -0.007513348013162613, -0.0064195506274700165, -0.00532575324177742, -0.004231955856084824, -0.003138158470392227, -0.0020443610846996307, -0.0009505636990070343, 0.00014323368668556213, 0.0012370310723781586, 0.002330828458070755, 0.0034246258437633514, 0.004518423229455948, 0.005612220615148544, 0.006706018000841141, 0.007799815386533737, 0.008893612772226334, 0.00998741015791893, 0.011081207543611526, 0.012175004929304123, 0.01326880231499672, 0.014362599700689316, 0.015456397086381912, 0.01655019447207451, 0.017643991857767105, 0.0187377892434597, 0.019831586629152298, 0.020925384014844894, 0.02201918140053749, 0.023112978786230087, 0.024206776171922684, 0.02530057355761528, 0.026394370943307877, 0.027488168329000473, 0.02858196571469307, 0.029675763100385666, 0.030769560486078262, 0.03186335787177086, 0.032957155257463455, 0.03405095264315605, 0.03514475002884865, 0.036238547414541245, 0.03733234480023384]}, "gradients/roberta.encoder.layer.0.attention.self.query.lora_A": {"_type": "histogram", "values": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 6.0, 29.0, 90.0, 206.0, 658.0, 1511.0, 1871.0, 1114.0, 411.0, 151.0, 54.0, 20.0, 7.0, 4.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], "bins": [-0.061005957424640656, -0.05945361405611038, -0.05790127441287041, -0.05634893476963043, -0.05479659140110016, -0.053244248032569885, -0.05169190838932991, -0.050139568746089935, -0.04858722537755966, -0.04703488200902939, -0.04548254236578941, -0.04393020272254944, -0.042377859354019165, -0.04082551598548889, -0.03927317634224892, -0.03772083669900894, -0.03616849333047867, -0.034616149961948395, -0.03306381031870842, -0.031511470675468445, -0.02995912730693817, -0.028406785801053047, -0.026854444295167923, -0.0253021027892828, -0.023749761283397675, -0.02219741977751255, -0.020645078271627426, -0.019092736765742302, -0.017540395259857178, -0.015988053753972054, -0.01443571224808693, -0.012883370742201805, -0.011331029236316681, -0.009778687730431557, -0.008226346224546432, -0.006674004718661308, -0.005121663212776184, -0.00356932170689106, -0.0020169802010059357, -0.00046463869512081146, 0.0010877028107643127, 0.002640044316649437, 0.004192385822534561, 0.005744727328419685, 0.00729706883430481, 0.008849410340189934, 0.010401751846075058, 0.011954093351960182, 0.013506434857845306, 0.01505877636373043, 0.016611117869615555, 0.01816345937550068, 0.019715800881385803, 0.021268142387270927, 0.02282048389315605, 0.024372825399041176, 0.0259251669049263, 0.027477508410811424, 0.02902984991669655, 0.030582191422581673, 0.0321345329284668, 0.03368687629699707, 0.035239215940237045, 0.03679155558347702, 0.038343898952007294]}, "eval_metroc": {"matthews_correlation": 0.5548848010257114}}